<?xml version="1.0"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Planet SymPy</title>
    <link>http://planet.sympy.org/</link>
    <language>en</language>
    <description>Planet SymPy - http://planet.sympy.org/</description>
    <atom:link href="http://planet.sympy.org/rss10.xml" rel="self" type="application/rss+xml"/>
    <item>
      <guid isPermaLink="false">https://asmeurer.com/blog/posts/switching-to-utterances-comments/</guid>
      <author>Aaron Meurer (asmeurer)</author>
      <title>Aaron Meurer (asmeurer): Switching to Utterances Comments</title>
      <pubDate>Thu, 03 Jun 2021 03:57:49 GMT</pubDate>
      <link>https://asmeurer.com/blog/posts/switching-to-utterances-comments/</link>
      <description>&lt;div&gt;&lt;p&gt;I've ditched Disqus as the comment system on this blog. I am now using
&lt;a href="https://utteranc.es/"&gt;Utterances&lt;/a&gt;. Utterances is an open source comment
system that is backed by GitHub issues. Basically, every post has a
corresponding issue opened on GitHub, and the comments on the post are the
comments on the issue. Utterances automatically places the comments at the
bottom of the post. For example,
&lt;a href="https://github.com/asmeurer/blog/issues/18"&gt;here&lt;/a&gt; is the issue corresponding
to this post.&lt;/p&gt;
&lt;p&gt;I didn't like Disqus mostly because it serves ads and tracking. Even though I
had opted out from as much of it as I could in the Disqus settings, it still
loads tracking scripts on every page. I run &lt;a href="https://github.com/gorhill/uBlock"&gt;uBlock
Origin&lt;/a&gt; always, and it's a bit hypocritical
if my own side has things that are blocked by it. In some cases I can't avoid
it (as far as I know), like when I embed a YouTube video, but it definitely
shouldn't be on every post.&lt;/p&gt;
&lt;p&gt;Utterances is a very nice alternative. I has lots of advantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Comments are not self-hosted. GitHub hosts them. Since you need a GitHub
account to comment, this should make comment spam a non-issue.&lt;/li&gt;
&lt;li&gt;Comments support full Markdown.&lt;/li&gt;
&lt;li&gt;Users can edit their comments.&lt;/li&gt;
&lt;li&gt;I can edit and fully moderate all comments.&lt;/li&gt;
&lt;li&gt;Users log in with a federated system that proves their identity.&lt;/li&gt;
&lt;li&gt;Email subscription to posts.&lt;/li&gt;
&lt;li&gt;No ads or tracking.&lt;/li&gt;
&lt;li&gt;It's completely open source and free to use.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you use &lt;a href="https://getnikola.com/"&gt;Nikola&lt;/a&gt; like I do, it &lt;a href="https://getnikola.com/handbook.html#comments"&gt;natively supports
Utterances&lt;/a&gt; (a feature which I
added). Otherwise, go to the &lt;a href="https://utteranc.es/"&gt;Utterances&lt;/a&gt; and paste the
script tag generated at the bottom into your blog template. Then install the
&lt;a href="https://github.com/apps/utterances"&gt;Utterances app&lt;/a&gt; in your repo, and you are
done.&lt;/p&gt;
&lt;h3&gt;Exporting Disqus Comments&lt;/h3&gt;
&lt;p&gt;Some of my old posts had Disqus comments, which I wanted to preserve somehow.
Here is guide on how I did that, since it wasn't as straightforward as I would
have hoped.&lt;/p&gt;
&lt;p&gt;The first step is to export your Disqus comments. It's very difficult to
actually find the place in the Disqus site where you do this, but I finally
found the &lt;a href="https://disqus.com/admin/discussions/export/"&gt;URL&lt;/a&gt;. The export takes
some time to complete (for me it took about half an hour). When it finished,
Disqus will email you an XML file with all your comments. Note that the file
contains all comments for all sites you have ever set up with Disqus. For me,
it also included all the comments on my old &lt;a href="http://asmeurersympy.wordpress.com/"&gt;Wordpress
blog&lt;/a&gt;, as well as posts for draft blog
posts that I never ended up publishing. It also contained all comments that
were marked as spam, so you will need to remember to filter those.&lt;/p&gt;
&lt;p&gt;I decided that since I only have a handful of posts with Disqus comments, I
would just write a script to process them all and manually print them out,
which I will then manually enter in to the Utterances comment system for those
posts.&lt;/p&gt;
&lt;p&gt;I wrote a script to process the comments, which you can find
&lt;a href="https://github.com/asmeurer/blog/blob/master/disqus-comments/export_disqus_comments.py"&gt;here&lt;/a&gt;.
Disqus does provides an &lt;a href="https://disqus.com/api/schemas/1.0/disqus.xsd"&gt;XML
schema&lt;/a&gt; for the XML. I used a
library called &lt;a href="https://xsdata.readthedocs.io/en/latest/index.html"&gt;xsData&lt;/a&gt;,
which lets you take an XML scheme and generate Python dataclasses
corresponding to it, which make manipulating the parsed XML much easier than
the standard library xml library. The script outputs text like&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-markdown"&gt;========== Comments from https://asmeurer.github.io/blog/posts/what-happens-when-you-mess-with-hashing-in-python/ ==========

These are the original comments on this post that were made when this blog used the [Disqus blog system](https://www.asmeurer.com/blog/posts/switching-to-utterances-comments/).

&amp;gt;**Comment from bjd2385 on 2016-08-28 12:33:12+00:00:**

&amp;gt;&amp;lt;p&amp;gt;Very interesting post. I was just looking into hash functions (I've never formally learned what the topic entails), and since I'm most familiar with Python this post explained quite a bit, especially your early mathematical points.&amp;lt;/p&amp;gt;

&amp;gt;**Comment from Mark Lawrence on 2016-10-03 20:26:54+00:00:**

&amp;gt;&amp;lt;p&amp;gt;At what point does Python 3 force the override of __hash__ if you've defined __eq__?  E.g when would your&amp;lt;/p&amp;gt;&amp;lt;p&amp;gt;AlwaysEqual class fail?&amp;lt;/p&amp;gt;

&amp;gt;**Replies:**

&amp;gt;&amp;gt;**Comment from asmeurer on 2016-10-03 20:38:13+00:00:**

&amp;gt;&amp;gt;&amp;lt;p&amp;gt;That's a good catch. I originally wrote this post in Python 2. The example does indeed fail in Python 3. More specifically, if you override __eq__, Python 3 automatically sets __hash__ to None. I'll update the post to make this more clear.&amp;lt;/p&amp;gt;

&amp;gt;**Comment from Erick Mendon&amp;#231;a on 2017-07-30 03:23:55+00:00:**

&amp;gt;&amp;lt;p&amp;gt;Great article! We must really pay attention to these details when implementing custom hashes.&amp;lt;/p&amp;gt;

&amp;gt;**Comment from Ignacio on 2017-10-07 22:31:56+00:00:**

&amp;gt;&amp;lt;p&amp;gt;Thanks a lot for this post! Clarified a lot of concepts.&amp;lt;/p&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which I then manually copied to each post's Utterances page on GitHub.&lt;/p&gt;
&lt;p&gt;Feel free to adapt &lt;a href="https://github.com/asmeurer/blog/blob/master/disqus-comments/export_disqus_comments.py"&gt;my
script&lt;/a&gt;
if you find yourself in a similar situation.&lt;/p&gt;
&lt;h3&gt;Utterances Comments&lt;/h3&gt;
&lt;p&gt;Feel free to use the comments on this page to play around with the commenting
system.&lt;/p&gt;
&lt;p&gt;Note that to comment, there are two options. You can log in on this page,
which will let you type your comment in the box below. This requires giving
the Utterances bot access to your GitHub account. Alternately, if you don't
want to give a bot access, you can just go directly to the GitHub issue page
and comment there. I am currently in the process of figuring out how to add
some boilerplate to each page that makes this clear (see &lt;a href="https://github.com/utterance/utterances/issues/355"&gt;this Utterances
issue&lt;/a&gt;). If anyone has any
suggestions on how to do this, let me know. For now, I am just going to
manually add a statement about this as the first comment on each post.&lt;/p&gt;&lt;/div&gt;</description>
    </item>
    <item>
      <guid isPermaLink="false">https://iamit.in/blog/upgrading-sympy-gamma</guid>
      <author>Amit Kumar (aktech)</author>
      <title>Amit Kumar (aktech): Porting SymPy Gamma to Google App Engine Python 3</title>
      <pubDate>Fri, 30 Oct 2020 18:30:00 GMT</pubDate>
      <link>https://iamit.in/blog/sympy-gamma-gae-python3/</link>
      <description>&lt;p&gt;This summer I had plenty of time during COVID-19 lockdown and I was looking at
&lt;a href="https://sympygamma.com/"&gt;SymPy Gamma&lt;/a&gt;.&lt;/p&gt;

&lt;center&gt;&lt;img src="https://iamit.in/assets/sympy-gamma-port/sympy_gamma_demo.gif" width="700" /&gt;&lt;/center&gt;

&lt;h2 id="sympy-gamma"&gt;Sympy Gamma&lt;/h2&gt;

&lt;p&gt;SymPy Gamma is a web application that executes mathematical expressions
via natural language input from the user, after parsing them as SymPy
expressions it displays the result with additional related computations.
It is inspired from the idea of &lt;a href="http://www.wolframalpha.com/"&gt;WolframAlpha&lt;/a&gt; which is based on the
commercial Computer Algebra System named &lt;a href="https://en.wikipedia.org/wiki/Mathematica"&gt;&amp;#8220;Mathematica&amp;#8221;&lt;/a&gt;.&lt;/p&gt;

&lt;center&gt;&lt;img src="https://iamit.in/assets/wolfram-alpha-logo.svg" width="300" /&gt;&lt;/center&gt;

&lt;p&gt;I have always been impressed by it ever since I first found about it.
While playing with it during this summer, I realised that it runs on Google
App Engine&amp;#8217;s Python 2.7 runtime. It is powered by SymPy, an open source
computer algebra system.&lt;/p&gt;

&lt;center&gt;&lt;img align="center" src="https://iamit.in/assets/Sympy_logo.svg" width="150" /&gt;&lt;/center&gt;

&lt;h2 id="the-problem"&gt;The Problem&lt;/h2&gt;

&lt;p&gt;Despite being widely used around the world (about ~14K users everyday,
as seen from Google Analytics), there hasn&amp;#8217;t been a lot of development
in the past 5 years. Due to this the current infrastructure
was stuck on &lt;a href="https://en.wikipedia.org/wiki/Google_App_Engine"&gt;Google App Engine&lt;/a&gt;&amp;#8217;s Python 2 runtime which obviously does
not support Python 3.&lt;/p&gt;

&lt;p&gt;This also prevented it to use the latest version of SymPy. The SymPy
version (~0.7.6) it was using was last updated 6 years ago. This made
SymPy Gamma in urgent need for upgradation. At the time of writing this blog,
SymPy Gamma is running on Google App Engine&amp;#8217;s latest runtime and latest
version of SymPy.&lt;/p&gt;

&lt;h2 id="solution-and-process"&gt;Solution and Process&lt;/h2&gt;

&lt;p&gt;It was a fun project and was interesting to see how Google cloud offering has evolved
from Google App Engine to Google Cloud Platform. The old App engine did
seem like a minimal cloud offering launched by Google in an attempt to
ship something early and quickly. It reminded me of my first cloud project
in college (&lt;a href="https://github.com/aktech/dturmscrap"&gt;dturmscrap&lt;/a&gt;), which I
deployed to Google App Engine, back in 2015.&lt;/p&gt;

&lt;p&gt;I used Github projects to track the whole project, all the work done for this
can be seen &lt;a href="https://github.com/sympy/sympy_gamma/projects/1"&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id="-git-log"&gt;$ Git Log&lt;/h2&gt;

&lt;p&gt;Here is a summary of what was achieved:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href="https://github.com/sympy/sympy_gamma/pull/135"&gt;PR 135&lt;/a&gt;: Migrating Django to a slightly higher version,
this was the first blood just to make sure everything was working. I upgraded it to the latest version of
Django that was supported on Python 2 runtime. This also exposed the broken CI, which was fixed in this.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href="https://github.com/sympy/sympy_gamma/pull/137"&gt;PR 137&lt;/a&gt;: This upgraded the CI infrastructure to use Google Cloud SDK
for deployment, the previous method was discontinued.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href="https://github.com/sympy/sympy_gamma/pull/140"&gt;PR 140&lt;/a&gt;: Upgrading the Database backend to use Cloud NDB instead
of the legacy App Engine NDB.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href="https://github.com/sympy/sympy_gamma/pull/148"&gt;PR 148&lt;/a&gt;: Since we change the database backend, we needed something for
testing locally, this was done by using Google Cloud Datastore emulator locally.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href="https://github.com/sympy/sympy_gamma/pull/149"&gt;PR 149&lt;/a&gt;: The installation and setup of the project was quite a challenge.
Installing and keeping track of the versions of a number of application was non-trivial. This Pull request dockerized
the project and made the development setup trivial and it all boiled down to just one command.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href="https://github.com/sympy/sympy_gamma/pull/152"&gt;PR 152&lt;/a&gt;: The login feature was previously implemented using the user API
of the Google App Engine&amp;#8217;s Python2 runtime, which was not available in Python 3 runtime. We removed the login feature as it
was not used by many and was too much effort to setup OAuth for login.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href="https://github.com/sympy/sympy_gamma/pull/153"&gt;PR 153&lt;/a&gt;: Now was the time to slowly move towards Python 3 by making the
code compatible with both 2 and 3. It was achieved via &lt;a href="https://python-modernize.readthedocs.io/en/latest/"&gt;python-modernize&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href="https://github.com/sympy/sympy_gamma/pull/154"&gt;PR 154&lt;/a&gt;: We then made the migration to Python 3.7 runtime and removed submodules
and introduced a &lt;code class="language-plaintext highlighter-rouge"&gt;requirements.txt&lt;/code&gt; for installing dependencies.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href="https://github.com/sympy/sympy_gamma/pull/154"&gt;PR 159&lt;/a&gt;: The above change made it possible to upgrade SymPy to latest version,
which was 1.6 at that time.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href="https://github.com/sympy/sympy_gamma/pull/154"&gt;PR 165&lt;/a&gt;: The last piece of the puzzle was upgrading Django itself, so we upgraded
it to the latest version, which was Django 3.0.8.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id="next-steps"&gt;Next Steps&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;At the time of writing this Google has released the Python 3.8 runtime, it would nice to further upgrade it now.&lt;/li&gt;
  &lt;li&gt;The test coverage can be increased.&lt;/li&gt;
  &lt;li&gt;The code can be refactored to be more readable and approachable for new contributors.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Thanks to Google for properly &lt;a href="https://cloud.google.com/appengine/docs/standard/python/migrate-to-python3"&gt;documenting the process&lt;/a&gt;,
which made the transition much easier.&lt;/p&gt;

&lt;p&gt;Thanks to &lt;a href="https://numfocus.org/"&gt;NumFocus&lt;/a&gt;, without them this project would not have been possible. Also thanks to
&lt;a href="https://github.com/certik"&gt;Ondrej Certik&lt;/a&gt; and &lt;a href="http://github.com/asmeurer"&gt;Aaron Meurer&lt;/a&gt; for their advice and support
throughout the project.&lt;/p&gt;</description>
    </item>
    <item>
      <guid isPermaLink="false">https://asmeurer.com/blog/posts/verifying-the-riemann-hypothesis-with-sympy-and-mpmath/</guid>
      <author>Aaron Meurer (asmeurer)</author>
      <title>Aaron Meurer (asmeurer): Verifying the Riemann Hypothesis with SymPy and mpmath</title>
      <pubDate>Tue, 31 Mar 2020 21:12:54 GMT</pubDate>
      <link>https://asmeurer.com/blog/posts/verifying-the-riemann-hypothesis-with-sympy-and-mpmath/</link>
      <description>&lt;div&gt;&lt;p&gt;Like most people, I've had a lot of free time recently, and I've spent some of
it watching various YouTube videos about the &lt;a href="https://en.wikipedia.org/wiki/Riemann_hypothesis"&gt;Riemann
Hypothesis&lt;/a&gt;. I've collected
the videos I've watched into &lt;a href="https://www.youtube.com/playlist?list=PLrFrByaoJbcqKjzgJvLs2-spSmzP7jolT"&gt;YouTube
playlist&lt;/a&gt;.
The playlist is sorted with the most mathematically approachable videos first,
so even if you haven't studied complex analysis before, you can watch the
first few. If you have studied complex analysis, all the videos will be within
your reach (none of them are highly technical with proofs). Each video
contains parts that aren't in any of the other videos, so you will get
something out of watching each of them.&lt;/p&gt;
&lt;p&gt;One of the &lt;a href="https://www.youtube.com/watch?v=lyf9W2PWm40&amp;amp;list=PLrFrByaoJbcqKjzgJvLs2-spSmzP7jolT&amp;amp;index=8"&gt;videos near the end of the
playlist&lt;/a&gt;
is a lecture by Keith Conrad. In it, he mentioned a method by which one could
go about verifying the Riemann Hypothesis with a computer. I wanted to see if
I could do this with SymPy and mpmath. It turns out you can.&lt;/p&gt;
&lt;h2&gt;Background Mathematics&lt;/h2&gt;
&lt;h3&gt;Euler's Product Formula&lt;/h3&gt;
&lt;p&gt;Before we get to the computations, let's go over some mathematical background.
As you may know, the Riemann Hypothesis is one of the 7 &lt;a href="https://en.wikipedia.org/wiki/Millennium_Prize_Problems"&gt;Millennium Prize
Problems&lt;/a&gt; outlined by
the Clay Mathematics Institute in 2000. The problems have gained some fame
because each problem comes with a $1,000,000 prize if solved. One problem, the
&lt;a href="https://en.wikipedia.org/wiki/Poincar%C3%A9_conjecture"&gt;Poincar&amp;#233; conjecture&lt;/a&gt;,
has already been solved (Grigori Perelman who solved it turned down the 1
million dollar prize). The remainder remain unsolved.&lt;/p&gt;
&lt;p&gt;The Riemann Hypothesis is one of the most famous of these problems. The reason
for this is that the problem is central many open questions in number theory.
There are hundreds of theorems which are only known to be true contingent on
the Riemann Hypothesis, meaning that if the Riemann Hypothesis were proven,
immediately hundreds of theorems would be proven as well. Also, unlike some
other Millennium Prize problems, like P=NP, the Riemann Hypothesis is almost
universally believed to be true by mathematicians. So it's not a question of
whether or not it is true, just one of how to actually prove it. The problem
has been open for over 160 years, and while many advances have been made, no
one has yet come up with a proof of it (crackpot proofs aside).&lt;/p&gt;
&lt;p&gt;To understand the statement of the hypothesis, we must first define the zeta
function. Let&lt;/p&gt;
&lt;p&gt;$$\zeta(s) = \sum_{n=1}^\infty \frac{1}{n^s}$$&lt;/p&gt;
&lt;p&gt;(that squiggle $\zeta$ is the lowercase Greek letter zeta). This expression
makes sense if $s$ is an integer greater than or equal to 2, $s=2, 3, 4, \ldots$,
since we know from simple arguments from calculus that the summation converges
in those cases (it isn't important for us what those values are, only that the
summation converges). The story begins with Euler, who in 1740 considered the
following infinite product:&lt;/p&gt;
&lt;p&gt;$$\prod_{\text{$p$ prime}}\frac{1}{1 -
\frac{1}{p^s}}.$$&lt;/p&gt;
&lt;p&gt;The product ranges over all prime numbers, i.e., it is
$$\left(\frac{1}{1 - \frac{1}{2^s}}\right)\cdot\left(\frac{1}{1 -
\frac{1}{3^s}}\right)\cdot\left(\frac{1}{1 - \frac{1}{5^s}}\right)\cdots.$$
The fraction $\frac{1}{1 - \frac{1}{p}}$ may seem odd at first, but consider
the famous geometric series formula, $$\sum_{k=0}^\infty r^k = \frac{1}{1 -
r},$$ which is true for $|r| &amp;lt; 1$. Our fraction is exactly of this form, with
$r = \frac{1}{p^s}$. So substituting, we have&lt;/p&gt;
&lt;p&gt;$$\prod_{\text{$p$ prime}}\frac{1}{1 - \frac{1}{p^s}} =
\prod_{\text{$p$ prime}}\sum_{k=0}^\infty \left(\frac{1}{p^s}\right)^k =
\prod_{\text{$p$ prime}}\sum_{k=0}^\infty \left(\frac{1}{p^k}\right)^s.$$&lt;/p&gt;
&lt;p&gt;Let's take a closer look at what this is. It is&lt;/p&gt;
&lt;p&gt;$$\left(1 + \frac{1}{p_1^s} + \frac{1}{p_1^{2s}} + \frac{1}{p_1^{3s}} +
\cdots\right)\cdot\left(1 + \frac{1}{p_2^s} + \frac{1}{p_2^{2s}} +
\frac{1}{p_2^{3s}} + \cdots\right)\cdot\left(1 + \frac{1}{p_3^s} + \frac{1}{p_3^{2s}} +
\frac{1}{p_3^{3s}} + \cdots\right)\cdots,$$&lt;/p&gt;
&lt;p&gt;where $p_1$ is the first prime, $p_2$ is the second prime, and so on. Now
think about how to expand finite products of finite sums, for instance,
$$(x_1 + x_2 + x_3)(y_1 + y_2 + y_3)(z_1 + z_2 + z_3).$$ To expand the above,
you would take a sum of every combination where you pick one $x$ term, one $y$
term, and one $z$ term, giving&lt;/p&gt;
&lt;p&gt;$$x_1y_1z_1 + x_1y_1z_2 + \cdots + x_2y_1z_3 + \cdots + x_3y_2z_1 + \cdots + x_3y_3z_3.$$&lt;/p&gt;
&lt;p&gt;So to expand the infinite product, we do the same thing. We take every
combination of picking $1/p_i^{ks}$, with one $k$ for each $i$. If we pick
infinitely many non-$1$ powers, the product will be zero, so we only need to
consider terms where there are finitely many primes. The resulting sum will be
something like&lt;/p&gt;
&lt;p&gt;$$\frac{1}{1^s} + \frac{1}{p_1^s} + \frac{1}{p_2^s} + \frac{1}{\left(p_1^2\right)^s} +
\frac{1}{p_3^s} + \frac{1}{\left(p_1p_2\right)^s} + \cdots,$$&lt;/p&gt;
&lt;p&gt;where each prime power combination is picked exactly once. However, we know by
the &lt;a href="https://en.wikipedia.org/wiki/Fundamental_theorem_of_arithmetic"&gt;Fundamental Theorem of
Arithmetic&lt;/a&gt;
that when you take all combinations of products of primes that you get each
positive integer exactly once. So the above sum is just&lt;/p&gt;
&lt;p&gt;$$\frac{1}{1^s} + \frac{1}{2^s} + \frac{1}{3^s} + \cdots,$$ which is just
$\zeta(s)$ as we defined it above.&lt;/p&gt;
&lt;p&gt;In other words,&lt;/p&gt;
&lt;p&gt;$$\zeta(s) = \sum_{n=1}^\infty \frac{1}{n^s} = \prod_{\text{$p$
prime}}\frac{1}{1 - \frac{1}{p^s}},$$ for $s = 2, 3, 4, \ldots$. This is known
as Euler's product formula for the zeta function. Euler's product formula
gives us our first clue as to why the zeta function can give us insights into
prime numbers.&lt;/p&gt;
&lt;h3&gt;Analytic Continuation&lt;/h3&gt;
&lt;p&gt;In 1859, Bernhard Riemann wrote a &lt;a href="https://en.wikipedia.org/wiki/On_the_Number_of_Primes_Less_Than_a_Given_Magnitude"&gt;short 9 page paper on number theory and the
zeta
function&lt;/a&gt;.
It was the only paper Riemann ever wrote on the subject of number theory, but
it is undoubtedly one of the most important papers every written on the
subject.&lt;/p&gt;
&lt;p&gt;In the paper, Riemann considered that the zeta function summation,&lt;/p&gt;
&lt;p&gt;$$\zeta(s) = \sum_{n=1}^\infty \frac{1}{n^s},$$&lt;/p&gt;
&lt;p&gt;makes sense not just for integers $s = 2, 3, 4, \ldots$, but for any real
number $s &amp;gt; 1$ (if $s = 1$, the summation is the &lt;a href="https://en.wikipedia.org/wiki/Harmonic_series_(mathematics)"&gt;harmonic
series&lt;/a&gt;, which
famously diverges). In fact, it is not hard to see that for complex $s$, the
summation makes sense so long as $\mathrm{Re}(s) &amp;gt; 1$ (for more about what it
even means for $s$ to be complex in that formula, and the basic ideas of
analytic continuation, I recommend &lt;a href="https://www.youtube.com/watch?v=sD0NjbwqlYw&amp;amp;list=PLrFrByaoJbcqKjzgJvLs2-spSmzP7jolT&amp;amp;index=3"&gt;3Blue1Brown's
video&lt;/a&gt;
from my YouTube playlist).&lt;/p&gt;
&lt;p&gt;Riemann wanted to extend this function to the entire complex plane, not just
$\mathrm{Re}(s) &amp;gt; 1$. The process of doing this is called &lt;a href="https://en.wikipedia.org/wiki/Analytic_continuation"&gt;analytic
continuation&lt;/a&gt;. The theory
of complex analysis tells us that if we can find an extension of $\zeta(s)$ to
the whole complex plan that remains differentiable, then that extension is
unique, and we can reasonably say that that &lt;em&gt;is&lt;/em&gt; the definition of the
function everywhere.&lt;/p&gt;
&lt;p&gt;Riemann used the following approach. Consider what we might call the
"completed zeta function"&lt;/p&gt;
&lt;p&gt;$$Z(s) = \pi^{-\frac{s}{2}}\Gamma\left(\frac{s}{2}\right)\zeta(s).$$&lt;/p&gt;
&lt;p&gt;Using Fourier analysis, Riemann gave a formula for $Z(s)$ that is defined
everywhere, allowing us to use it to define $\zeta(s)$ to the left of 1. I
won't repeat Riemann's formula for $Z(s)$ as the exact formula isn't
important, but from it one could also see&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;$Z(s)$ is defined everywhere in the complex plane, except for simple poles at 0
and 1.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$Z(s) = Z(1 - s).$ This means if we have a value for $s$ that is right of
the line $\mathrm{Re}(z) = \frac{1}{2},$ we can get a value to the left of
it by reflecting it over the real-axis and the line at $\frac{1}{2}$ (to
see this, note that the average of $s$ and $1 - s$ is $1/2$, so the
midpoint of a line connecting the two should always go through the point
$1/2$).&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;img alt="Reflection of s and 1 - s" src="https://asmeurer.com/blog/s-and-1-s.svg" width="608" /&gt;
&lt;p&gt;(Reflection of $s$ and $1 - s$. Created with
&lt;a href="https://www.geogebra.org/graphing/c9rzy9hj"&gt;Geogebra&lt;/a&gt;)&lt;/p&gt;
&lt;h3&gt;Zeros&lt;/h3&gt;
&lt;p&gt;Looking at $Z(s)$, it is a product of three parts. So the zeros and poles of
$Z(s)$ correspond to the zeros and poles of these parts, unless they cancel.
$\pi^{-\frac{s}{2}}$ is the easiest: it has no zeros and no poles. The second
part is the &lt;a href="https://en.wikipedia.org/wiki/Gamma_function"&gt;gamma function&lt;/a&gt;.
$\Gamma(z)$ has no zeros and has simple poles at nonpositive integers $z=0,
-1, -2, \ldots$.&lt;/p&gt;
&lt;p&gt;So taking this, along with the fact that $Z(s)$ is entire except for simple
poles at 0 and 1, we get from $$\zeta(s) =
\frac{Z(s)}{\pi^{-\frac{s}{2}}\Gamma\left(\frac{s}{2}\right)}$$&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;$Z(s)$ has a simple pole at 1, which means that $\zeta(s)$ does as well.
This is not surprising, since we already know the summation formula from
above diverges as $s$ approaches 1.&lt;/li&gt;
&lt;li&gt;$Z(s)$ has a simple pole at 0. Since $\Gamma\left(\frac{s}{2}\right)$ also
has a simple pole at 0, they must cancel and $\zeta(s)$ must have neither a
zero nor a pole at 0 (in fact, $\zeta(0) = -1/2$).&lt;/li&gt;
&lt;li&gt;Since $\Gamma\left(\frac{s}{2}\right)$ has no zeros, there are no further
poles of $\zeta(s)$. Thus, $\zeta(s)$ is entire everywhere except for a
simple pole at $s=1$.&lt;/li&gt;
&lt;li&gt;$\Gamma\left(\frac{s}{2}\right)$ has poles at the remaining negative even
integers. Since $Z(s)$ has no poles there, these must correspond to zeros
of $\zeta(s)$. These are the so-called "trivial" zeros of the zeta
function, at $s=-2, -4, -6, \ldots$. The term "trivial" here is a relative
one. They are trivial to see from the above formula, whereas other zeros of
$\zeta(s)$ are much harder to find.&lt;/li&gt;
&lt;li&gt;$\zeta(s) \neq 0$ if $\mathrm{Re}(s) &amp;gt; 1$. One way to see this is from the
Euler product formula. Since each term in the product is not zero, the
function itself cannot be zero (this is a bit hand-wavy, but it can be made
rigorous). This implies that $Z(s) \neq 0$ in this region as well. We can
reflect $\mathrm{Re}(s) &amp;gt; 1$ over the line at $\frac{1}{2}$ by considering
$\zeta(1 - s)$. Using the above formula and the fact that $Z(s) = Z(1 -
s)$, we see that $\zeta(s)$ cannot be zero for $\mathrm{Re}(s) &amp;lt; 0$ either,
with the exception of the aforementioned trivial zeros at $s=-2, -4, -6,
\ldots$.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Thus, any non-trivial zeros of $\zeta(s)$ must have real part between 0 and 1.
This is the so-called "critical strip". Riemann hypothesized that these zeros
are not only between 0 and 1, but are in fact on the line dividing the strip
at real part equal to $1/2$. This line is called the "critical line". This is
Riemann's famous hypothesis: that all the non-trivial zeros of $\zeta(s)$ have
real part equal to $1/2$.&lt;/p&gt;
&lt;h3&gt;Computational Verification&lt;/h3&gt;
&lt;p&gt;Whenever you have a mathematical hypothesis, it is good to check if it is true
numerically. Riemann himself used some methods (not the same ones we use here)
to numerically estimate the first few non-trivial zeros of $\zeta(s)$, and
found that they lied on the critical line, hence the motivation for his
hypothesis. Here is an &lt;a href="https://www.maths.tcd.ie/pub/HistMath/People/Riemann/Zeta/EZeta.pdf"&gt;English
translation&lt;/a&gt;
of his original paper if you are interested.&lt;/p&gt;
&lt;p&gt;If we verified that all the zeros in the critical strip from, say,
$\mathrm{Im}(s) = 0$ to $\mathrm{Im}(s) = N$ are in fact on the critical line
for some large $N$, then it would give evidence that the Riemann Hypothesis is
true. However, to be sure, this would not constitute a proof.
&lt;a href="https://en.wikipedia.org/wiki/G._H._Hardy"&gt;Hardy&lt;/a&gt; showed in 1914 that
$\zeta(s)$ has infinitely many zeros on the critical strip, so only finding
finitely many of them would not suffice as a proof. (Although if we were to
find a counter-example, a zero &lt;em&gt;not&lt;/em&gt; on the critical line, that WOULD
constitute a proof that the Hypothesis is false. However, there are strong
reasons to believe that the hypothesis is not false, so this would be unlikely
to happen.)&lt;/p&gt;
&lt;p&gt;How would we verify that the zeros are all on the line $1/2$. We can find
zeros of $\zeta(s)$ numerically, but how would we know if the real part is
really exactly 0.5 and not 0.500000000000000000000000000000000001? And more
importantly, just because we find some zeros, it doesn't mean that we have all
of them. Maybe we can find a bunch of zeros on the critical line, but how
would we be sure that there aren't other zeros lurking around elsewhere on the
critical strip?&lt;/p&gt;
&lt;p&gt;We want to find rigorous answers to these two questions:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;How can we count the number of zeros between $\mathrm{Im}(s) = 0$ and
$\mathrm{Im}(s) = N$ of $\zeta(s)$?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;How can we verify that all those zeros lie on the critical line, that is,
they have real part equal to exactly $1/2$?&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;Counting Zeros Part 1&lt;/h4&gt;
&lt;p&gt;To answer the first question, we can make use of a powerful theorem from
complex analysis called the &lt;a href="https://en.wikipedia.org/wiki/Argument_principle#Generalized_argument_principle"&gt;argument
principle&lt;/a&gt;.
The argument principle says that if $f$ is a meromorphic function on some
closed contour $C$, and does not have any zeros or poles on $C$ itself, then&lt;/p&gt;
&lt;p&gt;$$\frac{1}{2\pi i}\oint_C \frac{f'(z)}{f(z)}\,dz = \#\left\{\text{zeros of $f$
inside of C}\right\} - \#\left\{\text{poles of $f$
inside of C}\right\},$$ where all zeros and poles are counted with
multiplicity.&lt;/p&gt;
&lt;p&gt;In other words, the integral on the left-hand side counts the number of zeros
of $f$ minus the number of poles of $f$ in a region. The argument principle is
quite easy to show given the Cauchy residue theorem (see the above linked
Wikipedia article for a proof). The expression $f'(z)/f(z)$ is called the
"&lt;a href="https://en.wikipedia.org/wiki/Logarithmic_derivative"&gt;logarithmic
derivative&lt;/a&gt; of $f$",
because it equals $\frac{d}{dz} \log(f(z))$ (although it makes sense even without
defining what "$\log$" means).&lt;/p&gt;
&lt;p&gt;One should take a moment to appreciate the beauty of this result. The
left-hand side is an integral, something we generally think of as being a
continuous quantity. But it is always exactly equal to an integer. Results
such as these give us a further glimpse at how analytic functions and complex
analysis can produce theorems about number theory, a field which one would
naively think can only be studied via discrete means. In fact, these methods
are far more powerful than discrete methods. For many results in number
theory, we only know how to prove them using complex analytic means. So-called
&lt;a href="https://en.wikipedia.org/wiki/Elementary_proof"&gt;"elementary" proofs&lt;/a&gt; for
these results, or proofs that only use discrete methods and do not use complex
analysis, have not yet been found.&lt;/p&gt;
&lt;p&gt;Practically speaking, the fact that the above integral is exactly an integer
means that if we compute it numerically and it comes out to something like
0.9999999, we know that it must in fact equal exactly 1. So as long as we get
a result that is near an integer, we can round it to the exact answer.&lt;/p&gt;
&lt;p&gt;We can integrate a contour along the critical strip up to some $\mathrm{Im}(s)
= N$ to count the number of zeros up to $N$ (we have to make sure to account
for the poles. I go into more details about this when I actually compute the
integral below).&lt;/p&gt;
&lt;h4&gt;Counting Zeros Part 2&lt;/h4&gt;
&lt;p&gt;So using the argument principle, we can count the number of zeros in a region.
Now how can we verify that they all lie on the critical line? The answer lies
in the $Z(s)$ function defined above. By the points outlined in the previous
section, we can see that $Z(s)$ is zero exactly where $\zeta(s)$ is zero on
the critical strip, and it is not zero anywhere else. In other words,&lt;/p&gt;
&lt;div style="text-align: center;"&gt; &lt;b&gt;the zeros of $Z(s)$ are exactly the non-trivial zeros of $\zeta(s)$.&lt;/b&gt;&lt;/div&gt;
&lt;p&gt;This helps us because $Z(s)$ has a nice property on the critical line. First
we note that $Z(s)$ commutes with conjugation, that is $\overline{Z(s)} =
Z(\overline{s})$ (this isn't obvious from what I have shown, but it is true).
On the critical line $\frac{1}{2} + it$, we have&lt;/p&gt;
&lt;p&gt;$$\overline{Z\left(\frac{1}{2} + it\right)} = Z\left(\overline{\frac{1}{2} +
it}\right) = Z\left(\frac{1}{2} - it\right).$$&lt;/p&gt;
&lt;p&gt;However, $Z(s) = Z(1 - s)$, and $1 - \left(\frac{1}{2} - it\right) =
\frac{1}{2} + it$, so&lt;/p&gt;
&lt;p&gt;$$\overline{Z\left(\frac{1}{2} + it\right)} = Z\left(\frac{1}{2} +
it\right),$$&lt;/p&gt;
&lt;p&gt;which means that $Z\left(\frac{1}{2} + it\right)$ is real valued for real $t$.&lt;/p&gt;
&lt;p&gt;This simplifies things a lot, because it is much easier to find zeros of a real
function. In fact, we don't even care about finding the zeros, only counting
them. Since $Z(s)$ is continuous, we can use a simple method: counting sign
changes. If a continuous real function changes signs from negative to positive or from
positive to negative n times in an interval, then it must have at least n
zeros in that interval. It may have more, for instance, if some zeros are
clustered close together, or if a zero has a multiplicity greater than 1, but
we know that there must be at least n.&lt;/p&gt;
&lt;p&gt;So our approach to verifying the Riemann Hypothesis is as such:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Integrate $\frac{1}{2\pi i}\oint_C Z'(s)/Z(s)\,ds$ along a contour $C$
that runs along the critical strip up to some $\mathrm{Im}(s) = N$. The
integral will tell us there are exactly $n$ zeros in the contour, counting
multiplicity.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Try to find $n$ sign changes of $Z(1/2 + it)$ for $t\in [0, N]$. If we can
find $n$ of them, we are done. We have confirmed all the zeros are on the
critical line.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Step 2 would fail if the Riemann Hypothesis is false, in which case a zero
wouldn't be on the critical line. But it would also fail if a zero has a
multiplicity greater than 1, since the integral would count it more times than
the sign changes. Fortunately, as it turns out, the Riemann Hypothesis has
been verified up to N = 10000000000000, and no one has yet found a zero of the
zeta function yet that has a multiplicity greater than 1, so we should not
expect that to happen (no one has yet found a counterexample to the Riemann
Hypothesis either).&lt;/p&gt;
&lt;h2&gt;Verification with SymPy and mpmath&lt;/h2&gt;
&lt;p&gt;We now use SymPy and mpmath to compute the above quantities. We use
&lt;a href="https://www.sympy.org/"&gt;SymPy&lt;/a&gt; to do symbolic manipulation for us, but the
heavy work is done by &lt;a href="http://mpmath.org/doc/current/index.html"&gt;mpmath&lt;/a&gt;.
mpmath is a pure Python library for arbitrary precision numerics. It is used
by SymPy under the hood, but it will be easier for us to use it directly. It
can do, among other things, numeric integration. When I first tried to do
this, I tried using the &lt;a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.zeta.html"&gt;&lt;code&gt;scipy.special&lt;/code&gt; zeta
function&lt;/a&gt;,
but unfortunately, it does not support complex arguments.&lt;/p&gt;
&lt;p&gt;First we do some basic imports&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; from sympy import *
&amp;gt;&amp;gt;&amp;gt; import mpmath
&amp;gt;&amp;gt;&amp;gt; import numpy as np
&amp;gt;&amp;gt;&amp;gt; import matplotlib.pyplot as plt
&amp;gt;&amp;gt;&amp;gt; s = symbols('s')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the completed zeta function $Z = \pi^{-s/2}\Gamma(s/2)\zeta(s)$.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; Z = pi**(-s/2)*gamma(s/2)*zeta(s)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can verify that Z is indeed real for $s = \frac{1}{2} + it.$&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; Z.subs(s, 1/2 + 0.5j).evalf()
-1.97702795164031 + 5.49690501450151e-17*I
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We get a small imaginary part due to the way floating point arithmetic works.
Since it is below &lt;code&gt;1e-15&lt;/code&gt;, we can safely ignore it.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;D&lt;/code&gt; will be the logarithmic derivative of &lt;code&gt;Z&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; D = simplify(Z.diff(s)/Z)
&amp;gt;&amp;gt;&amp;gt; D
polygamma(0, s/2)/2 - log(pi)/2 + Derivative(zeta(s), s)/zeta(s)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is $$\frac{\operatorname{polygamma}{\left(0,\frac{s}{2} \right)}}{2} -
\frac{\log{\left(\pi \right)}}{2} + \frac{
\zeta'\left(s\right)}{\zeta\left(s\right)}.$$&lt;/p&gt;
&lt;p&gt;Note that logarithmic derivatives behave similar to logarithms. The
logarithmic derivative of a product is the sum of logarithmic derivatives (the
$\operatorname{polygamma}$ function is the derivative of $\Gamma$).&lt;/p&gt;
&lt;p&gt;We now use
&lt;a href="https://docs.sympy.org/latest/modules/utilities/lambdify.html#sympy.utilities.lambdify.lambdify"&gt;&lt;code&gt;lambdify&lt;/code&gt;&lt;/a&gt;
to convert the SymPy expressions &lt;code&gt;Z&lt;/code&gt; and &lt;code&gt;D&lt;/code&gt; into functions that are evaluated
using mpmath. A technical difficulty here is that the derivative of the zeta
function $\zeta'(s)$ does not have a closed-form expression. &lt;a href="http://mpmath.org/doc/current/functions/zeta.html?highlight=zeta#mpmath.zeta"&gt;mpmath's &lt;code&gt;zeta&lt;/code&gt;
can evaluate
$\zeta'$&lt;/a&gt;
but it doesn't yet work with &lt;code&gt;sympy.lambdify&lt;/code&gt; (see &lt;a href="https://github.com/sympy/sympy/issues/11802"&gt;SymPy issue
11802&lt;/a&gt;). So we have to manually
define &lt;code&gt;"Derivative"&lt;/code&gt; in lambdify, knowing that it will be the derivative of
&lt;code&gt;zeta&lt;/code&gt; when it is called. Beware that this is only correct for this specific
expression where we know that &lt;code&gt;Derivative&lt;/code&gt; will be &lt;code&gt;Derivative(zeta(s), s)&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; Z_func = lambdify(s, Z, 'mpmath')
&amp;gt;&amp;gt;&amp;gt; D_func = lambdify(s, D, modules=['mpmath',
...     {'Derivative': lambda expr, z: mpmath.zeta(z, derivative=1)}])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now define a function to use the argument principle to count the number of
zeros up to $Ni$. Due to the symmetry $Z(s) = Z(1 - s)$, it is only necessary
to count zeros in the top half-plane.&lt;/p&gt;
&lt;p&gt;We have to be careful about the poles of $Z(s)$ at 0 and 1. We can either
integrate right above them, or expand the contour to include them. I chose to
do the former, starting at $0.1i$. It is known that there $\zeta(s)$ has no
zeros near the real axis on the critical strip. I could have also expanded the
contour to go around 0 and 1, and offset the result by 2 to account for the
integral counting those points as poles.&lt;/p&gt;
&lt;p&gt;It has also been shown that there are no zeros on the lines $\mathrm{Re}(s) =
0$ or $\mathrm{Re}(s) = 1$, so we do not need to worry about that. If the
upper point of our contour happens to have zeros exactly on it, we would be
very unlucky, but even if this were to happen we could just adjust it up a
little bit.&lt;/p&gt;
&lt;img alt="Our contour" src="https://asmeurer.com/blog/contour-c.svg" width="608" /&gt;
&lt;p&gt;(Our contour with $N=10$. Created with &lt;a href="https://www.geogebra.org/graphing/nmnsaywd"&gt;Geogebra&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;&lt;a href="http://mpmath.org/doc/current/calculus/integration.html#mpmath.quad"&gt;&lt;code&gt;mpmath.quad&lt;/code&gt;&lt;/a&gt;
can take a list of points to compute a contour. The &lt;code&gt;maxdegree&lt;/code&gt; parameter
allows us to increase the degree of the quadrature if it becomes necessary to
get an accurate result.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; def argument_count(func, N, maxdegree=6):
...     return 1/(2*mpmath.pi*1j)*(mpmath.quad(func,
...         [1 + 0.1j, 1 + N*1j, 0 + N*1j, 0 + 0.1j,  1 + 0.1j],
...         maxdegree=maxdegree))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let's test it. Lets count the zeros of $$s^2 - s + 1/2$$ in the box
bounded by the above rectangle ($N = 10$).&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; expr = s**2 - s + S(1)/2
&amp;gt;&amp;gt;&amp;gt; argument_count(lambdify(s, expr.diff(s)/expr), 10)
mpc(real='1.0', imag='3.4287545414000525e-24')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The integral is 1. We can confirm there is indeed one
zero in this box, at $\frac{1}{2} + \frac{i}{2}$.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; solve(s**2 - s + S(1)/2)
[1/2 - I/2, 1/2 + I/2]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now compute points of $Z$ along the critical line so we can count the sign
changes. We also make provisions in case we have to increase the precision of
mpmath to get correct results here. &lt;code&gt;dps&lt;/code&gt; is the number of digits of precision
the values are computed to. The default is 15, but mpmath can compute values
to any number of digits.
&lt;a href="http://mpmath.org/doc/current/general.html#chop"&gt;&lt;code&gt;mpmath.chop&lt;/code&gt;&lt;/a&gt; zeros out
values that are close to &lt;code&gt;0&lt;/code&gt;, which removes any numerically insignificant
imaginary parts that arise from the floating point evaluation.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; def compute_points(Z_func, N, npoints=10000, dps=15):
...     import warnings
...     old_dps = mpmath.mp.dps
...     points = np.linspace(0, N, npoints)
...     try:
...         mpmath.mp.dps = dps
...         L = [mpmath.chop(Z_func(i)) for i in 1/2 + points*1j]
...     finally:
...         mpmath.mp.dps = old_dps
...     if L[-1] == 0:
...         # mpmath will give 0 if the precision is not high enough, since Z
...         # decays rapidly on the critical line.
...         warnings.warn("You may need to increase the precision")
...     return L
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next define a function to count the number of sign changes in a list of real
values.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; def sign_changes(L):
...     """
...     Count the number of sign changes in L
...
...     Values of L should all be real.
...     """
...     changes = 0
...     assert im(L[0]) == 0, L[0]
...     s = sign(L[0])
...     for i in L[1:]:
...         assert im(i) == 0, i
...         s_ = sign(i)
...         if s_ == 0:
...             # Assume these got chopped to 0
...             continue
...         if s_ != s:
...             changes += 1
...         s = s_
...     return changes
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For example, for $\sin(s)$ from -10 to 10, there are 7 zeros ($3\pi\approx
9.42$).&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; sign_changes(lambdify(s, sin(s))(np.linspace(-10, 10)))
7
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can check how many zeros of $Z(s)$ (and hence non-trivial zeros of
$\zeta(s)$) we can find. According to
&lt;a href="https://en.wikipedia.org/wiki/Riemann_hypothesis"&gt;Wikipedia&lt;/a&gt;, the first few
non-trivial zeros of $\zeta(s)$ in the upper half-plane are 14.135, 21.022,
and 25.011.&lt;/p&gt;
&lt;p&gt;First try up to $N=20$.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; argument_count(D_func, 20)
mpc(real='0.99999931531867581', imag='-3.2332902529067346e-24')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Mathematically, the above value &lt;em&gt;must&lt;/em&gt; be an integer, so we know it is 1.&lt;/p&gt;
&lt;p&gt;Now check the number of sign changes of $Z(s)$ from $\frac{1}{2} + 0i$ to
$\frac{1}{2} + 20i$.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; L = compute_points(Z_func, 20)
&amp;gt;&amp;gt;&amp;gt; sign_changes(L)
1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So it checks out. There is one zero between $0$ and $20i$ on the critical
strip, and it is in fact on the critical line, as expected!&lt;/p&gt;
&lt;p&gt;Now let's verify the other two zeros from Wikipedia.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; argument_count(D_func, 25)
mpc(real='1.9961479945577916', imag='-3.2332902529067346e-24')
&amp;gt;&amp;gt;&amp;gt; L = compute_points(Z_func, 25)
&amp;gt;&amp;gt;&amp;gt; sign_changes(L)
2
&amp;gt;&amp;gt;&amp;gt; argument_count(D_func, 30)
mpc(real='2.9997317058520916', imag='-3.2332902529067346e-24')
&amp;gt;&amp;gt;&amp;gt; L = compute_points(Z_func, 30)
&amp;gt;&amp;gt;&amp;gt; sign_changes(L)
3
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Both check out as well.&lt;/p&gt;
&lt;p&gt;Since we are computing the points, we can go ahead and make a plot as well.
However, there is a technical difficulty. If you naively try to plot $Z(1/2 +
it)$, you will find that it decays rapidly, so fast that you cannot really
tell where it crosses 0:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; def plot_points_bad(L, N):
...     npoints = len(L)
...     points = np.linspace(0, N, npoints)
...     plt.figure()
...     plt.plot(points, L)
...     plt.plot(points, [0]*npoints, linestyle=':')
&amp;gt;&amp;gt;&amp;gt; plot_points_bad(L, 30)
&lt;/code&gt;&lt;/pre&gt;
&lt;img src="https://asmeurer.com/blog/riemann-bad.svg" width="608" /&gt;
&lt;p&gt;So instead of plotting $Z(1/2 + it)$, we plot $\log(|Z(1/2 + it)|)$. The
logarithm will make the zeros go to $-\infty$, but these will be easy to see.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; def plot_points(L, N):
...     npoints = len(L)
...     points = np.linspace(0, N, npoints)
...     p = [mpmath.log(abs(i)) for i in L]
...     plt.figure()
...     plt.plot(points, p)
...     plt.plot(points, [0]*npoints, linestyle=':')
&amp;gt;&amp;gt;&amp;gt; plot_points(L, 30)
&lt;/code&gt;&lt;/pre&gt;
&lt;img src="https://asmeurer.com/blog/riemann-30.svg" width="608" /&gt;
&lt;p&gt;The spikes downward are the zeros.&lt;/p&gt;
&lt;p&gt;Finally, let's check up to N=100. &lt;a href="https://oeis.org/A072080"&gt;OEIS A072080&lt;/a&gt;
gives the number of zeros of $\zeta(s)$ in upper half-plane up to $10^ni$.
According to it, we should get 29 zeros between $0$ and $100i$.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; argument_count(D_func, 100)
mpc(real='28.248036536895913', imag='-3.2332902529067346e-24')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is not near an integer. This means we need to increase the precision of
the quadrature (the &lt;code&gt;maxdegree&lt;/code&gt; argument).&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; argument_count(D_func, 100, maxdegree=9)
mpc(real='29.000000005970151', imag='-3.2332902529067346e-24')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And the sign changes...&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; L = compute_points(Z_func, 100)
__main__:11: UserWarning: You may need to increase the precision
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Our guard against the precision being too low was triggered. Try raising it
(the default dps is 15).&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; L = compute_points(Z_func, 100, dps=50)
&amp;gt;&amp;gt;&amp;gt; sign_changes(L)
29
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;They both give 29. So we have verified the Riemann Hypothesis up to $100i$!&lt;/p&gt;
&lt;p&gt;Here is a plot of these 29 zeros.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; plot_points(L, 100)
&lt;/code&gt;&lt;/pre&gt;
&lt;img src="https://asmeurer.com/blog/riemann-100.svg" width="608" /&gt;
&lt;p&gt;(remember that the spikes downward are the zeros)&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;$N=100$ takes a few minutes to compute, and I imagine larger and larger values
would require increasing the precision more, slowing it down even further, so
I didn't go higher than this. But it is clear that this method works.&lt;/p&gt;
&lt;p&gt;This was just me playing around with SymPy and mpmath, but if I wanted to
actually verify the Riemann Hypothesis, I would try to find a more efficient
method of computing the above quantities. For the sake of simplicity, I used
$Z(s)$ for both the argument principle and sign changes computations, but it
would have been more efficient to use $\zeta(s)$ for the argument principle
integral, since it has a simpler formula. It would also be useful if there
were a formula with similar properties to $Z(s)$ (real on the critical line
with the same zeros as $\zeta(s)$), but that did not decay as rapidly.&lt;/p&gt;
&lt;p&gt;Furthermore, for the argument principle integral, I would like to see precise
error estimates for the integral. We saw above with $N=100$ with the default
quadrature that we got a value of 28.248, which is not close to an integer.
This tipped us off that we should increase the quadrature, which ended up
giving us the right answer, but if the original number happened to be close to
an integer, we might have been fooled. Ideally, one would like know the exact
quadrature degree needed. If you can get error estimates guaranteeing the
error for the integral will be less than 0.5, you can always round the answer
to the nearest integer. For the sign changes, you don't need to be as
rigorous, because simply seeing as many sign changes as you have zeros is
sufficient. However, one could certainly be more efficient in computing the
values along the interval, rather than just naively computing 10000 points and
raising the precision until it works, as I have done.&lt;/p&gt;
&lt;p&gt;One would also probably want to use a faster integrator than mpmath (like one
written in C), and perhaps also find a faster to evaluate expression than the
one I used for $Z(s)$. It is also possible that one could special-case the
quadrature algorithm knowing that it will be computed on $\zeta'(s)/\zeta(s)$.&lt;/p&gt;
&lt;p&gt;In this post I described the Riemann zeta function and the Riemann Hypothesis,
and showed how to computationally verify it. But I didn't really go over the
details of why the Riemann Hypothesis matters. I encourage you to watch the
videos in my &lt;a href="https://www.youtube.com/playlist?list=PLrFrByaoJbcqKjzgJvLs2-spSmzP7jolT"&gt;YouTube
playlist&lt;/a&gt;
if you want to know this. Among other things, the truth of the Riemann
Hypothesis would give a very precise bound on the distribution of prime
numbers. Also, the non-trivial zeros of $\zeta(s)$ are, in some sense, the
"spectrum" of the prime numbers, meaning they exactly encode the position of
every prime on the number line.&lt;/p&gt;&lt;/div&gt;</description>
    </item>
    <item>
      <guid isPermaLink="false">http://ishanaj.wordpress.com/?p=122</guid>
      <author>Ishan Joshi (ishanaj)</author>
      <title>Ishan Joshi (ishanaj): Everything about SymPy&#x2019;s Column module</title>
      <pubDate>Thu, 28 Nov 2019 19:56:42 GMT</pubDate>
      <link>https://ishanaj.wordpress.com/2019/11/29/everything-about-sympys-column-module/</link>
      <description>&lt;p&gt;The Column class implemented in &lt;a href="https://github.com/sympy/sympy/pull/17122"&gt;PR #17122&lt;/a&gt; enables the
continuum mechanics module of SymPy to deal with column buckling related
calculations. The Column module can calculate the moment equation, deflection
equation, slope equation and the critical load for a column defined by a user.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Example use-case of Column class:&lt;/strong&gt;&lt;/p&gt;


&lt;pre class="brush: python; collapse: false; title: ; wrap-lines: false; notranslate"&gt;
&amp;gt;&amp;gt;&amp;gt; from sympy.physics.continuum_mechanics.column import Column
&amp;gt;&amp;gt;&amp;gt; from sympy import Symbol, symbols
&amp;gt;&amp;gt;&amp;gt; E, I, P = symbols('E, I, P', positive=True)
&amp;gt;&amp;gt;&amp;gt; c = Column(3, E, I, 78000, top="pinned", bottom="pinned")
&amp;gt;&amp;gt;&amp;gt; c.end_conditions
{'bottom': 'pinned', 'top': 'pinned'}
&amp;gt;&amp;gt;&amp;gt; c.boundary_conditions
{'deflection': [(0, 0), (3, 0)], 'slope': [(0, 0)]}
&amp;gt;&amp;gt;&amp;gt; c.moment()
78000*y(x)
&amp;gt;&amp;gt;&amp;gt; c.solve_slope_deflection()
&amp;gt;&amp;gt;&amp;gt; c.deflection()
C1*sin(20*sqrt(195)*x/(sqrt(E)*sqrt(I)))
&amp;gt;&amp;gt;&amp;gt; c.slope()
20*sqrt(195)*C1*cos(20*sqrt(195)*x/(sqrt(E)*sqrt(I)))/(sqrt(E)*sqrt(I))
&amp;gt;&amp;gt;&amp;gt; c.critical_load()
pi**2*E*I/9
&lt;/pre&gt;



&lt;h1&gt;&lt;strong&gt;The Column class&lt;/strong&gt;&lt;/h1&gt;



&lt;p&gt;The Column class is non-mutable,&lt;span id="more-122"&gt;&lt;/span&gt; which means unlike the Beam class, a user cannot change the attributes of the class once they are defined along with the object definition. Therefore to change the attribute values one will have to define a new object.&lt;/p&gt;



&lt;h3&gt;&lt;strong&gt;Reasons for creating a non-mutable class&lt;/strong&gt;&lt;/h3&gt;



&lt;ul&gt;&lt;li&gt; From a backward-compatibility perspective, it is always possible to  adopt a different plan and add mutability later but not the other way  around. &lt;/li&gt;&lt;li&gt;Most things are immutable in SymPy which is useful for caching etc. Matrix is an example where allowing mutability has lead to many problems that are now impossible to fix without breaking backwards compatibility.&lt;/li&gt;&lt;/ul&gt;



&lt;h2&gt;&lt;strong&gt;Working of the column class:&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;
The &lt;strong&gt;governing equation&lt;/strong&gt; for column buckling is:&lt;/p&gt;



&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh3.googleusercontent.com/qfv6QbVnotFKUPebBoLgBNPjNz5uhN6g2-mbfBzDTR13Cb5z4BkAM7RHGerTtvqEzMzjQFL8r44iYeIVTm0OpYX6f0QWn2rCuz1qxKNVnvM6LHnTX9mfJ9pyBzPmBaFGZPrdiy-p" /&gt;&lt;/figure&gt;&lt;/div&gt;



&lt;p&gt;If we determine the the &lt;strong&gt;moment equation&lt;/strong&gt; of the column ,on which the buckling load is applied, and place it in the above equation,  we might be able to get the deflection by further solving the differential equation for &lt;strong&gt;y&lt;/strong&gt;. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Step-1: To determine the internal moment.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;This is simply done by assuming deflection at any arbitrary cross section at a distance&lt;strong&gt; x&lt;/strong&gt; from the bottom as &lt;strong&gt;y &lt;/strong&gt;and then multiplying this by the load &lt;strong&gt;P&lt;/strong&gt; and for eccentric load another moment of magnitude &lt;strong&gt;P*e&lt;/strong&gt; is added to the moment.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="" class="wp-image-129" src="https://ishanaj.files.wordpress.com/2019/11/image-2.png?w=641" /&gt;&lt;/figure&gt;



&lt;p&gt;&lt;strong&gt;Simple load&lt;/strong&gt; &lt;strong&gt;is given by&lt;/strong&gt;:&amp;#160;&lt;/p&gt;



&lt;figure class="wp-block-image"&gt;&lt;img alt="" src="https://lh3.googleusercontent.com/mY4nhR2YWfTEITzlL8LFRGnPq2KXPcwbyAGajOWtTkMEBYtTKGya0n4r62RolTLImOGjXazs0RqAjOyAy3K94vrM4G_xZxRKV-GBdG2uULX9qap7xPsgI6ahIY4-tXbx1zYH2LNR" /&gt;&lt;/figure&gt;



&lt;p&gt;&lt;strong&gt;Eccentric load is given by:&amp;#160;&lt;/strong&gt;&lt;/p&gt;



&lt;figure class="wp-block-image"&gt;&lt;img alt="" src="https://lh3.googleusercontent.com/vIfQDO151xRZO2hcDi9pSPeyafqlYmTUBnr_zszHjiZiv07cOA6xnuu__5EslONxpPtQFY5RaUGLXefgY0AtHip6Y6LgANv3XZ1uo790QctxO-Q5qTledCkiTuKzmpaMzJ5LBt-e" /&gt;&lt;/figure&gt;



&lt;p&gt;&lt;strong&gt;Step-2: &lt;/strong&gt;This moment can then be substituted in the governing equation and the resulting differential equation can be solved using SymPy&amp;#8217;s &lt;strong&gt;dsolve()&lt;/strong&gt; for the &lt;strong&gt;deflection y&lt;/strong&gt;.&lt;/p&gt;



&lt;h2&gt;&lt;strong&gt;Applying different end-conditions&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;The above steps considers a simple example of a column pinned at both of its ends. But the end-condition of the column can vary, which will cause the moment equation to to vary.&lt;/p&gt;



&lt;p&gt;Currently &lt;strong&gt;four&lt;/strong&gt; basic supports are implemented:&amp;#160; Pinned-pinned, fixed-fixed, fixed-pinned, one pinned-other free.&lt;/p&gt;



&lt;p&gt;Depending on the supports the moment due to applied load would change as:&lt;/p&gt;



&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Pinned-Pinned:&lt;/strong&gt;&amp;nbsp; no change in moment&lt;/li&gt;&lt;/ul&gt;



&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh5.googleusercontent.com/1rNjrJP3SC6q80sWh9m5-EAj80_YLYSmCECNYMqGh0n24r7EAqP5D8b-joCrvjhV0pnoQeD5EWrcStUufFj8zgHGSIMkk-lrnRPfkxYIJP42RIzh6pCNxthuEP83wWDdhAAZ8I30" /&gt;&lt;/figure&gt;&lt;/div&gt;



&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter is-resized"&gt;&lt;img alt="" height="218" src="https://lh4.googleusercontent.com/ki5Fbllhkj2xCcEJiRQxPyuTDlJnQGPfjcvk2GNjnJq5tNd83--zKWRKMck4v9TRx7SINESjNxcmdsXaXh6Le1-fBp8pQLY7pVTy-H_o895Ts_813cFmjlQDfbp34i3RJ3Qvb9RR" width="217" /&gt;&lt;/figure&gt;&lt;/div&gt;



&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Fixed-fixed&lt;/strong&gt;: reaction moment M is included&lt;/li&gt;&lt;/ul&gt;



&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh6.googleusercontent.com/76IEGW9i83Am9oy_YQC7xm2BVGnEw_BcgM_bQxUgnVdWY4hBpgIIbhE4bG0C8FLpNYpajyoi7F_z8g4uVLfEZOfjv3dQBQ9fvLnIFVZUJvsIaleRSUVA7B1vrQsBj5FY3Ln3H6sx" /&gt;&lt;/figure&gt;&lt;/div&gt;



&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh3.googleusercontent.com/8jXG4tyFMgAzJOanpHqj-d_f37-OkFrntfuhulynED1JjhNT6h_UkHmcAtDyN3Rem95uYIoKuhHUkslItdgIictxZC8dS_6mA9xbW-YxcDgMtyJ-L46UExUNH8VR8octca5v7RWa" /&gt;&lt;/figure&gt;&lt;/div&gt;



&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Fixed-pinned:&lt;/strong&gt;&amp;nbsp;&lt;/li&gt;&lt;/ul&gt;



&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh5.googleusercontent.com/zphyPG-BZaoTYFrhY1NVWVza7oBX85d-K3HIDXF02bpcG_3gMsA8zMD-T6UO1X7GX4ssJYeok9IFCILq18GZMDkztjLdA_IA_Otq-qSM30Us22gwqPjPwPnhubYPG3jwtwzq0yML" /&gt;&lt;/figure&gt;&lt;/div&gt;



&lt;p&gt;Here &lt;strong&gt;M&lt;/strong&gt; is the restraint moment at &lt;strong&gt;B (&lt;/strong&gt;which is fixed&lt;strong&gt;). &lt;/strong&gt;To counter this, another moment is considered by applying a horizontal force &lt;strong&gt;F&lt;/strong&gt; at point A.&lt;/p&gt;



&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh5.googleusercontent.com/2Wlvbp1qFbq2p9uf057TCNM7StusOl0J5VAFU-qMQ0BhKTDDdtvP_l-tPgSkC9vmmsAaJd3QR8sEddl_z4LsAqo5FBKEvQNVF6eEssYdex61ENPUb4qWf6nFV7OkZV1Hy5ftDCdJ" /&gt;&lt;/figure&gt;&lt;/div&gt;



&lt;ul&gt;&lt;li&gt;&lt;strong&gt;One pinned- other free:&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;



&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh6.googleusercontent.com/8vG470fp-wb2CzGMHfR5_chDnr4SqLGM0pAaRXXLSiDklpxXlcCoVOAh8q4dc97ZjWF3GM5-HvPGO1RzRhevUpDxl-cM6pHhztiTxJY-P7Ft04bfciVYK-FnzYJTZr4TvNqqX_wJ" /&gt;&lt;/figure&gt;&lt;/div&gt;



&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter"&gt;&lt;img alt="" src="https://lh3.googleusercontent.com/eoHyQWUNWNOTFDsofRof215piNvdk9OqETpA4YQWRlp904vpTx69eKRxW12NdAHGxTBNRs63oyP87cMT36DE5judlZWoVeh_7zpP7Vxq5MZ_RkUieecAZGgxSm8Hj5RpKrZIk87g" /&gt;&lt;/figure&gt;&lt;/div&gt;



&lt;h2&gt; &lt;strong&gt;Solving for slope and critical load&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Once we get the deflection equation we can solve for the slope by differentiating the deflection equation with respect to &lt;strong&gt;x&lt;/strong&gt;. This is done by SymPy&amp;#8217;s &lt;strong&gt;diff()&lt;/strong&gt; function&lt;/p&gt;


&lt;pre class="brush: python; collapse: false; title: ; wrap-lines: false; notranslate"&gt;
self._slope = self._deflection.diff(x)
&lt;/pre&gt;



&lt;h2&gt;&lt;strong&gt;Critical load&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Critical load for single bow buckling condition can be easily determined by the substituting the boundary conditions in the deflection equation and solving it for &lt;strong&gt;P&lt;/strong&gt; i.e the load.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Even if the user provides the applied load, during the entire calculation, we consider the  load to be &lt;strong&gt;P&lt;/strong&gt;. Whenever the &lt;strong&gt;moment()&lt;/strong&gt;, &lt;strong&gt;slope(), deflection(),&lt;/strong&gt; &lt;strong&gt;etc&lt;/strong&gt;. methods are called the variable &lt;strong&gt;P &lt;/strong&gt;is replaced with the users value. This is done so that it is easier for us to calculate the critical load in the end.&lt;/p&gt;


&lt;pre class="brush: python; collapse: false; title: ; wrap-lines: false; notranslate"&gt;
defl_eqs = []
# taking last two bounndary conditions which are actually
# the initial boundary conditions.
for point, value in self._boundary_conditions['deflection'][-2:]:
    defl_eqs.append(self._deflection.subs(x, point) - value)

# C1, C2 already solved, solve for P
self._critical_load = solve(defl_eqs, P, dict=True)[0][P]
&lt;/pre&gt;



&lt;p&gt;The case of the pinned-pinned end condition is a bit tricky.  On solving the differential equation via &lt;strong&gt;dsolve()&lt;/strong&gt;, the deflection comes out to be zero. This problem has been described in &lt;a href="https://ishanaj.wordpress.com/2019/07/08/gsoc19-week-6-completing-the-column-class/#more-56"&gt;this&lt;/a&gt; blog. Its calculation is handled a bit differently in the &lt;a href="https://github.com/sympy/sympy/pull/17122/files#diff-00c8ee080a295764f42be4b0e448935dR225"&gt;code&lt;/a&gt;. Instead of directly solving it via &lt;strong&gt;dsolve()&lt;/strong&gt;, it is solved in steps, and the trivial solutions are removed. This technique not only solves for the deflection of the column, but simultaneously also calculates the critical load it can bear.&lt;/p&gt;



&lt;p&gt;Although this may be considered as a hack to the problem. I think in future it would be better if &lt;strong&gt;dsolve()&lt;/strong&gt; gets the ability to remove the trivial solutions. But this seems to be better as of now.&lt;/p&gt;



&lt;p&gt;A problem that still persists is the calculation of critical load for pinned-fixed end condition. Currently, it has been made as an XFAIL, since to resolve that either &lt;strong&gt;solve()&lt;/strong&gt; or &lt;strong&gt;solveset() &lt;/strong&gt;has to return the solution in the required form. An &lt;a href="https://github.com/sympy/sympy/issues/17162"&gt;issue &lt;/a&gt;has been raised on GitHub, regarding the same.&lt;/p&gt;



&lt;p&gt;Hope that gives a crisp idea about the functioning of SymPy&amp;#8217;s Column module.&lt;/p&gt;



&lt;p&gt;Thanks!&lt;/p&gt;</description>
    </item>
    <item>
      <guid isPermaLink="false">https://asmeurer.com/blog/posts/quansight-labs-work-update-for-september-2019/</guid>
      <author>Aaron Meurer (asmeurer)</author>
      <title>Aaron Meurer (asmeurer): Quansight Labs Work Update for September, 2019</title>
      <pubDate>Mon, 07 Oct 2019 05:00:00 GMT</pubDate>
      <link>https://asmeurer.com/blog/posts/quansight-labs-work-update-for-september-2019/</link>
      <description>&lt;div&gt;&lt;p&gt;&lt;em&gt;This post has been cross-posted on the &lt;a href="https://labs.quansight.org/blog/2019/10/quansight-labs-work-update-for-september-2019/"&gt;Quansight Labs
Blog&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;As of November, 2018, I have been working at
&lt;a href="https://www.quansight.com/"&gt;Quansight&lt;/a&gt;. Quansight is a new startup founded by
the same people who started Anaconda, which aims to connect companies and open
source communities, and offers consulting, training, support and mentoring
services. I work under the heading of &lt;a href="https://www.quansight.com/labs"&gt;Quansight
Labs&lt;/a&gt;. Quansight Labs is a public-benefit
division of Quansight. It provides a home for a "PyData Core Team" which
consists of developers, community managers, designers, and documentation
writers who build open-source technology and grow open-source communities
around all aspects of the AI and Data Science workflow.&lt;/p&gt;
&lt;p&gt;My work at Quansight is split between doing open source consulting for various
companies, and working on SymPy.
&lt;a href="https://www.sympy.org/en/index.html"&gt;SymPy&lt;/a&gt;, for those who do not know, is a
symbolic mathematics library written in pure Python. I am the lead maintainer
of SymPy.&lt;/p&gt;
&lt;p&gt;In this post, I will detail some of the open source work that I have done
recently, both as part of my open source consulting, and as part of my work on
SymPy for Quansight Labs.&lt;/p&gt;
&lt;h3&gt;Bounds Checking in Numba&lt;/h3&gt;
&lt;p&gt;As part of work on a client project, I have been working on contributing code
to the &lt;a href="https://numba.pydata.org"&gt;numba&lt;/a&gt; project. Numba is a just-in-time
compiler for Python. It lets you write native Python code and with the use of
a simple &lt;code&gt;@jit&lt;/code&gt; decorator, the code will be automatically sped up using LLVM.
This can result in code that is up to 1000x faster in some cases:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
In [1]: import numba

In [2]: import numpy

In [3]: def test(x):
   ...:     A = 0
   ...:     for i in range(len(x)):
   ...:         A += i*x[i]
   ...:     return A
   ...:

In [4]: @numba.njit
   ...: def test_jit(x):
   ...:     A = 0
   ...:     for i in range(len(x)):
   ...:         A += i*x[i]
   ...:     return A
   ...:

In [5]: x = numpy.arange(1000)

In [6]: %timeit test(x)
249 &amp;#181;s &amp;#177; 5.77 &amp;#181;s per loop (mean &amp;#177; std. dev. of 7 runs, 1000 loops each)

In [7]: %timeit test_jit(x)
336 ns &amp;#177; 0.638 ns per loop (mean &amp;#177; std. dev. of 7 runs, 1000000 loops each)

In [8]: 249/.336
Out[8]: 741.0714285714286
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Numba only works for a subset of Python code, and primarily targets code that
uses NumPy arrays.&lt;/p&gt;
&lt;p&gt;Numba, with the help of LLVM, achieves this level of performance through many
optimizations. One thing that it does to improve performance is to remove all
bounds checking from array indexing. This means that if an array index is out
of bounds, instead of receiving an &lt;code&gt;IndexError&lt;/code&gt;, you will get garbage, or
possibly a segmentation fault.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; import numpy as np
&amp;gt;&amp;gt;&amp;gt; from numba import njit
&amp;gt;&amp;gt;&amp;gt; def outtabounds(x):
...     A = 0
...     for i in range(1000):
...         A += x[i]
...     return A
&amp;gt;&amp;gt;&amp;gt; x = np.arange(100)
&amp;gt;&amp;gt;&amp;gt; outtabounds(x) # pure Python/NumPy behavior
Traceback (most recent call last):
  File "&amp;lt;stdin&amp;gt;", line 1, in &amp;lt;module&amp;gt;
  File "&amp;lt;stdin&amp;gt;", line 4, in outtabounds
IndexError: index 100 is out of bounds for axis 0 with size 100
&amp;gt;&amp;gt;&amp;gt; njit(outtabounds)(x) # the default numba behavior
-8557904790533229732
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In numba pull request &lt;a href="https://github.com/numba/numba/pull/4432"&gt;#4432&lt;/a&gt;, I am
working on adding a flag to &lt;code&gt;@njit&lt;/code&gt; that will enable bounds checks for array
indexing. This will remain disabled by default for performance purposes. But
you will be able to enable it by passing &lt;code&gt;boundscheck=True&lt;/code&gt; to &lt;code&gt;@njit&lt;/code&gt;, or by
setting the &lt;code&gt;NUMBA_BOUNDSCHECK=1&lt;/code&gt; environment variable. This will make it
easier to detect out of bounds issues like the one above. It will work like&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-pycon"&gt;&amp;gt;&amp;gt;&amp;gt; @njit(boundscheck=True)
... def outtabounds(x):
...     A = 0
...     for i in range(1000):
...         A += x[i]
...     return A
&amp;gt;&amp;gt;&amp;gt; x = np.arange(100)
&amp;gt;&amp;gt;&amp;gt; outtabounds(x) # numba behavior in my pull request #4432
Traceback (most recent call last):
  File "&amp;lt;stdin&amp;gt;", line 1, in &amp;lt;module&amp;gt;
IndexError: index is out of bounds
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The pull request is still in progress, and many things such as the quality of
the error message reporting will need to be improved. This should make
debugging issues easier for people who write numba code once it is merged.&lt;/p&gt;
&lt;h3&gt;removestar&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://www.asmeurer.com/removestar/"&gt;removestar&lt;/a&gt; is a new tool I wrote to
automatically replace &lt;code&gt;import *&lt;/code&gt; in Python modules with explicit imports.&lt;/p&gt;
&lt;p&gt;For those who don't know, Python's &lt;code&gt;import&lt;/code&gt; statement supports so-called
"wildcard" or "star" imports, like&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;from sympy import *
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will import every public name from the &lt;code&gt;sympy&lt;/code&gt; module into the current
namespace. This is often useful because it saves on typing every name that is
used in the import line. This is especially useful when working interactively,
where you just want to import every name and minimize typing.&lt;/p&gt;
&lt;p&gt;However, doing &lt;code&gt;from module import *&lt;/code&gt; is generally frowned upon in Python. It is
considered acceptable when working interactively at a &lt;code&gt;python&lt;/code&gt; prompt, or in
&lt;code&gt;__init__.py&lt;/code&gt; files (removestar skips &lt;code&gt;__init__.py&lt;/code&gt; files by default).&lt;/p&gt;
&lt;p&gt;Some reasons why &lt;code&gt;import *&lt;/code&gt; is bad:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It hides which names are actually imported.&lt;/li&gt;
&lt;li&gt;It is difficult both for human readers and static analyzers such as
pyflakes to tell where a given name comes from when &lt;code&gt;import *&lt;/code&gt; is used. For
example, pyflakes cannot detect unused names (for instance, from typos) in
the presence of &lt;code&gt;import *&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;If there are multiple &lt;code&gt;import *&lt;/code&gt; statements, it may not be clear which names
come from which module. In some cases, both modules may have a given name,
but only the second import will end up being used. This can break people's
intuition that the order of imports in a Python file generally does not
matter.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;import *&lt;/code&gt; often imports more names than you would expect. Unless the module
you import defines &lt;code&gt;__all__&lt;/code&gt; or carefully &lt;code&gt;del&lt;/code&gt;s unused names at the module
level, &lt;code&gt;import *&lt;/code&gt; will import every public (doesn't start with an
underscore) name defined in the module file. This can often include things
like standard library imports or loop variables defined at the top-level of
the file. For imports from modules (from &lt;code&gt;__init__.py&lt;/code&gt;), &lt;code&gt;from module import *&lt;/code&gt; will include every submodule defined in that module. Using &lt;code&gt;__all__&lt;/code&gt; in
modules and &lt;code&gt;__init__.py&lt;/code&gt; files is also good practice, as these things are
also often confusing even for interactive use where &lt;code&gt;import *&lt;/code&gt; is
acceptable.&lt;/li&gt;
&lt;li&gt;In Python 3, &lt;code&gt;import *&lt;/code&gt; is syntactically not allowed inside of a function
definition.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here are some official Python references stating not to use &lt;code&gt;import *&lt;/code&gt; in
files:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://docs.python.org/3/faq/programming.html?highlight=faq#what-are-the-best-practices-for-using-import-in-a-module"&gt;The official Python
FAQ&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In general, don&amp;#8217;t use &lt;code&gt;from modulename import *&lt;/code&gt;. Doing so clutters the
importer&amp;#8217;s namespace, and makes it much harder for linters to detect
undefined names.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.python.org/dev/peps/pep-0008/#imports"&gt;PEP 8&lt;/a&gt; (the official
Python style guide):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Wildcard imports (&lt;code&gt;from &amp;lt;module&amp;gt; import *&lt;/code&gt;) should be avoided, as they
make it unclear which names are present in the namespace, confusing both
readers and many automated tools.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Unfortunately, if you come across a file in the wild that uses &lt;code&gt;import *&lt;/code&gt;, it
can be hard to fix it, because you need to find every name in the file that is
imported from the &lt;code&gt;*&lt;/code&gt; and manually add an import for it. Removestar makes this
easy by finding which names come from &lt;code&gt;*&lt;/code&gt; imports and replacing the import
lines in the file automatically.&lt;/p&gt;
&lt;p&gt;As an example, suppose you have a module &lt;code&gt;mymod&lt;/code&gt; like&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mymod/
  | __init__.py
  | a.py
  | b.py
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;with&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;# mymod/a.py
from .b import *

def func(x):
    return x + y
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;# mymod/b.py
x = 1
y = 2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then &lt;code&gt;removestar&lt;/code&gt; works like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ removestar -i mymod/
$ cat mymod/a.py
# mymod/a.py
from .b import y

def func(x):
    return x + y
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;-i&lt;/code&gt; flag causes it to edit &lt;code&gt;a.py&lt;/code&gt; in-place. Without it, it would just
print a diff to the terminal.&lt;/p&gt;
&lt;p&gt;For implicit star imports and explicit star imports from the same module,
&lt;code&gt;removestar&lt;/code&gt; works statically, making use of
&lt;a href="https://github.com/PyCQA/pyflakes"&gt;pyflakes&lt;/a&gt;. This means none of the code is
actually executed. For external imports, it is not possible to work statically
as external imports may include C extension modules, so in that case, it
imports the names dynamically.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;removestar&lt;/code&gt; can be installed with pip or conda:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install removestar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or if you use conda&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda install -c conda-forge removestar
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;sphinx-math-dollar&lt;/h3&gt;
&lt;p&gt;In SymPy, we make heavy use of LaTeX math in our documentation. For example,
in our &lt;a href="https://docs.sympy.org/dev/modules/functions/special.html#sympy.functions.special.hyper.hyper"&gt;special functions
documentation&lt;/a&gt;,
most special functions are defined using a LaTeX formula, like &lt;img alt="The docs for besselj" src="https://asmeurer.com/blog/besselj_docs.png" /&gt;&lt;/p&gt;
&lt;p&gt;(from &lt;a href="https://docs.sympy.org/dev/modules/functions/special.html#sympy.functions.special.bessel.besselj"&gt;https://docs.sympy.org/dev/modules/functions/special.html#sympy.functions.special.bessel.besselj&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;However, the source for this math in the docstring of the function uses RST
syntax:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;class besselj(BesselBase):
    """
    Bessel function of the first kind.

    The Bessel `J` function of order `\nu` is defined to be the function
    satisfying Bessel's differential equation

    .. math ::
        z^2 \frac{\mathrm{d}^2 w}{\mathrm{d}z^2}
        + z \frac{\mathrm{d}w}{\mathrm{d}z} + (z^2 - \nu^2) w = 0,

    with Laurent expansion

    .. math ::
        J_\nu(z) = z^\nu \left(\frac{1}{\Gamma(\nu + 1) 2^\nu} + O(z^2) \right),

    if :math:`\nu` is not a negative integer. If :math:`\nu=-n \in \mathbb{Z}_{&amp;lt;0}`
    *is* a negative integer, then the definition is

    .. math ::
        J_{-n}(z) = (-1)^n J_n(z).
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Furthermore, in SymPy's documentation we have configured it so that text
between `single backticks` is rendered as math. This was originally done for
convenience, as the alternative way is to write &lt;code&gt;:math:`\nu`&lt;/code&gt; every
time you want to use inline math. But this has lead to many people being
confused, as they are used to Markdown where `single backticks` produce
&lt;code&gt;code&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;A better way to write this would be if we could delimit math with dollar
signs, like &lt;code&gt;$\nu$&lt;/code&gt;. This is how things are done in LaTeX documents, as well
as in things like the Jupyter notebook.&lt;/p&gt;
&lt;p&gt;With the new &lt;a href="https://www.sympy.org/sphinx-math-dollar/"&gt;sphinx-math-dollar&lt;/a&gt;
Sphinx extension, this is now possible. Writing &lt;code&gt;$\nu$&lt;/code&gt; produces $\nu$, and
the above docstring can now be written as&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;class besselj(BesselBase):
    """
    Bessel function of the first kind.

    The Bessel $J$ function of order $\nu$ is defined to be the function
    satisfying Bessel's differential equation

    .. math ::
        z^2 \frac{\mathrm{d}^2 w}{\mathrm{d}z^2}
        + z \frac{\mathrm{d}w}{\mathrm{d}z} + (z^2 - \nu^2) w = 0,

    with Laurent expansion

    .. math ::
        J_\nu(z) = z^\nu \left(\frac{1}{\Gamma(\nu + 1) 2^\nu} + O(z^2) \right),

    if $\nu$ is not a negative integer. If $\nu=-n \in \mathbb{Z}_{&amp;lt;0}$
    *is* a negative integer, then the definition is

    .. math ::
        J_{-n}(z) = (-1)^n J_n(z).
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We also plan to add support for &lt;code&gt;$$double dollars$$&lt;/code&gt; for display math so that &lt;code&gt;.. math ::&lt;/code&gt; is no longer needed either .&lt;/p&gt;
&lt;p&gt;For end users, the documentation on &lt;a href="https://docs.sympy.org"&gt;docs.sympy.org&lt;/a&gt;
will continue to render exactly the same, but for developers, it is much
easier to read and write.&lt;/p&gt;
&lt;p&gt;This extension can be easily used in any Sphinx project. Simply install it
with pip or conda:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install sphinx-math-dollar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda install -c conda-forge sphinx-math-dollar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then enable it in your &lt;code&gt;conf.py&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;extensions = ['sphinx_math_dollar', 'sphinx.ext.mathjax']
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Google Season of Docs&lt;/h3&gt;
&lt;p&gt;The above work on sphinx-math-dollar is part of work I have been doing to
improve the tooling around SymPy's documentation. This has been to assist our
technical writer Lauren Glattly, who is working with SymPy for the next three
months as part of the new &lt;a href="https://developers.google.com/season-of-docs/"&gt;Google Season of
Docs&lt;/a&gt; program. Lauren's project
is to improve the consistency of our docstrings in SymPy. She has already
identified many key ways our docstring documentation can be improved, and is
currently working on a style guide for writing docstrings. Some of the issues
that Lauren has identified require improved tooling around the way the HTML
documentation is built to fix. So some other SymPy developers and I have been
working on improving this, so that she can focus on the technical writing
aspects of our documentation.&lt;/p&gt;
&lt;p&gt;Lauren has created a draft style guide for documentation at
&lt;a href="https://github.com/sympy/sympy/wiki/SymPy-Documentation-Style-Guide"&gt;https://github.com/sympy/sympy/wiki/SymPy-Documentation-Style-Guide&lt;/a&gt;. Please
take a moment to look at it and if you have any feedback on it, comment below
or write to the SymPy mailing list.&lt;/p&gt;&lt;/div&gt;</description>
    </item>
    <item>
      <guid isPermaLink="false">http://ishanaj.wordpress.com/?p=113</guid>
      <author>Ishan Joshi (ishanaj)</author>
      <title>Ishan Joshi (ishanaj): GSoC&#x2019;19: Week-12 &#x2013; The Final wrap-up</title>
      <pubDate>Tue, 20 Aug 2019 17:10:27 GMT</pubDate>
      <link>https://ishanaj.wordpress.com/2019/08/20/gsoc19-week-12-the-final-wrap-up/</link>
      <description>&lt;p&gt;This was the last week of the coding
period. With not much of work left, the goal was to wrap-up the PR&amp;#8217;s.&lt;/p&gt;



&lt;p&gt;The week started with the merge of &amp;nbsp;&lt;a href="https://github.com/sympy/sympy/pull/17001"&gt;PR #17001&lt;/a&gt; which implemented a method &lt;strong&gt;cut_section()&lt;/strong&gt; in the polygon class, in order to get two new polygons when a polygon is cut via a line. After this a new method &lt;strong&gt;first_moment_of_area()&lt;/strong&gt; was added in &lt;a href="https://github.com/sympy/sympy/pull/17153"&gt;PR #17153&lt;/a&gt;. This method used &lt;strong&gt;cut_section()&lt;/strong&gt; for its implementation. Tests for the same were added in this PR. Also the existing documentation was improved. I also renamed the &lt;strong&gt;polar_modulus()&lt;/strong&gt; function to &lt;strong&gt;polar_second_moment_of_area() &lt;/strong&gt;which was a more general term as compared to the previous name. This PR also got &lt;strong&gt;merged&lt;/strong&gt; later on.&lt;/p&gt;



&lt;p&gt;Now, we are left with two more PR&amp;#8217;s to go.
&lt;a href="https://github.com/sympy/sympy/pull/17122"&gt;PR #17122&lt;/a&gt; (Column
Buckling) and &lt;a href="https://github.com/sympy/sympy/pull/17345"&gt;PR #17345&lt;/a&gt;
(Beam diagram). The column buckling probably requires a little more
documentation. I will surely look into it and add some more explanations and references
to it. Also, the beam diagram PR has been completed and documented. A few more
discussions to be done on its working and we will be ready with it.&lt;span id="more-113"&gt;&lt;/span&gt;&lt;/p&gt;



&lt;p&gt;I believe that by the end of this week
both of these will finally get a merge.&lt;/p&gt;



&lt;p&gt;Another task that remains is the implementation of the &lt;a href="https://github.com/sympy/sympy/issues/17302"&gt;Truss class&lt;/a&gt;. Some rigorous debate and discussion is still needed to be done before we start its implementation. Once we agree on the implementation needs and API it won&amp;#8217;t be a difficult task to write it through.&lt;/p&gt;



&lt;p&gt;Also, since the final evaluations have
started I will be writing the project report which I have to submit before the
next week ends.&lt;/p&gt;



&lt;p&gt;Since officially the coding period ends here, there would be no ToDo&amp;#8217;s for the next week, just the final wrapping up and will surely try to complete the work that is still left.&lt;/p&gt;



&lt;p&gt;Will keep you updated!&lt;/p&gt;



&lt;p&gt;Thanks! &lt;/p&gt;</description>
    </item>
    <item>
      <guid isPermaLink="false">https://divyanshu132.github.io//gsoc-week-12</guid>
      <author>Divyanshu Thakur (divyanshu132)</author>
      <title>Divyanshu Thakur (divyanshu132): GSoC 2019 - Week 11 and 12 - Phase-III Completion</title>
      <pubDate>Mon, 19 Aug 2019 00:00:00 GMT</pubDate>
      <link>https://divyanshu132.github.io//gsoc-week-12</link>
      <description>&lt;p&gt;We&amp;#8217;ve reached to the end of GSoC 2019, end to the really productive and wonderful summer. In the last two weeks I worked on documenting polycyclic groups which got merged as well, here is the PR &lt;a href="https://github.com/sympy/sympy/pull/17399"&gt;sympy/sympy#17399&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Also, the PR on Induced-pcgs and exponent vector for polycyclic subgroups got merged &lt;a href="https://github.com/sympy/sympy/pull/17317"&gt;sympy/sympy#17317&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Let&amp;#8217;s have a look at some of the highlights of documentation.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The parameters of both the classes(&lt;code class="highlighter-rouge"&gt;PolycyclicGroup&lt;/code&gt; and &lt;code class="highlighter-rouge"&gt;Collector&lt;/code&gt;) has been discussed in detail.&lt;/li&gt;
  &lt;li&gt;Conditions for a word to be collected or uncollected is highlighted.&lt;/li&gt;
  &lt;li&gt;Computation of polycyclic presentation has been explained in detail highlighting the sequence in which presentation is computed with the corresponding pcgs and and polycyclic series elements used.&lt;/li&gt;
  &lt;li&gt;Other methods like &lt;code class="highlighter-rouge"&gt;subword_index&lt;/code&gt;, &lt;code class="highlighter-rouge"&gt;exponent_vector&lt;/code&gt;, &lt;code class="highlighter-rouge"&gt;depth&lt;/code&gt;, etc are also documented.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;An example is provided for every functionality.
For more details one can visit:
&lt;a href="https://docs.sympy.org/dev/modules/combinatorics/pc_groups.html"&gt;https://docs.sympy.org/dev/modules/combinatorics/pc_groups.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Now, I&amp;#8217;m supposed to prepare a final report presenting all the work done. Will update with report next week.
In addition to the report preparation I&amp;#8217;ll try to add &lt;code class="highlighter-rouge"&gt;Parameters&lt;/code&gt; section in the &lt;code class="highlighter-rouge"&gt;docstrings&lt;/code&gt; for various classes and methods of &lt;code class="highlighter-rouge"&gt;pc_groups&lt;/code&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <guid isPermaLink="false">http://ishanaj.wordpress.com/?p=105</guid>
      <author>Ishan Joshi (ishanaj)</author>
      <title>Ishan Joshi (ishanaj): GSoC&#x2019;19: Week-11- Heading to the final week</title>
      <pubDate>Tue, 13 Aug 2019 17:26:54 GMT</pubDate>
      <link>https://ishanaj.wordpress.com/2019/08/13/gsoc19-week-11-heading-to-the-final-week/</link>
      <description>&lt;p&gt;With the end of this week the &lt;strong&gt;draw()&lt;/strong&gt; function has been completely implemented. The work on &lt;a href="https://github.com/sympy/sympy/pull/17345"&gt;PR #17345&lt;/a&gt; has been completed along with the documentations.&lt;/p&gt;



&lt;p&gt;As mentioned in the previous blog this PR was an attempt to make the &lt;strong&gt;draw()&lt;/strong&gt; function use SymPy&amp;#8217;s own plot() rather than importing matplotlib externally to plot the diagram. The idea was to plot the load equation which is in terms of singularity function. This would directly plot uniformly distributed load, uniformly varying load and other higher order loads except for point loads and moment loads.&lt;br /&gt; The task was now to plot the remaining parts of the diagram which were:&lt;/p&gt;



&lt;ul&gt;&lt;li&gt;A rectangle for drawing the beam&lt;/li&gt;&lt;li&gt;Arrows for point loads&lt;/li&gt;&lt;li&gt;Markers for moment loads and supports &lt;/li&gt;&lt;li&gt;Colour filling to fill colour in inside the higher order loads (order &amp;gt;=0).&lt;span id="more-105"&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;



&lt;p&gt;Instead of making temporary hacks to implement these, I went a step further to give the plotting module some additional functionalities. Apart from helping in implementing the &lt;strong&gt;draw()&lt;/strong&gt; function, &amp;nbsp;this would also enhance the plotting module.&lt;/p&gt;



&lt;p&gt;The basic idea was to have some additional keyworded arguments in the &lt;strong&gt;plot()&lt;/strong&gt; function. Every keyworded argument would be a list of dictionaries where each dictionary would represent the arguments (or parameters) that would have been passed in the corresponding matplotlib functions.&lt;/p&gt;



&lt;p&gt;These are the functions of matplotlib that can now be accessed using &lt;strong&gt;sympy&amp;#8217;s plot()&lt;/strong&gt;, along with where there are used in our current situation:&lt;/p&gt;



&lt;ul&gt;&lt;li&gt;&lt;a href="https://matplotlib.org/api/_as_gen/matplotlib.patches.Rectangle.html"&gt;matplotlib.patches.Rectangle&lt;/a&gt;&amp;nbsp;-to draw the beam&lt;/li&gt;&lt;li&gt;&lt;a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.annotate.html"&gt;matplotlib.pyplot.annotate&lt;/a&gt;&amp;nbsp;&amp;#8211; to draw arrows of load&lt;/li&gt;&lt;li&gt;&lt;a href="https://matplotlib.org/3.1.1/api/markers_api.html"&gt;matplotlib.markers&lt;/a&gt;&amp;#8211; to draw supports and moment loads&lt;/li&gt;&lt;li&gt;&lt;a href="https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.fill_between.html"&gt;fill_between()&lt;/a&gt; &amp;#8211; to fill an area with color&lt;/li&gt;&lt;/ul&gt;



&lt;p&gt;Another thing which is worth mentioning is that to use &lt;strong&gt;fill_between() &lt;/strong&gt;we would require numpy&amp;#8217;s &lt;strong&gt;arange()&lt;/strong&gt; for sure. Although it might be better if we could avoid using an external module directly, but I guess this is unavoidable for now. &lt;/p&gt;



&lt;p&gt;Also, I have added an option for the user to scale the plot and get a pictorial view of it in case where the plotting with the exact dimensions doesn&amp;#8217;t produce a decent diagram. For eg. If the magnitude of the load (order &amp;gt;= 0) is relatively higher to other applied loads or to the length of the beam, the load plot might get out of the final plot window. &lt;/p&gt;



&lt;p&gt;Here is an example:&lt;/p&gt;


&lt;pre class="brush: python; collapse: false; title: ; wrap-lines: false; notranslate"&gt;
&amp;gt;&amp;gt;&amp;gt; R1, R2 = symbols('R1, R2')
&amp;gt;&amp;gt;&amp;gt; E, I = symbols('E, I')

&amp;gt;&amp;gt;&amp;gt; b1 = Beam(50, 20, 30)

&amp;gt;&amp;gt;&amp;gt; b1.apply_load(10, 2, -1)
&amp;gt;&amp;gt;&amp;gt; b1.apply_load(R1, 10, -1)
&amp;gt;&amp;gt;&amp;gt; b1.apply_load(R2, 30, -1)
&amp;gt;&amp;gt;&amp;gt; b1.apply_load(90, 5, 0, 23)
&amp;gt;&amp;gt;&amp;gt; b1.apply_load(10, 30, 1, 50)
&amp;gt;&amp;gt;&amp;gt; b1.apply_support(50, "pin")
&amp;gt;&amp;gt;&amp;gt; b1.apply_support(0, "fixed")
&amp;gt;&amp;gt;&amp;gt; b1.apply_support(20, "roller")
# case 1 on the left
&amp;gt;&amp;gt;&amp;gt; p = b1.draw()
&amp;gt;&amp;gt;&amp;gt; p.show()

# case 2 on the right
&amp;gt;&amp;gt;&amp;gt; p1 = b1.draw(pictorial=True)
&amp;gt;&amp;gt;&amp;gt; p1.show()
&lt;/pre&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="" class="wp-image-107" src="https://ishanaj.files.wordpress.com/2019/08/screenshot-10-08-2019-23_04_45.png" /&gt;&lt;/figure&gt;



&lt;h2&gt;&lt;strong&gt;Next Week:&lt;/strong&gt;&lt;/h2&gt;



&lt;ul&gt;&lt;li&gt;Getting leftover PR&amp;#8217;s merged&lt;/li&gt;&lt;li&gt;Initiating implementation of Truss class&lt;/li&gt;&lt;/ul&gt;



&lt;p&gt;Will keep you updated!&lt;/p&gt;



&lt;p&gt;Thanks!&lt;/p&gt;</description>
    </item>
    <item>
      <guid isPermaLink="false">https://anpandey.github.io/posts/sympy/2019-08-06-week-10.html</guid>
      <author>Ankit Pandey (anpandey)</author>
      <title>Ankit Pandey (anpandey): Google Summer of Code Week 10: Matrix Wildcard Redux</title>
      <pubDate>Tue, 06 Aug 2019 00:00:00 GMT</pubDate>
      <link>https://anpandey.github.io/posts/sympy/2019-08-06-week-10.html</link>
      <description>&lt;p&gt;For this week, I&amp;#8217;ve made some more minor changes to the &lt;a href="https://github.com/sympy/sympy/pull/17299"&gt;&lt;code&gt;Indexed&lt;/code&gt; pull request&lt;/a&gt; from last week, in addition to filing a new &lt;a href="https://github.com/sympy/sympy/pull/17347"&gt;matrix wildcard pull request&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="matrix-wildcards-again"&gt;Matrix Wildcards (again)&lt;/h3&gt;
&lt;p&gt;Since &lt;a href="https://github.com/sympy/sympy/pull/17223"&gt;#17223&lt;/a&gt; was merged this week, I started with an implementation of matrix wildcards that takes advantage of the functionality included in the pull request. I thought that this would be relatively straightforward, with an implementation of the &lt;code&gt;matches&lt;/code&gt; method for the &lt;code&gt;MatrixWild&lt;/code&gt; subclass being enough. There was one problem though: the underlying matching implementation assumes that all powers in the expression are an instance of the &lt;code&gt;Pow&lt;/code&gt; class. However, this isn&amp;#8217;t true for matrix expressions: the &lt;code&gt;MatPow&lt;/code&gt; class, which represents matrix powers, is a subclass of its own. I&amp;#8217;m not exactly sure what the reason for this is, since a quick change of &lt;code&gt;MatPow&lt;/code&gt; to inherit from &lt;code&gt;Pow&lt;/code&gt; doesn&amp;#8217;t seem to break anything. I&amp;#8217;ll probably look into this a bit more, since I think this might have something to do with the fact that Matrix exponents can also include other matrices.&lt;/p&gt;
&lt;p&gt;My solution for this was to allow temporarily allow expansion of powers by recursing through the expression tree and setting the &lt;code&gt;is_Pow&lt;/code&gt; field of each matrix power to &lt;code&gt;True&lt;/code&gt; and later reverting these states later. It doesn&amp;#8217;t look pretty, but it does seem to work (you can see the code &lt;a href="https://github.com/sympy/sympy/blob/17fb5010e36e10de156dad032d2aea376051df24/sympy/matrices/expressions/matmul.py#L178-L197"&gt;here&lt;/a&gt;).&lt;/p&gt;
&lt;h2 id="next-steps"&gt;Next Steps&lt;/h2&gt;
&lt;p&gt;I&amp;#8217;ll try to get started with some optimizations that utilize this wildcard class once the pull request gets merged.&lt;/p&gt;</description>
    </item>
    <item>
      <guid isPermaLink="false">http://ishanaj.wordpress.com/?p=91</guid>
      <author>Ishan Joshi (ishanaj)</author>
      <title>Ishan Joshi (ishanaj): GSoC&#x2019;19: Week-10- An alternative to the draw() function</title>
      <pubDate>Mon, 05 Aug 2019 17:58:18 GMT</pubDate>
      <link>https://ishanaj.wordpress.com/2019/08/05/gsoc19-week-10-an-alternative-to-the-draw-function/</link>
      <description>&lt;p&gt;This was
the end of the tenth week, and we have entered the final phase of the project.&lt;/p&gt;



&lt;p&gt;For the last phase we have Truss calculations to be implemented in the continuum_mechanics module. I had initiated a discussion regarding what needs to be done and how the implementation will move forward in an &lt;a href="https://github.com/sympy/sympy/issues/17302"&gt;issue #17302&lt;/a&gt;. We will have to analyse a bit more about making Truss calculations symbolic and what benefits one might get in solving it symbolically. We have some good packages to compare from like &lt;a href="https://anastruct.readthedocs.io/en/latest/?badge=latest"&gt;this&lt;/a&gt;. I guess a bit more discussion is needed before we go ahead with it. &lt;/p&gt;



&lt;p&gt;Besides this, I had worked on improving the &lt;strong&gt;draw()&lt;/strong&gt; function implemented in the previous week in &lt;a href="https://github.com/sympy/sympy/pull/17240"&gt;PR #17240&lt;/a&gt;. I modified it to use the &lt;strong&gt;_backend&lt;/strong&gt; attribute for plotting the beam diagram. This could have worked until &lt;span id="more-91"&gt;&lt;/span&gt;I realised that using the &lt;strong&gt;_backend&lt;/strong&gt; attribute doesn&amp;#8217;t really has affect the &lt;strong&gt;Plot object. &lt;/strong&gt;To understand the last statement, lets go to how &lt;strong&gt;sympy.plot() &lt;/strong&gt;works.&lt;/p&gt;



&lt;p&gt;In simple terms, the equations that we pass through the &lt;strong&gt;plot()&lt;/strong&gt; function as arguments are actually stored in&lt;strong&gt; _series&lt;/strong&gt; attribute. So we can indirectly say that the basic data of the plot is stored in this attribute. But using the &lt;strong&gt;_backend &lt;/strong&gt;attribute wouldn&amp;#8217;t alter &lt;strong&gt;_series &lt;/strong&gt;at all and if &lt;strong&gt;_series &lt;/strong&gt;remains empty at the start it would end up storing nothing. &lt;/p&gt;



&lt;p&gt;But we are of course getting a decent plot at the end, so shouldn&amp;#8217;t we probably ignore this? No, it would surely  give the plot but we won&amp;#8217;t be getting a fully defined&lt;strong&gt; Plot &lt;/strong&gt;object which we can further use with &lt;strong&gt;PlotGrid&lt;/strong&gt; to get a subplot which includes all the five plots related to the beam.&lt;/p&gt;



&lt;p&gt;Keeping this in mind, I tried an alternative way to directly use&lt;strong&gt; sympy.plot() &lt;/strong&gt;&amp;nbsp;to give the plot. Although a bit hard and time taking to do, I have intiated this in a draft &lt;a href="https://github.com/sympy/sympy/pull/17345"&gt;PR #17345&lt;/a&gt;. This PR perfectly plots a rectangular beam and loads (except point and moment loads). Only things that are left here are to plot supports and arrows denoting the direction of the load.&lt;/p&gt;



&lt;p&gt;The example below shows how it functions: (keep in mind it just plots the basic structure of the intended beam diagram, it hasn&amp;#8217;t been completed yet)&lt;/p&gt;



&lt;div class="wp-container-61507d341c3cb wp-block-group"&gt;&lt;div class="wp-block-group__inner-container"&gt;&lt;pre class="brush: python; collapse: false; title: ; wrap-lines: false; notranslate"&gt;
&amp;gt;&amp;gt;&amp;gt; E, I = symbols('E, I')
&amp;gt;&amp;gt;&amp;gt; b = Beam(9, E, I)
&amp;gt;&amp;gt;&amp;gt; b.apply_load(-12, 9, -1)  # gets skipped
&amp;gt;&amp;gt;&amp;gt; b.apply_load(50, 5, -2)  # gets skipped
&amp;gt;&amp;gt;&amp;gt; b.apply_load(3, 6, 1, end=8)
&amp;gt;&amp;gt;&amp;gt; b.apply_load(4, 0, 0, end=5)
&amp;gt;&amp;gt;&amp;gt; b.draw()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;



&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="" class="wp-image-92" height="351" src="https://ishanaj.files.wordpress.com/2019/08/screenshot-05-08-2019-19_49_21.png" width="449" /&gt;&lt;/figure&gt;



&lt;p&gt;I also tried to complete the leftover PR&amp;#8217;s in this week, but still some work is left.&lt;/p&gt;



&lt;h2&gt;&lt;strong&gt;Next week:&lt;/strong&gt;&lt;/h2&gt;



&lt;ul&gt;&lt;li&gt;Completing the &lt;strong&gt;draw() &lt;/strong&gt;function&lt;/li&gt;&lt;li&gt;Documentation and testing&lt;/li&gt;&lt;li&gt;Starting Truss implementations&lt;/li&gt;&lt;/ul&gt;



&lt;p&gt;Will keep you updated!&lt;/p&gt;



&lt;p&gt;Thanks!&lt;/p&gt;</description>
    </item>
    <item>
      <guid isPermaLink="false">https://divyanshu132.github.io//gsoc-week-10</guid>
      <author>Divyanshu Thakur (divyanshu132)</author>
      <title>Divyanshu Thakur (divyanshu132): GSoC 2019 - Week 10 - Induced Pcgs for polycyclic subgroups</title>
      <pubDate>Mon, 05 Aug 2019 00:00:00 GMT</pubDate>
      <link>https://divyanshu132.github.io//gsoc-week-10</link>
      <description>&lt;p&gt;The tenth week of coding period has ended and a new PR&lt;a href="https://github.com/sympy/sympy/pull/17317"&gt;sympy/sympy#17317&lt;/a&gt; has been introduced. The PR implements induced Pcgs and exponent vector for polycyclic subgroups with respect to the original pcgs of the group.
Below is an example to show the functionality.&lt;/p&gt;

&lt;div class="highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; from sympy.combinatorics import *
&amp;gt;&amp;gt;&amp;gt; S = SymmetricGroup(8)
&amp;gt;&amp;gt;&amp;gt; G = S.sylow_subgroup(2)
&amp;gt;&amp;gt;&amp;gt; gens = [G[0], G[1]]
&amp;gt;&amp;gt;&amp;gt; PcGroup = G.polycyclic_group()
&amp;gt;&amp;gt;&amp;gt; collector = PcGroup.collector
&amp;gt;&amp;gt;&amp;gt; ipcgs = collector.induced_pcgs(gens)
&amp;gt;&amp;gt;&amp;gt; [gen.order() for gen in ipcgs]
[2, 2, 2]

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Further it can also be used to implement &lt;code class="highlighter-rouge"&gt;Canonical polycyclic sequence&lt;/code&gt; which can be used to check if two subgroups of polycyclic presented group &lt;code class="highlighter-rouge"&gt;G&lt;/code&gt; are equal or not.&lt;/p&gt;

&lt;p&gt;For the next week I&amp;#8217;ll try to complete the documentation work on polycyclic groups and open a PR for the same.&lt;/p&gt;

&lt;p&gt;Till then, good byee..&lt;/p&gt;</description>
    </item>
    <item>
      <guid isPermaLink="false">http://ishanaj.wordpress.com/?p=74</guid>
      <author>Ishan Joshi (ishanaj)</author>
      <title>Ishan Joshi (ishanaj): GSoC&#x2019;19: Week-9- Analyzing the draw() function</title>
      <pubDate>Mon, 29 Jul 2019 05:43:20 GMT</pubDate>
      <link>https://ishanaj.wordpress.com/2019/07/29/gsoc19-week-9-analyzing-the-draw-function/</link>
      <description>&lt;p&gt;With the
end of this week the third phase officially ends. &lt;/p&gt;



&lt;p&gt;There has been some discussions in the &lt;a href="https://github.com/sympy/sympy/pull/17240"&gt;PR #17240&lt;/a&gt; which implements the &lt;strong&gt;draw() &lt;/strong&gt;function. We might change the name of the function to &lt;strong&gt;plot() &lt;/strong&gt;which is more consistent with the previous beam methods &lt;strong&gt;plot_shear_force()&lt;/strong&gt;, &lt;strong&gt;plot_bending_moment(), &lt;/strong&gt;etc.&lt;/p&gt;



&lt;p&gt;Another discussion was about making this beam diagram a part of the &lt;strong&gt;plot_loading_results(), &lt;/strong&gt;which basically intends to plot all the beam related plots. Although currently the beam diagram uses &lt;strong&gt;matplotlib &lt;/strong&gt;as an external module, whereas the &lt;strong&gt;plot_loading_results()&lt;/strong&gt; uses &lt;strong&gt;PlotGrid&lt;/strong&gt; which is Sympy&amp;#8217;s internal functionality. So it would be a bit tricky to merge those two.&lt;span id="more-74"&gt;&lt;/span&gt;&lt;/p&gt;



&lt;p&gt;We also discussed the idea or rather the possibility of directly making use of SymPy&amp;#8217;s own plot to create a beam diagram. SymPy&amp;#8217;s &lt;strong&gt;plot() &lt;/strong&gt;is capable to plotting Singularity functions, so the load applied on the beam can also be plotted using &lt;strong&gt;sympy.plot() &lt;/strong&gt;as beam.load is indeed in terms of singularity function. But there is a problem when it comes to point loads and moment loads as the are in terms singularity function of negative order (or exponent). Not sure whether the sympy plot for singularity functions of negative order is plotted correctly, but the current plot won&amp;#8217;t help us in drawing point loads and moment loads. We might have to deal with it separately.&lt;/p&gt;



&lt;p&gt;I have
opened a discussion in the &lt;a href="https://groups.google.com/forum/?fromgroups#!topic/sympy/gmBNI-sffls"&gt;mailing
list&lt;/a&gt; regarding whether the plot is correct for singularity functions of negative
order, or what else should be done in order to get it corrected.&lt;/p&gt;



&lt;p&gt;Also, it will be difficult to plot a rectangle (for making beam) and markers (for making supports) via sympy.plot(). One idea is to go with the &lt;strong&gt;_backend&lt;/strong&gt; attribute of sympy.plot() which helps in directly using the &lt;strong&gt;backend &lt;/strong&gt;(i.e. matplotlib backend). I will have a look over it.&lt;/p&gt;



&lt;p&gt;Of
course if the beam diagram is made using SymPy&amp;#8217;s own plot it would surely be
preferred but for that we also need work on &lt;strong&gt;sympy.plot()&lt;/strong&gt; as currently it is limited to certain functionalities.&lt;/p&gt;



&lt;p&gt;From the
next week I will be starting with the last phase of implementing a Truss structure
and its respective calculations.&lt;/p&gt;



&lt;p&gt;Since only last few weeks are left, I think I will be able to make a draft PR for the last phase implementation by the end of the next week. And then we would only be left with minor things and leftovers of the previous phases.&lt;/p&gt;



&lt;p&gt;Also, I am glad to share that I was able to pass the second evaluations. So once again thank you mentors for all your support and guidance!&lt;/p&gt;



&lt;h2&gt;&lt;strong&gt;Next Week:&lt;/strong&gt;&lt;/h2&gt;



&lt;ul&gt;&lt;li&gt;Starting phase-IV&amp;nbsp; implementations&lt;/li&gt;&lt;li&gt;Simultaneously working and discussing previous
PR&amp;#8217;s.&lt;/li&gt;&lt;/ul&gt;



&lt;p&gt;Will
keep you updated!&lt;/p&gt;



&lt;p&gt;Thanks!&lt;/p&gt;</description>
    </item>
    <item>
      <guid isPermaLink="false">https://divyanshu132.github.io//gsoc-week-9</guid>
      <author>Divyanshu Thakur (divyanshu132)</author>
      <title>Divyanshu Thakur (divyanshu132): GSoC 2019 - Week 9 - Merged Polycyclic groups</title>
      <pubDate>Mon, 29 Jul 2019 00:00:00 GMT</pubDate>
      <link>https://divyanshu132.github.io//gsoc-week-9</link>
      <description>&lt;p&gt;Hello everyone, the ninth week of coding period has ended and there is a really good news the polycyclic group PR &lt;a href="https://github.com/sympy/sympy/pull/16991"&gt;sympy/sympy#16991&lt;/a&gt; that we were working from the last one and half months is finally merged. This week I didn&amp;#8217;t do that much work except organizing different methods and fixing small issues in the above pr to get it merged.&lt;/p&gt;

&lt;p&gt;There has been a lot of rearrangement of methods, where most of the methods were moved to the class &lt;code class="highlighter-rouge"&gt;Collector&lt;/code&gt; from the class &lt;code class="highlighter-rouge"&gt;PolycyclicGroup&lt;/code&gt;. Now, we do not need free symbols in-hand, they can be computed by the Collector if not provided by the user. There are few more things which are changed like relative order is computed in the course of polycyclic sequence and series computation. For better look one can go through the above Pr.&lt;/p&gt;

&lt;p&gt;I&amp;#8217;m hopping to implement few things next week which are mentioned below.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Induced polycyclic sequence for a subgroup.&lt;/li&gt;
  &lt;li&gt;Get started with writing docs for polycyclic groups.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Till then, good byee..&lt;/p&gt;</description>
    </item>
    <item>
      <guid isPermaLink="false">http://ishanaj.wordpress.com/?p=60</guid>
      <author>Ishan Joshi (ishanaj)</author>
      <title>Ishan Joshi (ishanaj): GSoC&#x2019;19: Week-8- The draw() function in action</title>
      <pubDate>Mon, 22 Jul 2019 04:50:39 GMT</pubDate>
      <link>https://ishanaj.wordpress.com/2019/07/22/gsoc19-week-8-the-draw-function-in-action/</link>
      <description>&lt;p&gt;The 8&lt;sup&gt;th&lt;/sup&gt; week has ended and we are now in the middle of phase &amp;#8211;III.&lt;/p&gt;



&lt;p&gt;Last week was a bit of research-based, understanding &lt;strong&gt;matplotlib &lt;/strong&gt;and how it can be used to plot a beam diagram. I had a conversation with Jason Moore and Jashan where Jason shared a link of a &lt;a href="https://github.com/alfredocarella/simplebendingpractice"&gt;repository&lt;/a&gt;, which also was a bit of help as I took some hints from it for the &lt;strong&gt;draw() &lt;/strong&gt;function. After a lot of investigation and analysis, I was finally able to make a draft &lt;a href="https://github.com/sympy/sympy/pull/17240"&gt;PR # 17240&lt;/a&gt; which did the work as we intended.&lt;/p&gt;



&lt;p&gt;Here is an example of how it would function:&lt;span id="more-60"&gt;&lt;/span&gt;&lt;/p&gt;


&lt;pre class="brush: python; collapse: false; title: ; wrap-lines: false; notranslate"&gt;

# This example has no prior logic involved. It just tests whether every functionality works or not

&amp;gt;&amp;gt;&amp;gt; E, I = symbols('E, I')

&amp;gt;&amp;gt;&amp;gt; b1 = Beam(50, E, I)

&amp;gt;&amp;gt;&amp;gt; b1.apply_load(-10, 0, -1)

&amp;gt;&amp;gt;&amp;gt; b1.apply_load(R1, 10, -1)

&amp;gt;&amp;gt;&amp;gt; b1.apply_load(R2, 30, -1)

&amp;gt;&amp;gt;&amp;gt; b1.apply_load(9, 5, 0, 23)

&amp;gt;&amp;gt;&amp;gt; b1.apply_load(9, 30, 1, 50)

&amp;gt;&amp;gt;&amp;gt; b1.apply_support(50, "pin")

&amp;gt;&amp;gt;&amp;gt; b1.apply_support(0, "fixed")

&amp;gt;&amp;gt;&amp;gt; b1.apply_support(20, "roller")

&amp;gt;&amp;gt;&amp;gt; b1.draw()

&lt;/pre&gt;



&lt;figure class="wp-block-image size-large is-resized .single-blog-image {display: none; }"&gt;&lt;img alt="" class="wp-image-62" height="387" src="https://ishanaj.files.wordpress.com/2019/07/61594696-552b5900-ac0c-11e9-96f9-4ba257dbf92c-1.png" width="467" /&gt;&lt;/figure&gt;



&lt;p&gt;Here we are using &lt;strong&gt;matplotlib&lt;/strong&gt; and &lt;strong&gt;numpy&lt;/strong&gt; by importing them as external modules. Of course, it would be better to have it done via &lt;strong&gt;SymPy&amp;#8217;s&lt;/strong&gt; own &lt;strong&gt;plot()&lt;/strong&gt;, but I think that is something we could work on in later stages as&lt;strong&gt; SymPy&amp;#8217;s plot()&lt;/strong&gt; is limited to work on equations and stuff (although on can use &lt;strong&gt;_backend &lt;/strong&gt;attribute for further functionalities). &amp;nbsp;Also to be noted here that &lt;strong&gt;SymPy&amp;#8217;s plot()&lt;/strong&gt; is not a replica of &lt;strong&gt;matplotib&amp;#8217;s plot()&lt;/strong&gt; but it makes it easier for SymPy equation to be plotted and it uses&amp;nbsp;&lt;strong&gt;matplotlib&lt;/strong&gt; to do so.&lt;/p&gt;



&lt;p&gt;Following are the&lt;strong&gt; m&lt;/strong&gt;&lt;strong&gt;atplotlib&lt;/strong&gt; modules/classes used:&lt;/p&gt;



&lt;ul&gt;&lt;li&gt;&lt;a href="https://matplotlib.org/api/_as_gen/matplotlib.patches.Rectangle.html"&gt;matplotlib.patches.Rectangle&lt;/a&gt;&amp;nbsp;-to draw the beam&lt;/li&gt;&lt;li&gt;&lt;a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.annotate.html"&gt;matplotlib.pyplot.annotate&lt;/a&gt;&amp;nbsp;&amp;#8211; to draw arrows of load&lt;/li&gt;&lt;li&gt;&lt;a href="https://matplotlib.org/3.1.1/api/markers_api.html"&gt;matplotlib.markers&lt;/a&gt;&amp;#8211; to draw supports&lt;/li&gt;&lt;/ul&gt;



&lt;p&gt;Also, considering Jason&amp;#8217;s &lt;a href="https://github.com/sympy/sympy/pull/17240#issuecomment-513577696"&gt;comment&lt;/a&gt; in the PR, I will have to work on making &lt;strong&gt;SymPy&amp;#8217;s plot()&lt;/strong&gt; to accept a singularity function, so that it would be easier to plot &lt;strong&gt;loads &lt;/strong&gt;which are indeed equations of Singularity function. This is still in consideration, so I will have to look into it and of course will have a discussion on how it is to be done.&lt;/p&gt;



&lt;p&gt;Currently, I am not able to determine how to plot parabolic loads. I think this could be added later as we should currently focus on plotting simple parts and certainly work on other complexities later. But we can have a discussion on it.&lt;/p&gt;



&lt;p&gt;Other PR&amp;#8217;s are still being parallelly worked on.&lt;/p&gt;



&lt;h2&gt;&lt;strong&gt;Next Week:&lt;/strong&gt;&lt;/h2&gt;



&lt;ul&gt;&lt;li&gt;Working on the idea of plotting singularity function via SymPy&amp;#8217;s plot()&lt;/li&gt;&lt;li&gt;Plotting parabolic loads&lt;/li&gt;&lt;li&gt;Writing documentation and tests&lt;/li&gt;&lt;/ul&gt;



&lt;p&gt;Will keep you updated!&lt;/p&gt;



&lt;p&gt;Thanks!&lt;/p&gt;</description>
    </item>
    <item>
      <guid isPermaLink="false">https://anpandey.github.io/posts/sympy/2019-07-30-week-9.html</guid>
      <author>Ankit Pandey (anpandey)</author>
      <title>Ankit Pandey (anpandey): Google Summer of Code Week 9: Matrices to Indexed</title>
      <pubDate>Mon, 22 Jul 2019 00:00:00 GMT</pubDate>
      <link>https://anpandey.github.io/posts/sympy/2019-07-30-week-9.html</link>
      <description>&lt;p&gt;&lt;em&gt;See the &lt;a href="https://anpandey.github.io/2019-07-22-week-8.html"&gt;previous post&lt;/a&gt; for Week 8&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;For this week, I&amp;#8217;ve started with &lt;a href="https://github.com/sympy/sympy/pull/17299"&gt;#17299&lt;/a&gt;. This pull request is meant to extend support for the &lt;code&gt;MatrixExpr&lt;/code&gt; class by allowing for conversion into an &lt;code&gt;Indexed&lt;/code&gt; class in which contractions equivalent to the matrix expression are represented.&lt;/p&gt;
&lt;h2 id="conversion-to-indexed"&gt;Conversion to &lt;code&gt;Indexed&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;as_indexed&lt;/code&gt; method that the pull request introduces is pretty self-explanatory:&lt;/p&gt;
&lt;div class="sourceCode" id="cb1"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb1-1" title="1"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; n, m &lt;span class="op"&gt;=&lt;/span&gt; symbols(&lt;span class="st"&gt;'n m'&lt;/span&gt;, integer&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-2" title="2"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; A &lt;span class="op"&gt;=&lt;/span&gt; MatrixSymbol(&lt;span class="st"&gt;'A'&lt;/span&gt;, n, m)&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-3" title="3"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; B &lt;span class="op"&gt;=&lt;/span&gt; MatrixSymbol(&lt;span class="st"&gt;'B'&lt;/span&gt;, m, n)&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-4" title="4"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; e &lt;span class="op"&gt;=&lt;/span&gt; A&lt;span class="op"&gt;*&lt;/span&gt;B&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-5" title="5"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; e.as_indexed()&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-6" title="6"&gt;A[i, j]&lt;span class="op"&gt;*&lt;/span&gt;B[j, k]&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;A matrix multiplication between two matrix symbols is equivalent to a contraction along the index &lt;span class="math inline"&gt;&lt;em&gt;j&lt;/em&gt;&lt;/span&gt; (Since matrix multiplication is equivalent to a contraction along a single index).&lt;/p&gt;
&lt;h3 id="relationship-to-codegen"&gt;Relationship to Codegen&lt;/h3&gt;
&lt;p&gt;The purpose of the pull request is to allow conversion to help in the generation of code related to some matrix expressions. This is because there&amp;#8217;s already an existing infrastructure for code generation through contractions (something that the still-WIP &lt;a href="https://github.com/sympy/sympy/pull/17170"&gt;#17170&lt;/a&gt; addresses). The currently work in progress PR is meant to aid in extending code generation to matrix expressions instead of just &lt;code&gt;Indexed&lt;/code&gt; objects. This same conversion might also be possible using the &lt;code&gt;Codegen*&lt;/code&gt; classes in &lt;code&gt;array_utils&lt;/code&gt;, though this way seems to make more sense since it&amp;#8217;s entirely possible to use the function for non-codegen related purposes.&lt;/p&gt;
&lt;h2 id="next-steps"&gt;Next steps&lt;/h2&gt;
&lt;p&gt;My plans for this week are to continue working on the pull request and start with the new Matrix Wildcard pull request.&lt;/p&gt;</description>
    </item>
    <item>
      <guid isPermaLink="false">https://anpandey.github.io/posts/sympy/2019-07-22-week-8.html</guid>
      <author>Ankit Pandey (anpandey)</author>
      <title>Ankit Pandey (anpandey): Google Summer of Code Week 8: Non-Commutative Wildcards</title>
      <pubDate>Mon, 22 Jul 2019 00:00:00 GMT</pubDate>
      <link>https://anpandey.github.io/posts/sympy/2019-07-22-week-8.html</link>
      <description>&lt;p&gt;&lt;em&gt;See the &lt;a href="https://anpandey.github.io/2019-07-14-week-7.html"&gt;previous post&lt;/a&gt; for Week 7&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;I spent most of this week rewriting the non-commutative matching code in Sympy&amp;#8217;s core as Aaron suggested. The pull request for this rewrite is available at &lt;a href="https://github.com/sympy/sympy/pull/17223"&gt;#17223&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="non-commutative-matching-in-sympy"&gt;Non-commutative matching in SymPy&lt;/h2&gt;
&lt;p&gt;SymPy already supports matching within non-commutative multiplication expressions. While I mentioned in my last blog post that this matching support was limited, I&amp;#8217;ll go into a bit more detail about what those limitations (which sometimes produce wrong results) are:&lt;/p&gt;
&lt;h3 id="no-matching-based-on-structure"&gt;No matching based on structure&lt;/h3&gt;
&lt;p&gt;Matching within commutative SymPy expressions allows for taking the structure of expressions into account. Two commutative SymPy expressions match only if both contain the same non-wildcard symbols:&lt;/p&gt;
&lt;div class="sourceCode" id="cb1"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb1-1" title="1"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="im"&gt;from&lt;/span&gt; sympy.abc &lt;span class="im"&gt;import&lt;/span&gt; a, x, y, z&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-2" title="2"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; w &lt;span class="op"&gt;=&lt;/span&gt; Wild(&lt;span class="st"&gt;'w'&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-3" title="3"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; m &lt;span class="op"&gt;=&lt;/span&gt; x&lt;span class="op"&gt;*&lt;/span&gt;y&lt;span class="op"&gt;*&lt;/span&gt;w&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-4" title="4"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; m.matches(x&lt;span class="op"&gt;*&lt;/span&gt;y&lt;span class="op"&gt;*&lt;/span&gt;z)&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-5" title="5"&gt;{w_: z}&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-6" title="6"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; m.matches(a&lt;span class="op"&gt;*&lt;/span&gt;x&lt;span class="op"&gt;*&lt;/span&gt;z)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;code&gt;m&lt;/code&gt; specifies that the expression must contain both &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; in addition to whatever the wildcard matches. For this reason, &lt;code&gt;m&lt;/code&gt; matches &lt;code&gt;x*y*z&lt;/code&gt; but not &lt;code&gt;a*x*z&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The corresponding example for non-commutative expressions does not work as expected, as it does not match when we expect it to:&lt;/p&gt;
&lt;div class="sourceCode" id="cb2"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb2-1" title="1"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; A, B, C, D &lt;span class="op"&gt;=&lt;/span&gt; symbols(&lt;span class="st"&gt;'A:D'&lt;/span&gt;, commutative&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;False&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-2" title="2"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; W &lt;span class="op"&gt;=&lt;/span&gt; Wild(&lt;span class="st"&gt;'W'&lt;/span&gt;, commutative&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;False&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-3" title="3"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; M &lt;span class="op"&gt;=&lt;/span&gt; A&lt;span class="op"&gt;*&lt;/span&gt;B&lt;span class="op"&gt;*&lt;/span&gt;W&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-4" title="4"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; M.matches(A&lt;span class="op"&gt;*&lt;/span&gt;B&lt;span class="op"&gt;*&lt;/span&gt;C)&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-5" title="5"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; M.matches(A&lt;span class="op"&gt;*&lt;/span&gt;D&lt;span class="op"&gt;*&lt;/span&gt;C)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="expressions-dont-respect-non-commutativity"&gt;Expressions don&amp;#8217;t respect non-commutativity&lt;/h3&gt;
&lt;p&gt;In instances where matching does seem to work, the non-commutativity of expressions is not respected:&lt;/p&gt;
&lt;div class="sourceCode" id="cb3"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb3-1" title="1"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; A, B, C, D &lt;span class="op"&gt;=&lt;/span&gt; symbols(&lt;span class="st"&gt;'A:D'&lt;/span&gt;, commutative&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;False&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-2" title="2"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; w &lt;span class="op"&gt;=&lt;/span&gt; Wild(&lt;span class="st"&gt;'w'&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-3" title="3"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="im"&gt;from&lt;/span&gt; sympy.abc &lt;span class="im"&gt;import&lt;/span&gt; x&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-4" title="4"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; (w&lt;span class="op"&gt;*&lt;/span&gt;A&lt;span class="op"&gt;*&lt;/span&gt;B&lt;span class="op"&gt;*&lt;/span&gt;C).matches(x&lt;span class="op"&gt;*&lt;/span&gt;C&lt;span class="op"&gt;*&lt;/span&gt;B&lt;span class="op"&gt;*&lt;/span&gt;A)&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-5" title="5"&gt;{w_: x}&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The two expressions should &lt;em&gt;not&lt;/em&gt; have matched, since the order of the non-commutative expressions were different. I reported this same error for matrix expressions in issue &lt;a href="https://github.com/sympy/sympy/issues/17172"&gt;#17172&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="sub-expressions-arent-expanded"&gt;Sub-expressions aren&amp;#8217;t expanded&lt;/h3&gt;
&lt;p&gt;The matching code should be able to match portions of powers, which are represented differently in the SymPy AST. As an example, a non-commutative matcher such as &lt;span class="math inline"&gt;&lt;em&gt;A&lt;/em&gt;&lt;em&gt;W&lt;/em&gt;&lt;/span&gt; (where &lt;span class="math inline"&gt;&lt;em&gt;W&lt;/em&gt;&lt;/span&gt; is a wildcard) should match &lt;span class="math inline"&gt;&lt;em&gt;A&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/span&gt; with &lt;span class="math inline"&gt;{&lt;em&gt;W&lt;/em&gt;&amp;#8196;&amp;#8614;&amp;#8196;&lt;em&gt;A&lt;/em&gt;}&lt;/span&gt;. I wasn&amp;#8217;t able create a working example of this using the existing matching code.&lt;/p&gt;
&lt;h2 id="matching-implementation"&gt;Matching Implementation&lt;/h2&gt;
&lt;p&gt;Since order needs to be taken into account for matching non-commutative expressions, the new matching code essentially does what a regular expression matcher would do, with nodes taking the place of characters and wildcards taking the place of the &lt;code&gt;.+&lt;/code&gt; regular expression.&lt;/p&gt;
&lt;h2 id="next-steps"&gt;Next Steps&lt;/h2&gt;
&lt;p&gt;The matching PR still needs to be polished, and the related documentation needs to be updated, so I&amp;#8217;ll be working on that. I&amp;#8217;ll also start with extending matrix matching from this PR.&lt;/p&gt;</description>
    </item>
    <item>
      <guid isPermaLink="false">https://divyanshu132.github.io//gsoc-week-8</guid>
      <author>Divyanshu Thakur (divyanshu132)</author>
      <title>Divyanshu Thakur (divyanshu132): GSoC 2019 - Week 8 - Phase-II Completion</title>
      <pubDate>Sat, 20 Jul 2019 00:00:00 GMT</pubDate>
      <link>https://divyanshu132.github.io//gsoc-week-8</link>
      <description>&lt;p&gt;Phase-II has been completed and now it&amp;#8217;s time to present all the work done during this phase. This week&amp;#8217;s blog is little early in comparison to my previous blogs because I&amp;#8217;ll not be active for next 2 upcoming days. In the whole phase we worked on &lt;strong&gt;Computations with Polycyclic Groups&lt;/strong&gt; though the tasks mentioned in proposal for this phase were quite different. But let me tell you it worth that much time, Computation with Polycyclic groups(solvable groups) shows the actual development in computational group theory.&lt;/p&gt;

&lt;p&gt;Below are the functioalities that were added to the polycyclic group in this phase, Here is the PR &lt;a href="https://github.com/sympy/sympy/pull/16991"&gt;sympy/sympy#16991&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Testing Collector&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;As discussed in &lt;a href="https://divyanshu132.github.io/gsoc-week-5"&gt;week-5 blog&lt;/a&gt; at the time of Collector implementation we did not have the implementation of polycyclic presentation so some hand made tests were used. Here is an example of &lt;code class="highlighter-rouge"&gt;S(4)&lt;/code&gt;.&lt;/p&gt;

&lt;div class="highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; from sympy.combinatorics import *
&amp;gt;&amp;gt;&amp;gt; from sympy.combinatorics.free_groups import free_group
&amp;gt;&amp;gt;&amp;gt; F, x0, x1, x2, x3 = free_group("x0, x1, x2, x3")
&amp;gt;&amp;gt;&amp;gt; pc_relators = { x0**2: (), x1**3: (), x2**2: (), x3**2: (),
...                 x0**-1*x1*x0: x1**2, x0**-1*x2*x0: x2*x3,
...                 x0**-1*x3*x0: x3, x1**-1*x2*x1: x3,
...                 x1**-1*x3*x1: x2*x3, x2**-1*x3*x2: x3
...               }
&amp;gt;&amp;gt;&amp;gt; word = x3*x2*x1*x0
&amp;gt;&amp;gt;&amp;gt; relative_order = [2, 3, 2, 2]
&amp;gt;&amp;gt;&amp;gt; group = word.group
&amp;gt;&amp;gt;&amp;gt; collector = Collector(pc_relators, relative_order, group)
&amp;gt;&amp;gt;&amp;gt; collector.collected_word(word)
x0*x1**2*x2*x3

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The final word &lt;code class="highlighter-rouge"&gt;x0*x1**2*x2*x3&lt;/code&gt; is said to be collected. For more information about collected word please look into the docstrings of the method &lt;code class="highlighter-rouge"&gt;Collector.collected_word()&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Computation of Polycyclic Sequence and Series&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Polycyclic sequence and series are the building blocks of polycyclic presentation (have a look at &lt;a href="https://divyanshu132.github.io/gsoc-week-6"&gt;week-6 blog&lt;/a&gt;) . One thing to note is that, the derived series of a group may change on different course of execution so we may have different pc sequence and series for the same group.&lt;/p&gt;

&lt;div class="highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; from sympy.combinatorics import *
&amp;gt;&amp;gt;&amp;gt; G = SymmetricGroup(4)
&amp;gt;&amp;gt;&amp;gt; PcGroup = G.polycyclic_group()
&amp;gt;&amp;gt;&amp;gt; PcGroup.pcgs
[Permutation(0, 1, 2, 3), Permutation(3)(0, 2, 1), Permutation(0, 3)(1, 2), Permutation(0, 1)(2, 3)]
&amp;gt;&amp;gt;&amp;gt; 
&amp;gt;&amp;gt;&amp;gt; PcGroup.pc_series[0] == G
True
&amp;gt;&amp;gt;&amp;gt; PcGroup.pc_series[1] == AlternatingGroup(4)
True
&amp;gt;&amp;gt;&amp;gt; PcGroup.relative_order()
[2, 3, 2, 2]

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Computation of Polycyclic Presentation&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Few approaches were used to compute polycyclic presentation, the current implementation is discussed in &lt;a href="https://divyanshu132.github.io/gsoc-week-7"&gt;week-7 blog&lt;/a&gt;. Below is a small example to show the functionality.&lt;/p&gt;

&lt;div class="highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; from sympy.combinatorics import *
&amp;gt;&amp;gt;&amp;gt; G = SymmetricGroup(4)
&amp;gt;&amp;gt;&amp;gt; PcGroup = G.polycyclic_group()
&amp;gt;&amp;gt;&amp;gt; from sympy.combinatorics.free_groups import free_group
&amp;gt;&amp;gt;&amp;gt; len(PcGroup.pcgs)
4
&amp;gt;&amp;gt;&amp;gt; free_group, x0, x1, x2, x3 = free_group("x0, x1, x2, x3")
&amp;gt;&amp;gt;&amp;gt; PcGroup.pc_presentation(free_group)
{x3**2: (), x2**2: (), x2**-1*x3*x2: x3, x1**3: (), x1**-1*x3*x1: x2*x3, x1**-1*x2*x1: x3, x0**2: x2*x3, x0**-1*x3*x0: x2, x0**-1*x2*x0: x3, x0**-1*x1*x0: x1**2*x3}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;As I mentioned above &lt;code class="highlighter-rouge"&gt;pc_sequence&lt;/code&gt; and &lt;code class="highlighter-rouge"&gt;pc_series&lt;/code&gt; may change on different course of execution and hence the &lt;code class="highlighter-rouge"&gt;pc_presentation&lt;/code&gt; changes accordingly.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Testing Presentation&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Due to the changing &lt;code class="highlighter-rouge"&gt;pc_presentation&lt;/code&gt; initially, it was difficult to test presentation but later on a method has been developed and a good amount of code is introduced to test the presentation. The details can be found in the module &lt;code class="highlighter-rouge"&gt;test_pc_groups.py&lt;/code&gt; in the above PR.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Additional methods for Polycyclic groups&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;There were few additional methods added to the polycyclic group.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class="highlighter-rouge"&gt;exponent_vector()&lt;/code&gt; :- It represents the given generator of a polycyclic group with the help of product of &lt;code class="highlighter-rouge"&gt;pcgs&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class="highlighter-rouge"&gt;depth()&lt;/code&gt; :- Depth of the first non-zero element in &lt;code class="highlighter-rouge"&gt;exponent_vector&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class="highlighter-rouge"&gt;leading_exponent()&lt;/code&gt; :- It represents the power of polycyclic generator at the above depth.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class="highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; from sympy.combinatorics import *
&amp;gt;&amp;gt;&amp;gt; from sympy.combinatorics.free_groups import free_group
&amp;gt;&amp;gt;&amp;gt; G = SymmetricGroup(4)
&amp;gt;&amp;gt;&amp;gt; PcGroup = G.polycyclic_group()
&amp;gt;&amp;gt;&amp;gt; pcgs = PcGroup.pcgs
&amp;gt;&amp;gt;&amp;gt; len(pcgs)
4
&amp;gt;&amp;gt;&amp;gt; free_group, x0, x1, x2, x3 = free_group("x0, x1, x2, x3")
&amp;gt;&amp;gt;&amp;gt; PcGroup.exponent_vector(G[1], F)
[1, 1, 1, 1]
&amp;gt;&amp;gt;&amp;gt; G[1] == pcgs[0]*pcgs[1]*pcgs[2]*pcgs[3]
True
&amp;gt;&amp;gt;&amp;gt; PcGroup.depth(G[1], free_group) == 1
&amp;gt;&amp;gt;&amp;gt; PcGroup.leading_exponent(G[1], free_group) == 1

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Currently, we are discussing about organizing above methods of polycyclic group. As Kalevi feels that the suitable place for &lt;code class="highlighter-rouge"&gt;pc_presentation&lt;/code&gt;(currently, it&amp;#8217;s a method of &lt;code class="highlighter-rouge"&gt;PolycyclicGroup class&lt;/code&gt;) is the &lt;code class="highlighter-rouge"&gt;Collector class&lt;/code&gt;, Perhaps the structure of both the classes should be changed and the same will be reflected in the examples mentioned above.&lt;/p&gt;</description>
    </item>
    <item>
      <guid isPermaLink="false">http://ishanaj.wordpress.com/?p=58</guid>
      <author>Ishan Joshi (ishanaj)</author>
      <title>Ishan Joshi (ishanaj): GSoC&#x2019;19: Week-7- Starting with the phase-III draw() function</title>
      <pubDate>Mon, 15 Jul 2019 03:02:10 GMT</pubDate>
      <link>https://ishanaj.wordpress.com/2019/07/15/gsoc19-week-7-starting-with-the-phase-iii-draw-function/</link>
      <description>&lt;p&gt;The week was successfully completed as planned. The work on &lt;a href="https://github.com/sympy/sympy/pull/17122"&gt;Column class&lt;/a&gt; has been completed.&lt;/p&gt;



&lt;p&gt;The documentation and tests have been written and with some changes in the &lt;strong&gt;solve_slope_deflection()&lt;/strong&gt; and &lt;strong&gt;critical_load(),&lt;/strong&gt; the &lt;strong&gt;Column&lt;/strong&gt; class is now able to handle cases with trivial solutions of the constants ( C1 &amp;amp; C2) which made the deflection equation zero.&lt;/p&gt;



&lt;p&gt;Apart from this, another problem that we had with the &lt;strong&gt;pinned-fixed&lt;/strong&gt; end condition, where &lt;strong&gt;solve()&lt;/strong&gt; wasn&amp;#8217;t giving the output in the required form, has temporary been handled by making an &lt;strong&gt;XFAIL &lt;/strong&gt;test against it. We can work on it later. Either there has to be some changes in &lt;strong&gt;solve()&lt;/strong&gt;&amp;nbsp;so that we would be able to handle our case or we might have to figure out a way to rewrite it into the desired form.&lt;span id="more-58"&gt;&lt;/span&gt;&lt;/p&gt;



&lt;p&gt;With the end of this week,&amp;nbsp;&lt;a href="https://github.com/sympy/sympy/pull/17122"&gt;PR #17122&lt;/a&gt; and &lt;a href="https://github.com/sympy/sympy/pull/17153"&gt;PR #17153&lt;/a&gt; are complete and ready for review. I have made some changes addressing some of the reviews, and we can have further discussions on it.&lt;/p&gt;



&lt;p&gt;Now, also moving on to the next phase, I have done a bit of research on it. I will most probably open a discussion to have an initial discussion regarding how work will progress in this stage. This phase is regarding plotting the beam diagrams using &lt;a href="https://matplotlib.org/"&gt;matplotlib&lt;/a&gt;. I have also considered &lt;strong&gt;pyglet&lt;/strong&gt; plotting module of SymPy, which according to the &lt;a href="https://docs.sympy.org/latest/modules/plotting.html#plotting-geometric-entities"&gt;documentation&lt;/a&gt; is capable of plotting geometries, but there has been some problems in this module and it doesn&amp;#8217;t seem to be working well. I had earlier made an &lt;a href="https://github.com/sympy/sympy/issues/16537"&gt;issue #16537&lt;/a&gt; regarding the same, but there seems to be no improvement here.&lt;/p&gt;



&lt;p&gt;So, we will be discussing the rest in an issue-cum-discussion, in the upcoming week.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Next week:&lt;/strong&gt;&lt;/p&gt;



&lt;ul&gt;&lt;li&gt;Working on the Stage-III&lt;/li&gt;&lt;li&gt;Simultaneously, discussing the leftover PR&amp;#8217;s and trying to finish them and make a merge.&lt;/li&gt;&lt;/ul&gt;



&lt;p&gt;Most probably, on successful discussion and planning, I will be opening a draft work-in-progress PR for the &lt;strong&gt;draw()&lt;/strong&gt; function in stage &amp;#8211;III.&lt;/p&gt;



&lt;p&gt;Will keep you updated!&lt;/p&gt;



&lt;p&gt;Thanks!&lt;/p&gt;</description>
    </item>
    <item>
      <guid isPermaLink="false">https://divyanshu132.github.io//gsoc-week-7</guid>
      <author>Divyanshu Thakur (divyanshu132)</author>
      <title>Divyanshu Thakur (divyanshu132): GSoC 2019 - Week 7 - Modify Presentation and Addition of Methods</title>
      <pubDate>Mon, 15 Jul 2019 00:00:00 GMT</pubDate>
      <link>https://divyanshu132.github.io//gsoc-week-7</link>
      <description>&lt;p&gt;The seventh week of coding period has ended and a few methods has been introduced to polycyclic groups, also pc presentation has been modified. Previously for pc presentation we were computing the LHS for both power and conjugate relators via separate methods and then finally their RHS was computed.&lt;/p&gt;

&lt;p&gt;Now, the computation of presentation starts from the bottom of the polycyclic generating sequence(pcgs) and polycyclic series. Storing all the previous generators from pcgs and then taking the last generator as the generator which acts as a conjugator and conjugates all the previous generators in the list.&lt;/p&gt;

&lt;p&gt;To get a clear picture let&amp;#8217;s take an example of &lt;code class="highlighter-rouge"&gt;S(4)&lt;/code&gt;
For S(4) we&amp;#8217;ll have 4 generators in pcgs say &lt;code class="highlighter-rouge"&gt;[x0, x1, x2, x3]&lt;/code&gt; and the &lt;code class="highlighter-rouge"&gt;relative_order vector as [2, 3, 2, 2]&lt;/code&gt;. Starting from bottom of this sequence the presentation is computed in order as below.&lt;/p&gt;

&lt;div class="highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;x3**2	       	---| ---&amp;gt; using only [x3] from pcgs and pc_series[1]
x2**2		   |
x2**-1*x3*x2	---| from bottom up because pc_series[0] is an identity.

x1**3		---| ---&amp;gt; using [x3, x2] from pcgs and pc_series[2]	
x1**-1*x3*x1	   | 
x1**-1*x2*x1	---|      from bottom up(which have both the gens).

x0**2		---| ---&amp;gt; using [x3, x2, x1] from pcgs and pc_series[3]
x0**-1*x3*x0	   |
x0**-1*x2*x0	   |      from bottom up(which have all three gens).
x0**-1*x1*x0	---|

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;There were 3-methods which were added namely:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Exponent vector&lt;/li&gt;
  &lt;li&gt;Depth&lt;/li&gt;
  &lt;li&gt;Leading Exponent&lt;/li&gt;
&lt;/ul&gt;

&lt;div class="highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; from sympy.combinatorics import *
&amp;gt;&amp;gt;&amp;gt; from sympy.combinatorics.free_groups import free_group
&amp;gt;&amp;gt;&amp;gt; G = SymmetricGroup(4)
&amp;gt;&amp;gt;&amp;gt; PcGroup = G.polycyclic_group()
&amp;gt;&amp;gt;&amp;gt; pcgs = PcGroup.pcgs
&amp;gt;&amp;gt;&amp;gt; group, x0, x1, x2, x3 = free_group("x0, x1, x2, x3")
&amp;gt;&amp;gt;&amp;gt; PcGroup.exponent_vector(G[0], group)
[1, 0, 0, 0]
&amp;gt;&amp;gt;&amp;gt; exp = PcGroup.exponent_vector(G[1], group)
&amp;gt;&amp;gt;&amp;gt; g = Permutation()
&amp;gt;&amp;gt;&amp;gt; for i in range(len(exp)):
...     g = g*pcgs[i] if exp[i] else g
... 
&amp;gt;&amp;gt;&amp;gt; g == G[1]
True
&amp;gt;&amp;gt;&amp;gt; 

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;For the details of these methods one can look into the docstrings and doctests of these methods in the PR &lt;a href="https://github.com/sympy/sympy/pull/16991"&gt;sympy/sympy#16991&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Tasks I hope to complete next week:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Get the polycyclic group pr ready to be merged.&lt;/li&gt;
  &lt;li&gt;Get started with quotient groups.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Till then good byee..&lt;/p&gt;</description>
    </item>
    <item>
      <guid isPermaLink="false">https://anpandey.github.io/posts/sympy/2019-07-14-week-7.html</guid>
      <author>Ankit Pandey (anpandey)</author>
      <title>Ankit Pandey (anpandey): Google Summer of Code Week 7: Matrix Wildcards</title>
      <pubDate>Sun, 14 Jul 2019 00:00:00 GMT</pubDate>
      <link>https://anpandey.github.io/posts/sympy/2019-07-14-week-7.html</link>
      <description>&lt;p&gt;&lt;em&gt;See the &lt;a href="https://anpandey.github.io/2019-07-07-week-6.html"&gt;previous post&lt;/a&gt; for Week 6&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;I spent most of this week on extending wildcard support for matrix expressions, along with some more explorations in printing array contractions.&lt;/p&gt;
&lt;h2 id="matrices-and-wildcards"&gt;Matrices and Wildcards&lt;/h2&gt;
&lt;p&gt;As I&amp;#8217;ve probably mentioned in the last two blog posts, SymPy&amp;#8217;s support for matching matrix expressions through the &lt;code&gt;Wild&lt;/code&gt; class is currently severely limited (&lt;a href="https://github.com/sympy/sympy/issues/17172"&gt;when it works&lt;/a&gt;). While it is possible to construct a non-commutative &lt;code&gt;Wild&lt;/code&gt;, it isn&amp;#8217;t able to match expressions in a matrix multiplication:&lt;/p&gt;
&lt;div class="sourceCode" id="cb1"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb1-1" title="1"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; W, X &lt;span class="op"&gt;=&lt;/span&gt; symbols(&lt;span class="st"&gt;'W, X'&lt;/span&gt;, cls&lt;span class="op"&gt;=&lt;/span&gt;Wild, commutative&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;False&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-2" title="2"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="im"&gt;from&lt;/span&gt; sympy.abc &lt;span class="im"&gt;import&lt;/span&gt;  N&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-3" title="3"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; A, B &lt;span class="op"&gt;=&lt;/span&gt; MatrixSymbol(&lt;span class="st"&gt;'A'&lt;/span&gt;, N, N), MatrixSymbol(&lt;span class="st"&gt;'B'&lt;/span&gt;, N, N)&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-4" title="4"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="bu"&gt;type&lt;/span&gt;((A &lt;span class="op"&gt;*&lt;/span&gt; B).match(W &lt;span class="op"&gt;*&lt;/span&gt; X))&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-5" title="5"&gt;&lt;span class="op"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kw"&gt;class&lt;/span&gt; &lt;span class="st"&gt;'NoneType'&lt;/span&gt;&lt;span class="op"&gt;&amp;gt;&lt;/span&gt;&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It&amp;#8217;s also currently not possible to combine matrices and wildcards in expressions, since wildcards don&amp;#8217;t have a defined shape and so may only function as scalars:&lt;/p&gt;
&lt;div class="sourceCode" id="cb2"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb2-1" title="1"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; W &lt;span class="op"&gt;+&lt;/span&gt; A&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-2" title="2"&gt;&lt;span class="pp"&gt;TypeError&lt;/span&gt;: Mix of Matrix &lt;span class="kw"&gt;and&lt;/span&gt; Scalar symbols&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-3" title="3"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; W &lt;span class="op"&gt;*&lt;/span&gt; A&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-4" title="4"&gt;&lt;span class="pp"&gt;NotImplementedError&lt;/span&gt;: noncommutative scalars &lt;span class="kw"&gt;in&lt;/span&gt; MatMul are &lt;span class="kw"&gt;not&lt;/span&gt; supported.&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="matrixwild"&gt;&lt;code&gt;MatrixWild&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;I spent most of this week working on &lt;a href="https://github.com/sympy/sympy/pull/17177"&gt;#17177&lt;/a&gt;, which implements a &lt;code&gt;MatrixWild&lt;/code&gt; class that functions as both a wildcard and a matrix expression. In order to construct the wildcard, we need to give it a shape:&lt;/p&gt;
&lt;div class="sourceCode" id="cb3"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb3-1" title="1"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="im"&gt;from&lt;/span&gt; sympy.abc &lt;span class="im"&gt;import&lt;/span&gt; N&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-2" title="2"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="im"&gt;from&lt;/span&gt; sympy.matrices.expressions.matexpr &lt;span class="im"&gt;import&lt;/span&gt; MatrixWild&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-3" title="3"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; W, X &lt;span class="op"&gt;=&lt;/span&gt; MatrixWild(&lt;span class="st"&gt;'W'&lt;/span&gt;, N, N), MatrixWild(&lt;span class="st"&gt;'X'&lt;/span&gt;, N, N)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Unlike in the example above using &lt;code&gt;Wild&lt;/code&gt;, compound expressions are able to match against a matrix multiplication:&lt;/p&gt;
&lt;div class="sourceCode" id="cb4"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb4-1" title="1"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; A, B &lt;span class="op"&gt;=&lt;/span&gt; MatrixSymbol(&lt;span class="st"&gt;'A'&lt;/span&gt;, N, N), MatrixSymbol(&lt;span class="st"&gt;'B'&lt;/span&gt;, N, N)&lt;/a&gt;
&lt;a class="sourceLine" id="cb4-2" title="2"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; (A &lt;span class="op"&gt;*&lt;/span&gt; B).match(W &lt;span class="op"&gt;*&lt;/span&gt; X)&lt;/a&gt;
&lt;a class="sourceLine" id="cb4-3" title="3"&gt;{W_: A, X_: B}&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note that in order for matrix wildcards to match, their shape must match with the target expression:&lt;/p&gt;
&lt;div class="sourceCode" id="cb5"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb5-1" title="1"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; x &lt;span class="op"&gt;=&lt;/span&gt; MatrixSymbol(&lt;span class="st"&gt;'x'&lt;/span&gt;, N, &lt;span class="dv"&gt;1&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-2" title="2"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; e &lt;span class="op"&gt;=&lt;/span&gt; A &lt;span class="op"&gt;*&lt;/span&gt; x&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-3" title="3"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; e.shape&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-4" title="4"&gt;(N, &lt;span class="dv"&gt;1&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-5" title="5"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="bu"&gt;type&lt;/span&gt;(e.match(W))&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-6" title="6"&gt;&lt;span class="op"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kw"&gt;class&lt;/span&gt; &lt;span class="st"&gt;'NoneType'&lt;/span&gt;&lt;span class="op"&gt;&amp;gt;&lt;/span&gt;&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;However, if we don&amp;#8217;t care about dimension, we can include another wildcard in the matrix wildcard&amp;#8217;s shape:&lt;/p&gt;
&lt;div class="sourceCode" id="cb6"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb6-1" title="1"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; M &lt;span class="op"&gt;=&lt;/span&gt; MatrixSymbol(&lt;span class="st"&gt;'M'&lt;/span&gt;, &lt;span class="dv"&gt;3&lt;/span&gt;, &lt;span class="dv"&gt;3&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-2" title="2"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; w &lt;span class="op"&gt;=&lt;/span&gt; Wild(&lt;span class="st"&gt;'w'&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-3" title="3"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; Y &lt;span class="op"&gt;=&lt;/span&gt; MatrixWild(&lt;span class="st"&gt;'Y'&lt;/span&gt;, w, w)&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-4" title="4"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; M.match(Y)&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-5" title="5"&gt;{w_: &lt;span class="dv"&gt;3&lt;/span&gt;, Y_: M}&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;While this is a good first step to the matching functionality I was looking for with &lt;code&gt;unify&lt;/code&gt; for rewriting matrix expressions, there is still quite a bit of functionality (and tests) to be implemented, along with an unknown number of bugs to fix.&lt;/p&gt;
&lt;h2 id="printing-indexed-bases"&gt;Printing Indexed Bases&lt;/h2&gt;
&lt;p&gt;I&amp;#8217;ve also been working on a small pull request to improve the functionality the printing &lt;code&gt;IndexedBases&lt;/code&gt; so that it instead uses intermediate values (represented through the new code generation classes) to accumulate the values of contractions. Currently, this does nothing but break existing compatibility (Fortran versions older than Fortran 95 don&amp;#8217;t support variable declarations in arbitrary locations, and the variable currently defaults to a 32-bit floating point number), though I think this is a good first step for supporting the printing of more complex contractions.&lt;/p&gt;
&lt;h2 id="next-steps"&gt;Next Steps&lt;/h2&gt;
&lt;p&gt;For this week, I plan to finish with the implementation of&lt;code&gt;MatrixWild&lt;/code&gt; (and hopefully get started with using it for rewriting matrix expressions), along with making some more progress on the indexed bases pull request.&lt;/p&gt;</description>
    </item>
    <item>
      <guid isPermaLink="false">http://ishanaj.wordpress.com/?p=56</guid>
      <author>Ishan Joshi (ishanaj)</author>
      <title>Ishan Joshi (ishanaj): GSoC&#x2019;19: Week-6-Completing the Column class.</title>
      <pubDate>Mon, 08 Jul 2019 04:44:15 GMT</pubDate>
      <link>https://ishanaj.wordpress.com/2019/07/08/gsoc19-week-6-completing-the-column-class/</link>
      <description>&lt;p&gt;The sixth week has ended with a lot of work to be done ahead.&lt;/p&gt;



&lt;p&gt;Last week the work was majorly focused on the work in progress &lt;a href="https://github.com/sympy/sympy/pull/17122"&gt;PR #17122&lt;/a&gt;. I have included the critical load function which makes the Column class capable of determining the critical load. Some problems still came up in solving some equations. I have made an &lt;a href="https://github.com/sympy/sympy/issues/17162"&gt;issue&lt;/a&gt; related to those.&lt;/p&gt;



&lt;p&gt;An equation similar to &lt;strong&gt;tan(x) &amp;#8211; x&lt;/strong&gt; comes up while determining the critical load for the&amp;nbsp;&lt;strong&gt;pinned-fixed&lt;/strong&gt;&amp;nbsp;end-condition. SymPy&amp;#8217;s &lt;strong&gt;solve() &lt;/strong&gt;won&amp;#8217;t be able to solve such an equation, and as per the solution given in the &lt;a href="https://github.com/sympy/sympy/issues/17162"&gt;issue&lt;/a&gt;, I think that &lt;strong&gt;nsolve()&lt;/strong&gt; would surely help in this case. So I will be going ahead to solve it using the approximation returned by &lt;strong&gt;nsolve()&lt;/strong&gt; to handle this condition.&lt;span id="more-56"&gt;&lt;/span&gt;&lt;/p&gt;



&lt;p&gt;Another problem that I faced was determining deflection and critical load for the&amp;nbsp;&lt;strong&gt;pinned-pinned&lt;/strong&gt;&amp;nbsp;end-condition. Here, the deflection comes out to be:&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;C1*sin(sqrt(P)*x/(sqrt(E)*sqrt(I)))&lt;/strong&gt; +&lt;strong&gt; C2*cos(sqrt(P)*x/(sqrt(E)*sqrt(I)))&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;Now on solving it for constants &lt;strong&gt;C1&lt;/strong&gt; and &lt;strong&gt;C2, &lt;/strong&gt;using initial boundary conditions,&amp;nbsp;both come out to be &lt;strong&gt;0&lt;/strong&gt;, making the deflection &lt;strong&gt;zero&lt;/strong&gt;. This implies that no buckling occurs, which is not the case.&lt;/p&gt;



&lt;p&gt;Even when solving it manually, this situation occurs, we deal with it by putting &lt;strong&gt;C2 = 0 &lt;/strong&gt;and instead of putting &lt;strong&gt;C1 = 0,&lt;/strong&gt; we consider the &lt;strong&gt;sin &lt;/strong&gt;term equal to zero and then solve for &lt;strong&gt;P (critical load).&amp;nbsp;&lt;/strong&gt;So, I will be adding a few more lines of code to deal with this situation.&lt;/p&gt;



&lt;p&gt;Apart from working on this module, I have also opened another &lt;a href="https://github.com/sympy/sympy/pull/17153"&gt;PR #17153&lt;/a&gt; which implement methods&amp;nbsp;to determine &lt;strong&gt;section modulus&lt;/strong&gt; and &lt;strong&gt;polar modulus&lt;/strong&gt; of any polygon (more precisely a cross-section). Initially it was a draft PR, but now the work has been completed on it. Once I get the approval, I will also be adding the same for the Ellipses module. Also, if &lt;strong&gt;&lt;a href="https://github.com/sympy/sympy/pull/17001"&gt;cut_section()&lt;/a&gt; &lt;/strong&gt;gets successfully implemented I will be adding another method to determine the first moment.&lt;/p&gt;



&lt;p&gt;I am pretty sure the work on &lt;strong&gt;Column class&lt;/strong&gt; will be successfully completed before the end of the next week. Also, we will be heading towards the next stage which intends to plot beam diagrams using matplotlib. Till then we can have an initial discussion regarding the same.&lt;/p&gt;



&lt;h2&gt;&lt;strong&gt;Next Week:&lt;/strong&gt;&lt;/h2&gt;



&lt;ul&gt;&lt;li&gt;Improving the &lt;strong&gt;critical_load()&lt;/strong&gt; to handle the above problems&lt;/li&gt;&lt;li&gt;Completing the Column class (documentation and tests)&lt;/li&gt;&lt;li&gt;Starting with the next phase&lt;/li&gt;&lt;/ul&gt;



&lt;p&gt;Will keep you updated!&lt;/p&gt;



&lt;p&gt;Thanks!&lt;/p&gt;</description>
    </item>
    <item>
      <guid isPermaLink="false">https://divyanshu132.github.io//gsoc-week-6</guid>
      <author>Divyanshu Thakur (divyanshu132)</author>
      <title>Divyanshu Thakur (divyanshu132): GSoC 2019 - Week 6 - Computation of Polycyclic presentation</title>
      <pubDate>Mon, 08 Jul 2019 00:00:00 GMT</pubDate>
      <link>https://divyanshu132.github.io//gsoc-week-6</link>
      <description>&lt;p&gt;The sixth week of coding period has ended and a good amount of work has been done on polycyclic groups. Polycyclic presentation, Polycyclic generating sequence(pcgs) and it&amp;#8217;s series is implemented which for sure need some improvement &lt;a href="https://github.com/sympy/sympy/pull/16991"&gt;sympy/sympy#16991&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The polycyclic series is computed starting from the bottom of the derived series of a group by adding the missing generators in the subgroups, and collecting these missing generators provide us the polycyclic generating sequence.&lt;/p&gt;

&lt;p&gt;As we discussed last week &lt;a href="https://divyanshu132.github.io/gsoc-week-5"&gt;here&lt;/a&gt; that to compute conjugate relators of a polycyclic group we were missing the &lt;code class="highlighter-rouge"&gt;RHS&lt;/code&gt; term, which was of the form &lt;code class="highlighter-rouge"&gt;x[i]**-1*x[i+1]*x[i] == RHS&lt;/code&gt;. So, starting from the bottom of the polycyclic generating sequence forming the subgroup and finding all the generators of the RHS using &lt;code class="highlighter-rouge"&gt;generator_product&lt;/code&gt;, mapping these generators with the free group elements and forming a word, finally collect the above formed word which will give us the collected RHS.&lt;/p&gt;

&lt;p&gt;Below is an example to compute polycyclic presentation for S(9).sylow_subgroup(3)&lt;/p&gt;

&lt;div class="highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; from sympy.combinatorics import *
&amp;gt;&amp;gt;&amp;gt; from sympy.combinatorics.free_groups import free_group
&amp;gt;&amp;gt;&amp;gt; F, x0, x1, x2, x3 = free_group("x0, x1, x2, x3")
&amp;gt;&amp;gt;&amp;gt; S = SymmetricGroup(9)
&amp;gt;&amp;gt;&amp;gt; G = S.sylow_subgroup(3)
&amp;gt;&amp;gt;&amp;gt; pc_group = G.polycyclic_group()
&amp;gt;&amp;gt;&amp;gt; group = F
&amp;gt;&amp;gt;&amp;gt; pc_group.pc_presentation(group)
{x3**3: (), x2**3: (), x1**3: (), x0**3: (), x2**-1*x3*x2: x3, x1**-1*x3*x1: x3, x1**-1*x2*x1: x2, x0**-1*x3*x0: x2**2*x3**2, x0**-1*x2*x0: x3, x0**-1*x1*x0: x1*x3}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;One problem that we&amp;#8217;ve encountered is that the generators in pcgs may change for the same group on executing it several times which makes it difficult to test pc_presentation but, Kalevi advised me to initalize &lt;code class="highlighter-rouge"&gt;random.seed&lt;/code&gt; with some chosen value and then it will result in the same repeatable result, will try it by today!&lt;/p&gt;

&lt;p&gt;The tasks that I&amp;#8217;m hopping to accomplish next week are&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Add tests for plycyclic presentation and be sure that it works properly.&lt;/li&gt;
  &lt;li&gt;Include more functionalities to pc groups like &lt;code class="highlighter-rouge"&gt;exponent_vector&lt;/code&gt;, &lt;code class="highlighter-rouge"&gt;element_depth&lt;/code&gt;, &lt;code class="highlighter-rouge"&gt;leading_coefficient&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Add documentation for all the functions.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Till then, good byee..&lt;/p&gt;</description>
    </item>
    <item>
      <guid isPermaLink="false">https://anpandey.github.io/posts/sympy/2019-07-07-week-6.html</guid>
      <author>Ankit Pandey (anpandey)</author>
      <title>Ankit Pandey (anpandey): Google Summer of Code Week 6: Unification and Tensors Continued</title>
      <pubDate>Sun, 07 Jul 2019 00:00:00 GMT</pubDate>
      <link>https://anpandey.github.io/posts/sympy/2019-07-07-week-6.html</link>
      <description>&lt;p&gt;&lt;em&gt;See the &lt;a href="https://anpandey.github.io/2019-06-28-week-5.html"&gt;previous post&lt;/a&gt; for Week 5&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;This week I&amp;#8217;ve made some progress on matching and tensors, though I haven&amp;#8217;t filed any pull requests.&lt;/p&gt;
&lt;h2 id="unification"&gt;Unification&lt;/h2&gt;
&lt;p&gt;I have a working implementation of rewriting non-commutative expressions using SymPy&amp;#8217;s unify. It works by generating a &lt;code&gt;ReplaceOptim&lt;/code&gt; object that applies the rewriting rules to any term it&amp;#8217;s called with. Here&amp;#8217;s how we specify the rewriting rules:&lt;/p&gt;
&lt;div class="sourceCode" id="cb1"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb1-1" title="1"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="im"&gt;from&lt;/span&gt; sympy &lt;span class="im"&gt;import&lt;/span&gt; Symbol, MatrixSymbol&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-2" title="2"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; n &lt;span class="op"&gt;=&lt;/span&gt; Symbol(&lt;span class="st"&gt;'N_matcher'&lt;/span&gt;, integer&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-3" title="3"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; X &lt;span class="op"&gt;=&lt;/span&gt; MatrixSymbol(&lt;span class="st"&gt;'X_matcher'&lt;/span&gt;, n, n)&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-4" title="4"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; Y &lt;span class="op"&gt;=&lt;/span&gt; MatrixSymbol(&lt;span class="st"&gt;'Y_matcher'&lt;/span&gt;, n, &lt;span class="dv"&gt;1&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-5" title="5"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; variables &lt;span class="op"&gt;=&lt;/span&gt; [n, X, Y]&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-6" title="6"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; matcher &lt;span class="op"&gt;=&lt;/span&gt; X&lt;span class="op"&gt;**&lt;/span&gt;(&lt;span class="op"&gt;-&lt;/span&gt;&lt;span class="dv"&gt;1&lt;/span&gt;) &lt;span class="op"&gt;*&lt;/span&gt; Y&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-7" title="7"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; goal &lt;span class="op"&gt;=&lt;/span&gt; MatrixSolve(X, Y)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Here, the combination of &lt;code&gt;matcher&lt;/code&gt; and &lt;code&gt;variables&lt;/code&gt; specifies that we&amp;#8217;re looking for any expression of the form &lt;span class="math inline"&gt;&lt;em&gt;X&lt;/em&gt;&lt;sup&gt;&amp;#8197;&amp;#8722;&amp;#8197;1&lt;/sup&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/span&gt;, where both &lt;span class="math inline"&gt;&lt;em&gt;X&lt;/em&gt;&lt;/span&gt; and &lt;span class="math inline"&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/span&gt; can be any compound matrix expression. The inclusion of &lt;code&gt;n&lt;/code&gt; in &lt;code&gt;variables&lt;/code&gt; imposes the additional restriction that the matrix expression matched by &lt;span class="math inline"&gt;&lt;em&gt;X&lt;/em&gt;&lt;/span&gt; must be square (i.e. &lt;span class="math inline"&gt;&lt;em&gt;n&lt;/em&gt;&amp;#8197;&amp;#215;&amp;#8197;&lt;em&gt;n&lt;/em&gt;&lt;/span&gt;) while the expression matched by &lt;span class="math inline"&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/span&gt; must be a vector (i.e. &lt;span class="math inline"&gt;&lt;em&gt;n&lt;/em&gt;&amp;#8197;&amp;#215;&amp;#8197;1&lt;/span&gt;). &lt;code&gt;goal&lt;/code&gt; specifies what the matched expression should be replaced with, where &lt;code&gt;X&lt;/code&gt; and &lt;code&gt;Y&lt;/code&gt; serve as stand-ins for the matched terms.&lt;/p&gt;
&lt;p&gt;After specifying our goals, we can construct the object and apply the replacement to some expressions:&lt;/p&gt;
&lt;div class="sourceCode" id="cb2"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb2-1" title="1"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; replacer &lt;span class="op"&gt;=&lt;/span&gt; gen_replacement_operator(matcher, goal, variables)&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-2" title="2"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; A, B, x &lt;span class="op"&gt;=&lt;/span&gt; MatrixSymbol(&lt;span class="st"&gt;'A'&lt;/span&gt;, &lt;span class="dv"&gt;3&lt;/span&gt;, &lt;span class="dv"&gt;3&lt;/span&gt;), MatrixSymbol(&lt;span class="st"&gt;'B'&lt;/span&gt;, &lt;span class="dv"&gt;3&lt;/span&gt;, &lt;span class="dv"&gt;3&lt;/span&gt;), MatrixSymbol(&lt;span class="st"&gt;'x'&lt;/span&gt;, &lt;span class="dv"&gt;3&lt;/span&gt;, &lt;span class="dv"&gt;1&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-3" title="3"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; replacer(A &lt;span class="op"&gt;**&lt;/span&gt; (&lt;span class="op"&gt;-&lt;/span&gt;&lt;span class="dv"&gt;1&lt;/span&gt;) &lt;span class="op"&gt;*&lt;/span&gt; x)&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-4" title="4"&gt;(MatrixSolve(A, vector&lt;span class="op"&gt;=&lt;/span&gt;x))&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-5" title="5"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; replacer(A &lt;span class="op"&gt;**&lt;/span&gt; (&lt;span class="op"&gt;-&lt;/span&gt;&lt;span class="dv"&gt;1&lt;/span&gt;) &lt;span class="op"&gt;*&lt;/span&gt; B)&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-6" title="6"&gt;A &lt;span class="op"&gt;**&lt;/span&gt; (&lt;span class="op"&gt;-&lt;/span&gt;&lt;span class="dv"&gt;1&lt;/span&gt;) &lt;span class="op"&gt;*&lt;/span&gt; B&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The first term was replaced since the dimensions of &lt;code&gt;A&lt;/code&gt; and &lt;code&gt;x&lt;/code&gt; agreed with what was specified in matcher, while the second expression was left untouched since &lt;code&gt;B&lt;/code&gt; is not a vector.&lt;/p&gt;
&lt;p&gt;While the matcher does work, I haven&amp;#8217;t filed a pull request because of some problems which don&amp;#8217;t seem like they could be easily addressed:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I had to give add the suffix &lt;code&gt;_matcher&lt;/code&gt; to the variable names to avoid variable capture, since SymPy symbols are considered equal if they have the same name. &lt;code&gt;unify&lt;/code&gt; does not support &lt;code&gt;Dummy&lt;/code&gt; symbols as variables.&lt;/li&gt;
&lt;li&gt;Some compound expressions are not matched. I&amp;#8217;ve narrowed this down to the way the variables are being passed to &lt;code&gt;unify&lt;/code&gt;, since they need to be converted to symbols. It seems like this conversion sometimes causes expressions to no longer be unifiable.&lt;/li&gt;
&lt;li&gt;Unification doesn&amp;#8217;t seem to work for a mixture of commutative and non-commutative expressions. I&amp;#8217;m not sure if this is a problem with &lt;code&gt;unify&lt;/code&gt; itself or the way that I&amp;#8217;m using it, since the only test of &lt;code&gt;unify&lt;/code&gt; in the SymPy codebase involving matrix expressions is on matrix multiplication.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As I mentioned in my last blog post, SymPy already supports this sort of pattern matching through &lt;code&gt;Wild&lt;/code&gt;, though it currently does not support expressions involving matrices. Before trying to address these issues, I think it would be worthwhile to look into extending the functionality of &lt;code&gt;Wild&lt;/code&gt; as an alternative.&lt;/p&gt;
&lt;h2 id="tensors"&gt;Tensors&lt;/h2&gt;
&lt;p&gt;I&amp;#8217;ve made some progress in low-level code generation of matrix expressions. I tried seeing if instances of classes in the &lt;code&gt;array_utils&lt;/code&gt; module could be converted to SymPy&amp;#8217;s AST representation before being passed off to the code generators. This doesn&amp;#8217;t seem possible at the moment, since the AST has a number of limitations (such as not supporting variables in &lt;code&gt;for&lt;/code&gt; loop ranges). The &lt;code&gt;IndexedBase&lt;/code&gt; printer already has some of the functionality that I&amp;#8217;m trying to implement, so I&amp;#8217;ve settled on extending the printer to support arbitrary contractions. This same functionality can probably be reused for the &lt;code&gt;array_utils&lt;/code&gt; printers. The implementation will hopefully be straightforward.&lt;/p&gt;
&lt;h2 id="next-steps"&gt;Next steps&lt;/h2&gt;
&lt;p&gt;My goal for this week is to have a pull request for the tensor code generation ready, along with a plan for what to do with matching.&lt;/p&gt;</description>
    </item>
    <item>
      <guid isPermaLink="false">https://divyanshu132.github.io//gsoc-week-5</guid>
      <author>Divyanshu Thakur (divyanshu132)</author>
      <title>Divyanshu Thakur (divyanshu132): GSoC 2019 - Week 5 - Hand-made tests for Collector</title>
      <pubDate>Mon, 01 Jul 2019 00:00:00 GMT</pubDate>
      <link>https://divyanshu132.github.io//gsoc-week-5</link>
      <description>&lt;p&gt;This week was mostly about testing the collection of a word and fixing small bugs in the implementation pointed out by Kalevi. The major challenge was to construct the polycyclic presentation of a group to test the Collector since we don&amp;#8217;t have the implementation of polycyclic presentation and it&amp;#8217;s generating sequence yet. So, we decided to form some hand made tests and we started with SymmetricGroup(4) and further we also tried with S(3) the details can be found in the test file of the PR(&lt;a href="https://github.com/sympy/sympy/pull/16991"&gt;here&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Now, the next step is to implement polycyclic presentation and polycyclic sequence. In the presentation we&amp;#8217;ll need generators which we can easily get and the relators. There are two types of relators needed for the presentation:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Power relations (ex. &lt;code class="highlighter-rouge"&gt;x^re = x'&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;Conjugate relations (ex. &lt;code class="highlighter-rouge"&gt;x[i]**-1*x[i+1]*x[i] = RHS and x[i]*x[i+1]*x[i]**-1 = RHS&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For every pair of generators we&amp;#8217;ll form above conjugate relations but the tough part is computing that &lt;code class="highlighter-rouge"&gt;RHS&lt;/code&gt; which should be collected and for now we don&amp;#8217;t have that much idea about how to get that RHS.&lt;/p&gt;

&lt;p&gt;But, let&amp;#8217;s hope that in upcoming days we&amp;#8217;ll be able to figure it out, till then Good byeee&amp;#8230;&lt;/p&gt;</description>
    </item>
    <item>
      <guid isPermaLink="false">http://ishanaj.wordpress.com/?p=54</guid>
      <author>Ishan Joshi (ishanaj)</author>
      <title>Ishan Joshi (ishanaj): GSoC&#x2019;19: Week-5 &#x2013; Moving on with a Non-mutable Column class</title>
      <pubDate>Sun, 30 Jun 2019 18:52:29 GMT</pubDate>
      <link>https://ishanaj.wordpress.com/2019/07/01/gsoc19-week-5-moving-on-with-a-non-mutable-column-class/</link>
      <description>&lt;p&gt;A lot of things happened this week and I am happy to inform you that &lt;a href="https://github.com/sympy/sympy/pull/17055"&gt;PR #17055&lt;/a&gt; has been successfully merged. The beam module now supports the cross-sectional shape of the beam as an alternative parameter to the second moment. With this, the aim of the stage-I to integrate the geometry module with beam module has been accomplished.&lt;/p&gt;



&lt;p&gt;Although we need to add some examples in the docs, to make it easier for the user to understand how to use this new feature.&lt;/p&gt;



&lt;p&gt;Coming on to stage-II, I had already, initiated a &lt;a href="https://github.com/sympy/sympy/issues/17072"&gt;discussion&lt;/a&gt; to finalize the API of the new Column class that is to be implemented as a part of the continuum mechanics module in this stage.&lt;span id="more-54"&gt;&lt;/span&gt;&lt;/p&gt;



&lt;p&gt;We concluded that it would be much better if the Column class remains non-mutable i.e. unlike the beam class where a beam is formed in a piecewise form, the new Column class would take all its required input data during the declaration and then one can call different methods to calculate different things.&lt;/p&gt;



&lt;p&gt;I have made a &lt;a href="https://github.com/sympy/sympy/pull/17122"&gt;work-in-progress PR #17122&lt;/a&gt; implementing the Column class which performs the required buckling calculations. Currently, I have not included a method to calculate the critical load as there was a bit of problem with the form of the equation which the &lt;strong&gt;dsolve() &lt;/strong&gt;returns after solving the differential equation of buckling. &lt;a href="https://docs.sympy.org/latest/modules/solvers/ode.html" rel="noopener" target="_blank"&gt;&lt;strong&gt;dsolve(&lt;/strong&gt;)&lt;/a&gt; is SymPy&amp;#8217;s differential equation solver.&lt;/p&gt;



&lt;p&gt;In general, if we solve the general equation of buckling manually, we might apply the &lt;strong&gt;method of undetermined coefficients&lt;/strong&gt;, which of course even &lt;strong&gt;dsolve() &lt;/strong&gt;&amp;nbsp;is capable to apply, but it gives the answer in an exponent form, while we need it in a trigonometric form (for ease of further calculations). So after seeking different methods trying to convert this equation in terms of &lt;strong&gt;sin(x)&lt;/strong&gt; and &lt;strong&gt;cos(x), &lt;/strong&gt;I finally had to put that problem in the discussion, where Oscar Benjamin, gave an idea to declare the variables as positive in order to get it in terms of &lt;strong&gt;sin &lt;/strong&gt;and&lt;strong&gt; cos.&amp;nbsp;&lt;/strong&gt;I tried that it works well for our case. I will have to figure out the further calculation of the critical load.&lt;/p&gt;



&lt;p&gt;Hopefully will be updating the code with a new method to calculate critical load, soon.&lt;/p&gt;



&lt;p&gt;Also, I have planned to have a method to solve the &lt;strong&gt;unknown reactions&lt;/strong&gt; and &lt;strong&gt;reaction moments&lt;/strong&gt;, which would use the &lt;strong&gt;boundary conditions&lt;/strong&gt; to get their values.&lt;/p&gt;



&lt;p&gt;With all these things going on, this week we also had our first evaluations, and I am very happy to say that I have passed it. &lt;strong&gt;Thanks to the mentors!&lt;/strong&gt;&lt;/p&gt;



&lt;h2&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;Next Week:&lt;/strong&gt;&lt;/h2&gt;



&lt;ul&gt;&lt;li&gt;Completing Column class with all its methods&lt;/li&gt;&lt;li&gt;Adding tests and documentation.&lt;/li&gt;&lt;li&gt;Starting discussions for the next stage.&lt;/li&gt;&lt;/ul&gt;



&lt;p&gt;I will try to finish working on the Column class this weekend.&lt;/p&gt;



&lt;p&gt;Will keep you updated!&lt;/p&gt;



&lt;p&gt;Thanks!&lt;/p&gt;</description>
    </item>
    <item>
      <guid isPermaLink="false">https://anpandey.github.io/posts/sympy/2019-06-28-week-5.html</guid>
      <author>Ankit Pandey (anpandey)</author>
      <title>Ankit Pandey (anpandey): Google Summer of Code Week 5: Unification and Tensors</title>
      <pubDate>Fri, 28 Jun 2019 00:00:00 GMT</pubDate>
      <link>https://anpandey.github.io/posts/sympy/2019-06-28-week-5.html</link>
      <description>&lt;p&gt;&lt;em&gt;See the &lt;a href="https://anpandey.github.io/2019-06-21-weeks-3-and-4.html"&gt;previous post&lt;/a&gt; for Weeks 3 and 4&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;This week I&amp;#8217;ve been mostly doing background reading. This post is mostly a summary of what I learned.&lt;/p&gt;
&lt;h2 id="unification"&gt;Unification&lt;/h2&gt;
&lt;p&gt;In short, unification is the process of finding substitutions of variables within two terms two terms to make them identical. For example, if we have the expressions &lt;span class="math inline"&gt;&lt;em&gt;x&lt;/em&gt;&amp;#8197;+&amp;#8197;2&lt;em&gt;y&lt;/em&gt;&lt;/span&gt; and &lt;span class="math inline"&gt;&lt;em&gt;a&lt;/em&gt;&amp;#8197;+&amp;#8197;3&lt;em&gt;b&lt;/em&gt;&lt;/span&gt;, the substitution &lt;span class="math inline"&gt;{&lt;em&gt;x&lt;/em&gt;&amp;#8196;&amp;#8614;&amp;#8196;&lt;em&gt;a&lt;/em&gt;,&amp;#8198;&lt;em&gt;y&lt;/em&gt;&amp;#8196;&amp;#8614;&amp;#8196;3,&amp;#8198;&lt;em&gt;b&lt;/em&gt;&amp;#8196;&amp;#8614;&amp;#8196;2}&lt;/span&gt; is a unifier, since applying the substitution to both expressions makes gives us the identical expression of &lt;span class="math inline"&gt;&lt;em&gt;a&lt;/em&gt;&amp;#8197;+&amp;#8197;3&amp;#8197;&amp;#8901;&amp;#8197;2&lt;/span&gt;. While this particular substitution includes variables from both expressions, we&amp;#8217;re mostly interested in rules involving substitutions of variables from just one expression (a case of unification known as matching). Several well-known algorithms for unification already exist.&lt;/p&gt;
&lt;h3 id="unification-in-sympy"&gt;Unification in SymPy&lt;/h3&gt;
&lt;p&gt;SymPy also has an implementation of a unification algorithm that is able to take the commutativity of operations into account. Suppose we wanted to unify the matrix expressions &lt;span class="math inline"&gt;&lt;em&gt;A&lt;/em&gt;&lt;sup&gt;&lt;em&gt;T&lt;/em&gt;&lt;/sup&gt;&lt;em&gt;B&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;em&gt;C&lt;/em&gt;&lt;sup&gt;&amp;#8197;&amp;#8722;&amp;#8197;1&lt;/sup&gt;&lt;/span&gt; and &lt;span class="math inline"&gt;&lt;em&gt;X&lt;/em&gt;&lt;em&gt;Y&lt;/em&gt;&lt;sup&gt;&amp;#8197;&amp;#8722;&amp;#8197;1&lt;/sup&gt;&lt;/span&gt;. This is essentially the problem of finding a substitution that makes these two expressions equal. Using the &lt;code&gt;sympy.unify.usympy&lt;/code&gt; module, we can discover what this substitution is:&lt;/p&gt;
&lt;div class="sourceCode" id="cb1"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb1-1" title="1"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="im"&gt;from&lt;/span&gt; sympy.unify.usympy &lt;span class="im"&gt;import&lt;/span&gt; &lt;span class="op"&gt;*&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-2" title="2"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="im"&gt;from&lt;/span&gt; sympy.abc &lt;span class="im"&gt;import&lt;/span&gt; N&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-3" title="3"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; m &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="kw"&gt;lambda&lt;/span&gt; x: MatrixSymbol(x, N, N)&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-4" title="4"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; A, B, C, X, Y &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;map&lt;/span&gt;(m, [&lt;span class="st"&gt;'A'&lt;/span&gt;, &lt;span class="st"&gt;'B'&lt;/span&gt;, &lt;span class="st"&gt;'X'&lt;/span&gt;, &lt;span class="st"&gt;'Y'&lt;/span&gt;])&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-5" title="5"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; e1 &lt;span class="op"&gt;=&lt;/span&gt; A.T &lt;span class="op"&gt;*&lt;/span&gt; B&lt;span class="op"&gt;**&lt;/span&gt;&lt;span class="dv"&gt;2&lt;/span&gt; &lt;span class="op"&gt;*&lt;/span&gt; C.I&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-6" title="6"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; e2 &lt;span class="op"&gt;=&lt;/span&gt; X &lt;span class="op"&gt;*&lt;/span&gt; Y &lt;span class="op"&gt;**&lt;/span&gt;(&lt;span class="op"&gt;-&lt;/span&gt;&lt;span class="dv"&gt;1&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-7" title="7"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="bu"&gt;next&lt;/span&gt;(unify(e1, e2, variables&lt;span class="op"&gt;=&lt;/span&gt;[X, Y]))&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-8" title="8"&gt;{X: A.T&lt;span class="op"&gt;*&lt;/span&gt;B&lt;span class="op"&gt;**&lt;/span&gt;&lt;span class="dv"&gt;2&lt;/span&gt;, Y: C}&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We&amp;#8217;ve reduced this to a matching problem in which the variables are specified only in &lt;code&gt;e2&lt;/code&gt;. What&amp;#8217;s important to note here is that the matching rule within &lt;code&gt;e2&lt;/code&gt; we specified (&lt;span class="math inline"&gt;&lt;em&gt;X&lt;/em&gt;&lt;em&gt;Y&lt;/em&gt;&lt;sup&gt;&amp;#8197;&amp;#8722;&amp;#8197;1&lt;/sup&gt;&lt;/span&gt;) was a compound expression. This is something that is currently not possible for non-commutative expressions (such as matrix multiplication) using SymPy&amp;#8217;s &lt;code&gt;Wild&lt;/code&gt; interface. &lt;code&gt;unify&lt;/code&gt; allows use to express substitution rules that are able to match across sub-expressions in matrix multiplication.&lt;/p&gt;
&lt;p&gt;Through unification, we can express substitution rules for optimization as a simple term-rewriting rule. In my previous blog post, I mentioned rewriting the matrix multiplication &lt;span class="math inline"&gt;&lt;em&gt;A&lt;/em&gt;&lt;em&gt;x&lt;/em&gt;&lt;/span&gt; as a solving operation of &lt;code&gt;MatSolve(A, x)&lt;/code&gt; under certain assumptions. The actual implementation is restricted to cases where both the &lt;code&gt;A&lt;/code&gt; and the &lt;code&gt;x&lt;/code&gt; are matrix symbols, and the optimization can&amp;#8217;t identify cases where either the &lt;code&gt;A&lt;/code&gt; or the &lt;code&gt;x&lt;/code&gt; is a compound expression. With unification, we can identify the same pattern in more complex subexpressions. If we&amp;#8217;re given the matrix expression &lt;span class="math inline"&gt;&lt;em&gt;A&lt;/em&gt;&lt;sup&gt;&lt;em&gt;T&lt;/em&gt;&lt;/sup&gt;(&lt;em&gt;A&lt;/em&gt;&lt;em&gt;B&lt;/em&gt;)&lt;sup&gt;&amp;#8197;&amp;#8722;&amp;#8197;1&lt;/sup&gt;&lt;em&gt;x&lt;/em&gt;&lt;em&gt;y&lt;/em&gt;&lt;/span&gt;, a unification based transformer can produce &lt;code&gt;MatSolve(AB, x)&lt;/code&gt;, provided that the shapes of the matrices match the given rule.&lt;/p&gt;
&lt;h2 id="codegen-tensors"&gt;Codegen Tensors&lt;/h2&gt;
&lt;p&gt;I also looked into generating C and Fortran code from SymPy matrix expressions. For the purposes of code generation, SymPy has a relatively new &lt;code&gt;array_utils&lt;/code&gt; module. The AST nodes in this module express generalizations of operations on matrices, which require a bit of background in tensors.&lt;/p&gt;
&lt;p&gt;Many array operations (including matrix multiplication) involve &lt;em&gt;contraction&lt;/em&gt; along an axis. Contractions are a combination of multiplication and summation along certain axis of a tensor&lt;a class="footnote-ref" href="https://anpandey.github.io/atom-sympy.xml#fn1" id="fnref1"&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;. In assigning the matrix multiplication &lt;span class="math inline"&gt;&lt;em&gt;A&lt;/em&gt;&lt;em&gt;B&lt;/em&gt;&lt;/span&gt; to the &lt;span class="math inline"&gt;&lt;em&gt;n&lt;/em&gt;&amp;#8197;&amp;#215;&amp;#8197;&lt;em&gt;n&lt;/em&gt;&lt;/span&gt; matrix &lt;span class="math inline"&gt;&lt;em&gt;C&lt;/em&gt;&lt;/span&gt;, we can explicitly write the summations (using subscripts for indexing matrix elements) as&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;span class="math display"&gt;$$C_{ik} = \sum_{j = 1}^{n} A_{ij} B_{jk}$$&lt;/span&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;The index &lt;span class="math inline"&gt;&lt;em&gt;j&lt;/em&gt;&lt;/span&gt; is contracted, as it is shared between both &lt;span class="math inline"&gt;&lt;em&gt;A&lt;/em&gt;&lt;/span&gt; and &lt;span class="math inline"&gt;&lt;em&gt;B&lt;/em&gt;&lt;/span&gt;, and describing this summation operation as a whole boils down to which indices are shared between the matrices. This is essentially what the &lt;code&gt;array_utils&lt;/code&gt; classes do. This is what happens when we use &lt;code&gt;array_utils&lt;/code&gt; to convert the matrix multiplication to an equivalent contraction operation:&lt;/p&gt;
&lt;div class="sourceCode" id="cb2"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb2-1" title="1"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="im"&gt;from&lt;/span&gt; sympy.codegen.array_utils &lt;span class="im"&gt;import&lt;/span&gt; CodegenArrayContraction&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-2" title="2"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="im"&gt;from&lt;/span&gt; sympy.abc &lt;span class="im"&gt;import&lt;/span&gt; N&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-3" title="3"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; A &lt;span class="op"&gt;=&lt;/span&gt; MatrixSymbol(&lt;span class="st"&gt;'A'&lt;/span&gt;, N, N)&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-4" title="4"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; B &lt;span class="op"&gt;=&lt;/span&gt; MatrixSymbol(&lt;span class="st"&gt;'B'&lt;/span&gt;, N, N)&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-5" title="5"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; CodegenArrayContraction.from_MatMul(A &lt;span class="op"&gt;*&lt;/span&gt; B)&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-6" title="6"&gt;CodegenArrayContraction(CodegenArrayTensorProduct(A, B), (&lt;span class="dv"&gt;1&lt;/span&gt;, &lt;span class="dv"&gt;2&lt;/span&gt;))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We&amp;#8217;re given a new&lt;code&gt;CodegenArrayContraction&lt;/code&gt; object that stores, along with the variables &lt;code&gt;A&lt;/code&gt; and &lt;code&gt;B&lt;/code&gt;, tuples of integers representing contractions along certain indices. Here, the &lt;code&gt;(1, 2)&lt;/code&gt; means that the variable at index 1 and index 2 (indices start at 0) are shared. We can confirm this by looking at the above summation, since both the second and third indices out of all indices that appear in the expression are &lt;span class="math inline"&gt;&lt;em&gt;j&lt;/em&gt;&lt;/span&gt;.&lt;/p&gt;
&lt;h2 id="next-steps"&gt;Next Steps&lt;/h2&gt;
&lt;p&gt;For next week, I&amp;#8217;ll try to re-implement the rewriting optimization in terms of &lt;code&gt;unify&lt;/code&gt;. This will both make it easier to express rules and extend to sub-expressions as well. I&amp;#8217;ll also start with implementing additional printers for the C and Fortran printers. The printer will probably just print naive &lt;code&gt;for&lt;/code&gt; loops to keep things simple (and it would probaly be better to use something like Theano for highly optimized code).&lt;/p&gt;
&lt;section class="footnotes"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn1"&gt;&lt;p&gt;For our purposes, we can think of tensors as just &lt;span class="math inline"&gt;&lt;em&gt;n&lt;/em&gt;&lt;/span&gt;-dimensional arrays. Most of my reading on tensors was Justin C. Feng&amp;#8217;s &lt;a href="https://justincfeng.github.io/Tensors_Poor_Man.pdf"&gt;The Poor Man&amp;#8217;s Introduction to Tensors&lt;/a&gt;.&lt;a class="footnote-back" href="https://anpandey.github.io/atom-sympy.xml#fnref1"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;</description>
    </item>
    <item>
      <guid isPermaLink="false">https://divyanshu132.github.io//gsoc-week-4</guid>
      <author>Divyanshu Thakur (divyanshu132)</author>
      <title>Divyanshu Thakur (divyanshu132): GSoC 2019 - Week 4 - Phase-I Completion</title>
      <pubDate>Mon, 24 Jun 2019 00:00:00 GMT</pubDate>
      <link>https://divyanshu132.github.io//gsoc-week-4</link>
      <description>&lt;p&gt;The fourth week of coding period has ended and now it&amp;#8217;s time for phase-I evaluations. Below, is a brief progress report of the project.&lt;/p&gt;

&lt;p&gt;The tasks that were proposed in the proposal for phase-I consists of:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Implementation of Abelian Invariants&lt;/li&gt;
  &lt;li&gt;Implementation of Composition Series&lt;/li&gt;
  &lt;li&gt;Computation with Polycyclic groups&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Abelian Invariants&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Implemented a function to compute the abelian invariants for a given permutation or free group. These are given as a list of prime-powers and describe the stucture of &lt;code class="highlighter-rouge"&gt;G/G'&lt;/code&gt; as a direct product of cyclic groups of prime power order.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;PR link &lt;a href="https://github.com/sympy/sympy/pull/16670"&gt;Added method to calculate Abelian Invariants&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Composition Series&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Implemented a function to compute the composition series. It provides a way to break up a group into simple pieces. Composition series of a group &lt;code class="highlighter-rouge"&gt;G&lt;/code&gt; is defined as the maximal subnormal series &lt;code class="highlighter-rouge"&gt;G = H_0 &amp;gt; H_1 &amp;gt; H_2 ... &amp;gt; H_k = 1&lt;/code&gt; where every factor group &lt;code class="highlighter-rouge"&gt;H(i+1)/H(i)&lt;/code&gt; is simple.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;PR link &lt;a href="https://github.com/sympy/sympy/pull/16881"&gt;Added method for Composition Series computation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Polycyclic Groups&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The work on polycyclic group is in progress. For now, collection algorithm has been implemented which needs to be tested and a lot of discussions were made on the polycyclic generating sequence and its presentation and may be in a week we&amp;#8217;ll be ready with the stucture of polycyclic groups and collection of words.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;PR link &lt;a href="https://github.com/sympy/sympy/pull/16991"&gt;Added Polycyclic Group Class&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Documentation&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Some documentation is done to increase the sphinx coverage of SymPy.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;PR link &lt;a href="https://github.com/sympy/sympy/pull/16809"&gt;Increase Accessibility of docstrings from Sphinx&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To follow the discussion on above topics and the further progress of the project one can check Gitter room &lt;a href="https://gitter.im/sympy/GroupTheory"&gt;sympy/GroupTheory&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <guid isPermaLink="false">http://ishanaj.wordpress.com/?p=52</guid>
      <author>Ishan Joshi (ishanaj)</author>
      <title>Ishan Joshi (ishanaj): GSoC&#x2019;19: Week-4-Starting with Column Buckling implementation</title>
      <pubDate>Sun, 23 Jun 2019 18:41:36 GMT</pubDate>
      <link>https://ishanaj.wordpress.com/2019/06/24/gsoc19-week-4-starting-with-column-buckling-implementation/</link>
      <description>&lt;p&gt;Finalizing what had been discussed in &lt;a href="https://github.com/sympy/sympy/pull/16964"&gt;PR #16964&lt;/a&gt; for integrating geometry module with the beam module,&lt;a href="https://github.com/sympy/sympy/pull/17055"&gt; PR #17055&lt;/a&gt; was opened which is now ready to go!&lt;/p&gt;



&lt;p&gt;There is no special function for defining the cross-section of a Beam object. A user can simply pass the geometry object as a parameter instead of the &lt;strong&gt;second_moment, &lt;/strong&gt;and the corresponding second moment would be calculated internally. The example below might explain this better:&lt;span id="more-52"&gt;&lt;/span&gt;&lt;/p&gt;


&lt;pre class="brush: python; collapse: false; title: ; wrap-lines: false; notranslate"&gt;

&amp;gt;&amp;gt;&amp;gt; b = Beam(l, E, Circle((0, 0), r))

&amp;gt;&amp;gt;&amp;gt; b.second_moment

pi*r*Abs(r)**3/4

&amp;gt;&amp;gt;&amp;gt; b.cross_section

Circle(Point2D(0, 0), r)

&lt;/pre&gt;



&lt;p&gt;Further, the &lt;strong&gt;cross_section&lt;/strong&gt; attribute can be changed even after the beam is created. Every time the &lt;strong&gt;cross_section&lt;/strong&gt; is assigned a new value, the &lt;strong&gt;second_moment&lt;/strong&gt; gets automatically updated.&lt;/p&gt;



&lt;p&gt;Similarly, every time the user changes the &lt;strong&gt;second_moment&lt;/strong&gt; explicitly after the creation of the beam, the previous &lt;strong&gt;cross_section&lt;/strong&gt; gets destroyed, or in other words, the &lt;strong&gt;cross_section&lt;/strong&gt; is set to None.&lt;/p&gt;


&lt;pre class="brush: python; collapse: false; title: ; wrap-lines: false; notranslate"&gt;

&amp;gt;&amp;gt;&amp;gt; b = Beam(l, E, Circle((0, 0), r))

&amp;gt;&amp;gt;&amp;gt; I&amp;#160; = Symbol(&amp;#8216;I&amp;#8217;)

&amp;gt;&amp;gt;&amp;gt; b.second_moment = I

&amp;gt;&amp;gt;&amp;gt; b.cross_section

None

&amp;gt;&amp;gt;&amp;gt; b.second_moment = Polygon((0, 0), (a, 0), (a, b), (0, b))

ValueError: To update cross-section geometry use `cross_section` attribute

&lt;/pre&gt;



&lt;p&gt;The PR is complete and just needs the final approval from the mentors.&lt;/p&gt;



&lt;p&gt;Simultaneously, I had worked on the column buckling calculations which is a part of the stage &amp;#8211;II.&lt;/p&gt;



&lt;p&gt;I have opened an &lt;a href="https://github.com/sympy/sympy/issues/17072"&gt;issue-cum-discussion&lt;/a&gt; for discussing its API and further implementations.&lt;/p&gt;



&lt;p&gt;Since the calculations of the Column Buckling are very much different from those of beam bending, we will have to make a separate class Column. The basic API and the way the calculations are supposed to go can be seen from the stage &amp;#8211;II in the &lt;a href="https://docs.google.com/document/d/1LOtMTr9cCrzQ8_OnKrgkZs8wFS9N9PxlR10h3aKG0jg/edit?usp=sharing"&gt;proposal&lt;/a&gt;.&lt;/p&gt;



&lt;p&gt;I would be making a PR for column buckling calculations within a day or two, once some initial questions (as mentioned in the issue-cum-discussion) gets clarified.&lt;/p&gt;



&lt;h2&gt;Next Week:&lt;/h2&gt;



&lt;ul&gt;&lt;li&gt;Finalizing the basic API and implementations of Column class&lt;/li&gt;&lt;li&gt;Making a PR for the above implementations&lt;/li&gt;&lt;li&gt;Documentation and testing&lt;/li&gt;&lt;/ul&gt;



&lt;p&gt;Will keep you updated!&lt;/p&gt;



&lt;p&gt;Thanks!&lt;/p&gt;</description>
    </item>
    <item>
      <guid isPermaLink="false">https://anpandey.github.io/posts/sympy/2019-06-21-weeks-3-and-4.html</guid>
      <author>Ankit Pandey (anpandey)</author>
      <title>Ankit Pandey (anpandey): Google Summer of Code Weeks 3 and 4: Matrix Optimizations</title>
      <pubDate>Fri, 21 Jun 2019 00:00:00 GMT</pubDate>
      <link>https://anpandey.github.io/posts/sympy/2019-06-21-weeks-3-and-4.html</link>
      <description>&lt;p&gt;&lt;em&gt;See the &lt;a href="https://anpandey.github.io/2019-06-07-week-2.html"&gt;previous post&lt;/a&gt; for Week 2&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;I spent a large part of last week travelling, so I&amp;#8217;m combining the blog posts for the last two weeks.&lt;/p&gt;
&lt;h2 id="finishing-up-with-lfortran"&gt;Finishing up with LFortran&lt;/h2&gt;
&lt;p&gt;I&amp;#8217;m finished with the &lt;a href="https://github.com/sympy/sympy/pull/16931"&gt;pull request&lt;/a&gt; for the LFortran code printer for now, though it&amp;#8217;s definitely way too incomplete to be merged. The code passes &lt;em&gt;most&lt;/em&gt; of the rudimentary tests I&amp;#8217;ve added.&lt;/p&gt;
&lt;p&gt;Here&amp;#8217;s a simple example of one of the failing LFortran tests: Suppose we want to generate Fortran (using LFortran) code from the mathematical expression &lt;span class="math inline"&gt;&amp;#8197;&amp;#8722;&amp;#8197;&lt;em&gt;x&lt;/em&gt;&lt;/span&gt;. SymPy sees this expression as multiplication with -1, as it implements only addition and multiplication in its arithmetic operations:&lt;/p&gt;
&lt;div class="sourceCode" id="cb1"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb1-1" title="1"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="im"&gt;from&lt;/span&gt; sympy &lt;span class="im"&gt;import&lt;/span&gt; &lt;span class="op"&gt;*&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-2" title="2"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; x &lt;span class="op"&gt;=&lt;/span&gt; Symbol(&lt;span class="st"&gt;'x'&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-3" title="3"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; srepr(&lt;span class="op"&gt;-&lt;/span&gt;x)&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-4" title="4"&gt;&lt;span class="co"&gt;&amp;quot;Mul(Integer(-1), Symbol('x'))&amp;quot;&lt;/span&gt;&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Directly converting same mathematical expression in Fortran as &lt;code&gt;-x&lt;/code&gt; we can see that LFortran instead sees it as unary subtraction:&lt;/p&gt;
&lt;div class="sourceCode" id="cb2"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb2-1" title="1"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="im"&gt;from&lt;/span&gt; lfortran &lt;span class="im"&gt;import&lt;/span&gt; &lt;span class="op"&gt;*&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-2" title="2"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; src_to_ast(&lt;span class="st"&gt;&amp;quot;-x&amp;quot;&lt;/span&gt;, &lt;span class="va"&gt;False&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-3" title="3"&gt;&lt;span class="op"&gt;&amp;lt;&lt;/span&gt;lfortran.ast.ast.UnaryOp &lt;span class="bu"&gt;object&lt;/span&gt; at &lt;span class="bn"&gt;0x7f9027f1aba8&lt;/span&gt;&lt;span class="op"&gt;&amp;gt;&lt;/span&gt;&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This is a major problem for the tests, which right now look to see if the Lfortran-parsed output of &lt;code&gt;fcode&lt;/code&gt; (SymPy&amp;#8217;s current Fortran code generator) on an expression matches the same directly translated AST. This won&amp;#8217;t be true for &lt;span class="math inline"&gt;&amp;#8197;&amp;#8722;&amp;#8197;&lt;em&gt;x&lt;/em&gt;&lt;/span&gt;, since the translated expression is a multiplication &lt;code&gt;BinOp&lt;/code&gt; while the parsed expression in an &lt;code&gt;UnaryOp&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;One solution might be to not parse &lt;code&gt;fcode&lt;/code&gt;&amp;#8217;s output and instead just check for equivalence between strings. This would mean dealing with the quirks of the code printers (such as their tendency to produce excessive parenthesis), and take away some of the advantages of direct translation. The more probable solution would be to introduce substitution rules within the LFortran AST.&lt;/p&gt;
&lt;h2 id="missing-matrix-nodes"&gt;Missing matrix nodes&lt;/h2&gt;
&lt;p&gt;I filed issue &lt;a href="https://github.com/sympy/sympy/issues/17006"&gt;#17006&lt;/a&gt;, in which &lt;code&gt;lambdify&lt;/code&gt; misinterpreted identity matrices as the imaginary unit. The fix in &lt;a href="https://github.com/sympy/sympy/pull/17022"&gt;#17022&lt;/a&gt; is pretty simple: just generate identity matrices with &lt;code&gt;np.eye&lt;/code&gt; when we can.&lt;/p&gt;
&lt;p&gt;I also went through the matrix expression classes to see which ones weren&amp;#8217;t supported by the NumPy code printer and filed issue &lt;a href="https://github.com/sympy/sympy/issues/17013"&gt;#17013&lt;/a&gt;. These are addressed by another contributor in &lt;a href="https://github.com/sympy/sympy/pull/17029%5D"&gt;#17029&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="rewriting-matrix-inversion"&gt;Rewriting matrix inversion&lt;/h2&gt;
&lt;p&gt;Most of this week was spent on implementing an optimization for the NumPy generator suggested by Aaron: given the expression &lt;span class="math inline"&gt;&lt;em&gt;A&lt;/em&gt;&lt;sup&gt;&amp;#8197;&amp;#8722;&amp;#8197;1&lt;/sup&gt;&lt;em&gt;b&lt;/em&gt;&lt;/span&gt; where &lt;span class="math inline"&gt;&lt;em&gt;A&lt;/em&gt;&lt;/span&gt; is a square matrix and &lt;span class="math inline"&gt;&lt;em&gt;b&lt;/em&gt;&lt;/span&gt; a vector, generate the expression &lt;code&gt;np.linalg.solve(A, b)&lt;/code&gt; instead of &lt;code&gt;np.linalg.inv(A) * b&lt;/code&gt;. While both &lt;code&gt;solve&lt;/code&gt; and &lt;code&gt;inv&lt;/code&gt; use the same LU-decomposition based LAPACK &lt;a href="http://www.netlib.org/lapack95/DOC/la_gesv.txt"&gt;&lt;code&gt;?gesv&lt;/code&gt;&lt;/a&gt; functions &lt;a class="footnote-ref" href="https://anpandey.github.io/atom-sympy.xml#fn1" id="fnref1"&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;, &lt;code&gt;solve&lt;/code&gt; is called on a vector while the &lt;code&gt;inv&lt;/code&gt; on a (much larger) matrix. In addition to cutting down on the number of operations, this optimization might also remove any errors introduced in calculating the inverse.&lt;/p&gt;
&lt;p&gt;My pull request for this optimization is available at &lt;a href="https://github.com/sympy/sympy/pull/17041"&gt;#17041&lt;/a&gt;, which uses SymPy&amp;#8217;s assumption system to make sure that &lt;span class="math inline"&gt;&lt;em&gt;A&lt;/em&gt;&lt;/span&gt; is full-rank (a constraint imposed by &lt;code&gt;solve&lt;/code&gt;). My initial approach was to embed these optimizations directly in the code printing base classes. After some discussion with Bj&amp;#246;rn, we decided it would be better to separate optimization from printing as much as possible, leading to the representation of the solving operation as its own distinct AST node. This approach is much better than the original, since it was fairly easy to the optimization to the Octave/Matlab code printer.&lt;/p&gt;
&lt;h2 id="next-steps"&gt;Next Steps&lt;/h2&gt;
&lt;p&gt;For this week, I&amp;#8217;ll be continuing with the matrix optimization PR. I&amp;#8217;ll try to find other optimizations that can be applied (such as the evaluation order of complicated matrix expressions) and look into using Sympy&amp;#8217;s unification capabilities in simplifying the expression of optimization rules.&lt;/p&gt;
&lt;section class="footnotes"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn1"&gt;&lt;p&gt;You can find the C definitions for the functions eventually called by &lt;a href="https://github.com/numpy/numpy/blob/b80d360e/numpy/linalg/umath_linalg.c.src#L1694"&gt;&lt;code&gt;inv&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://github.com/numpy/numpy/blob/b80d360e/numpy/linalg/umath_linalg.c.src#L1622"&gt;&lt;code&gt;solve&lt;/code&gt;&lt;/a&gt;. These are written in a special templated version of C, but you can find the &lt;a href="https://github.com/numpy/numpy/blob/b80d360e/numpy/linalg/umath_linalg.c.src#L1560"&gt;template variable definitions&lt;/a&gt; a bit higher up in the source.&lt;a class="footnote-back" href="https://anpandey.github.io/atom-sympy.xml#fnref1"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;</description>
    </item>
    <item>
      <guid isPermaLink="false">https://divyanshu132.github.io//gsoc-week-3</guid>
      <author>Divyanshu Thakur (divyanshu132)</author>
      <title>Divyanshu Thakur (divyanshu132): GSoC 2019 - Week 3 - Polycyclic Groups</title>
      <pubDate>Mon, 17 Jun 2019 00:00:00 GMT</pubDate>
      <link>https://divyanshu132.github.io//gsoc-week-3</link>
      <description>&lt;p&gt;The third week has ended and a good amount of work has been done on polycyclic groups PR &lt;a href="https://github.com/sympy/sympy/pull/16991"&gt;here&lt;/a&gt;. The collection algorithm has been implemented, from the beginning of the week, I started with understanding the algorithm which took some time and then finally it was implemented, still we are facing a problem in type conversion(&lt;a href="https://github.com/sympy/sympy/pull/16991#discussion_r294054681"&gt;here&lt;/a&gt;) but that will be sorted out soon!&lt;/p&gt;

&lt;p&gt;Even though only two weeks were alloted for polycyclic group implementation but it seems we need one more week or maybe more than a week to implement more functionalities for pc groups. But it&amp;#8217;s completely fine because we started work early and according to the proposed timeline we still have one week.&lt;/p&gt;

&lt;p&gt;Few of the issues with the current implementation which needs to be sorted out are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;firstly to &lt;code class="highlighter-rouge"&gt;compute uncollected subwords&lt;/code&gt; the word is manipulated using its &lt;code class="highlighter-rouge"&gt;array_form&lt;/code&gt; which eventually leads to change in the type of the subwords computed and it creates a problem in processing these subwords further.&lt;/li&gt;
  &lt;li&gt;Some more issues were pointed out by Kalevi and can be seen in the comments of the PR.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The complete week was spent implementing collection of words so a lot of tasks targeted last week were not completed, I&amp;#8217;ll try to cover those tasks in the upcomming week.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Solve the issues with collection of words.&lt;/li&gt;
  &lt;li&gt;Get ready with the pc presentation.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Till then, Good byee..!&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
